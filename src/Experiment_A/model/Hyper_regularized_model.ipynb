{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN Model - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@authors: Donggeun Kim\n",
    "@affiliation: NYSPI, Columbia University\n",
    "@date: Oct 2018 - Oct 2020\n",
    "@overview: Architecture implementation and model training for the Experiment A 1D CNN model in Keras.\n",
    "@input: LOOCV Train/Test folds of 300-length hyperaligned voxels as numpy arrays. LOOCV Train/Test labels.\n",
    "@output: Trained model checkpoints (.ckpt & metadata)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2586,
     "status": "ok",
     "timestamp": 1621906313358,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "VHC679VZ0PZY",
    "outputId": "5278e360-fd90-4659-b24c-77bc3e0a39aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import History\n",
    "import pickle\n",
    "from keras import initializers\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import glob\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, show\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1621906342080,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "yGAj7qa26WIN"
   },
   "outputs": [],
   "source": [
    "folder_root = '/content/drive/My Drive/BrainStateClassification/code/'#Update to your main folder, this folder must contain a data and a result subfolder\n",
    "folder_data = folder_root + 'data/' #folder containing all the .mat files\n",
    "folder_result = folder_root + 'data/plateau' #folder where your models and logs will be stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1621906342968,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "1Law7G13BPoK"
   },
   "outputs": [],
   "source": [
    "os.chdir(folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3053,
     "status": "ok",
     "timestamp": 1621906346015,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "Bmva1NFY1P3n"
   },
   "outputs": [],
   "source": [
    "Y = np.loadtxt('Y_hyp_v2.csv',delimiter=\",\")\n",
    "X = np.loadtxt('X_hyp_v2.csv',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1621906346023,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "6DTfTRYUz98n",
    "outputId": "a8853283-f26f-4891-81e7-2881d938440b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 2200, 1.0: 1100, 2.0: 1100})"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19621,
     "status": "ok",
     "timestamp": 1618108614850,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "No5angtRiavu",
    "outputId": "d73ecb76-8335-43ee-e0aa-ca906bd92006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4400, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4ShFEhI0Nj3"
   },
   "outputs": [],
   "source": [
    "bias_regularization = 0.005\n",
    "kernel_regularization = 0.005\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, (10), input_shape=(300,1)))\n",
    "    model.add(Conv1D(128, (10)))\n",
    "    model.add(Conv1D(128, (10)))\n",
    "    model.add(Conv1D(64, (10)))\n",
    "    model.add(Conv1D(64, (10)))\n",
    "    model.add(Conv1D(64, (10)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1024, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "                           bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "                       bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dense(256, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "                    bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "                bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dense(64, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "              bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dense(32, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "          bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dense(16, activation='relu',kernel_regularizer=keras.regularizers.l1(kernel_regularization),\n",
    "      bias_regularizer=keras.regularizers.l1(bias_regularization)))\n",
    "    model.add(Dense(3, activation='softmax')) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "executionInfo": {
     "elapsed": 6684,
     "status": "ok",
     "timestamp": 1603407235682,
     "user": {
      "displayName": "할 수 있어",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgLVzc1_GMYPmtvHB2c7yYra-Pi5yv_4fEfEqCYg=s64",
      "userId": "07644359063870838140"
     },
     "user_tz": 240
    },
    "id": "47Gu55GSAfKI",
    "outputId": "708f0b3b-1a59-4223-d4e1-4f2c5a3ab9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 291, 128)          1408      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 282, 128)          163968    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 273, 128)          163968    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 264, 64)           81984     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 255, 64)           41024     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 246, 64)           41024     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15744)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15744)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              16122880  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 17,316,195\n",
      "Trainable params: 17,316,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4X4MzLwxMAr"
   },
   "source": [
    "# **Manual Cross-Validation over X,y Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5862371,
     "status": "ok",
     "timestamp": 1602543618150,
     "user": {
      "displayName": "할 수 있어",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgLVzc1_GMYPmtvHB2c7yYra-Pi5yv_4fEfEqCYg=s64",
      "userId": "07644359063870838140"
     },
     "user_tz": 240
    },
    "id": "JofUAlaAkKyJ",
    "outputId": "9098ac51-3c60-4dea-d495-985f64ee351d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "to create\n",
      "created\n",
      "./plateau/weights_holdout_regularized_0_0.0045.best.hdf5\n",
      "created a new model\n",
      "Before Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7867 - accuracy: 0.6488 - val_loss: 0.7311 - val_accuracy: 0.6600\n",
      "Epoch 2524/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7849 - accuracy: 0.6405 - val_loss: 0.7359 - val_accuracy: 0.6417\n",
      "Epoch 2525/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7985 - accuracy: 0.6432 - val_loss: 0.7468 - val_accuracy: 0.6433\n",
      "Epoch 2526/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8027 - accuracy: 0.6453 - val_loss: 0.7504 - val_accuracy: 0.6517\n",
      "Epoch 2527/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8048 - accuracy: 0.6365 - val_loss: 0.7380 - val_accuracy: 0.6567\n",
      "Epoch 2528/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7918 - accuracy: 0.6425 - val_loss: 0.7460 - val_accuracy: 0.6500\n",
      "Epoch 2529/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7928 - accuracy: 0.6435 - val_loss: 0.7503 - val_accuracy: 0.6400\n",
      "Epoch 2530/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7925 - accuracy: 0.6418 - val_loss: 0.7527 - val_accuracy: 0.6467\n",
      "Epoch 2531/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7896 - accuracy: 0.6483 - val_loss: 0.7370 - val_accuracy: 0.6783\n",
      "Epoch 2532/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7920 - accuracy: 0.6495 - val_loss: 0.7315 - val_accuracy: 0.6633\n",
      "Epoch 2533/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8009 - accuracy: 0.6397 - val_loss: 0.7425 - val_accuracy: 0.6533\n",
      "Epoch 2534/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8117 - accuracy: 0.6565 - val_loss: 0.7408 - val_accuracy: 0.6417\n",
      "Epoch 2535/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8051 - accuracy: 0.6402 - val_loss: 0.7474 - val_accuracy: 0.6467\n",
      "Epoch 2536/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7880 - accuracy: 0.6360 - val_loss: 0.7384 - val_accuracy: 0.6500\n",
      "Epoch 2537/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7813 - accuracy: 0.6440 - val_loss: 0.7342 - val_accuracy: 0.6450\n",
      "Epoch 2538/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7893 - accuracy: 0.6390 - val_loss: 0.7423 - val_accuracy: 0.6400\n",
      "Epoch 2539/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7929 - accuracy: 0.6413 - val_loss: 0.7502 - val_accuracy: 0.6400\n",
      "Epoch 2540/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7921 - accuracy: 0.6338 - val_loss: 0.7471 - val_accuracy: 0.6517\n",
      "Epoch 2541/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8035 - accuracy: 0.6307 - val_loss: 0.7524 - val_accuracy: 0.6450\n",
      "Epoch 2542/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6330 - val_loss: 0.7467 - val_accuracy: 0.6367\n",
      "Epoch 2543/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7943 - accuracy: 0.6382 - val_loss: 0.7490 - val_accuracy: 0.6617\n",
      "Epoch 2544/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7978 - accuracy: 0.6383 - val_loss: 0.7504 - val_accuracy: 0.6383\n",
      "Epoch 2545/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7906 - accuracy: 0.6320 - val_loss: 0.7501 - val_accuracy: 0.6600\n",
      "Epoch 2546/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7864 - accuracy: 0.6455 - val_loss: 0.7500 - val_accuracy: 0.6550\n",
      "Epoch 2547/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7863 - accuracy: 0.6495 - val_loss: 0.7516 - val_accuracy: 0.6617\n",
      "Epoch 2548/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7856 - accuracy: 0.6380 - val_loss: 0.7460 - val_accuracy: 0.6383\n",
      "Epoch 2549/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7788 - accuracy: 0.6405 - val_loss: 0.7513 - val_accuracy: 0.6533\n",
      "Epoch 2550/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7813 - accuracy: 0.6397 - val_loss: 0.7482 - val_accuracy: 0.6617\n",
      "Epoch 2551/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7814 - accuracy: 0.6435 - val_loss: 0.7531 - val_accuracy: 0.6500\n",
      "Epoch 2552/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7787 - accuracy: 0.6408 - val_loss: 0.7583 - val_accuracy: 0.6533\n",
      "Epoch 2553/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7901 - accuracy: 0.6432 - val_loss: 0.7527 - val_accuracy: 0.6433\n",
      "Epoch 2554/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7921 - accuracy: 0.6430 - val_loss: 0.7509 - val_accuracy: 0.6500\n",
      "Epoch 2555/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7830 - accuracy: 0.6420 - val_loss: 0.7498 - val_accuracy: 0.6700\n",
      "Epoch 2556/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7809 - accuracy: 0.6372 - val_loss: 0.7406 - val_accuracy: 0.6667\n",
      "Epoch 2557/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7861 - accuracy: 0.6462 - val_loss: 0.7399 - val_accuracy: 0.6500\n",
      "Epoch 2558/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7912 - accuracy: 0.6418 - val_loss: 0.7428 - val_accuracy: 0.6600\n",
      "Epoch 2559/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7982 - accuracy: 0.6472 - val_loss: 0.7393 - val_accuracy: 0.6333\n",
      "Epoch 2560/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7813 - accuracy: 0.6372 - val_loss: 0.7403 - val_accuracy: 0.6467\n",
      "Epoch 2561/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7810 - accuracy: 0.6437 - val_loss: 0.7344 - val_accuracy: 0.6467\n",
      "Epoch 2562/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7854 - accuracy: 0.6473 - val_loss: 0.7399 - val_accuracy: 0.6117\n",
      "Epoch 2563/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7709 - accuracy: 0.6468 - val_loss: 0.7423 - val_accuracy: 0.6450\n",
      "Epoch 2564/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7778 - accuracy: 0.6413 - val_loss: 0.7383 - val_accuracy: 0.6317\n",
      "Epoch 2565/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7761 - accuracy: 0.6415 - val_loss: 0.7362 - val_accuracy: 0.6483\n",
      "Epoch 2566/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7887 - accuracy: 0.6360 - val_loss: 0.7406 - val_accuracy: 0.6467\n",
      "Epoch 2567/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7909 - accuracy: 0.6348 - val_loss: 0.7458 - val_accuracy: 0.6400\n",
      "Epoch 2568/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7936 - accuracy: 0.6317 - val_loss: 0.7440 - val_accuracy: 0.6300\n",
      "Epoch 2569/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7841 - accuracy: 0.6347 - val_loss: 0.7471 - val_accuracy: 0.6667\n",
      "Epoch 2570/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7948 - accuracy: 0.6393 - val_loss: 0.7436 - val_accuracy: 0.6367\n",
      "Epoch 2571/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7889 - accuracy: 0.6387 - val_loss: 0.7453 - val_accuracy: 0.6367\n",
      "Epoch 2572/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7866 - accuracy: 0.6383 - val_loss: 0.7458 - val_accuracy: 0.6400\n",
      "Epoch 2573/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7979 - accuracy: 0.6338 - val_loss: 0.7432 - val_accuracy: 0.6317\n",
      "Epoch 2574/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7780 - accuracy: 0.6483 - val_loss: 0.7519 - val_accuracy: 0.6267\n",
      "Epoch 2575/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7991 - accuracy: 0.6365 - val_loss: 0.7506 - val_accuracy: 0.6550\n",
      "Epoch 2576/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8011 - accuracy: 0.6403 - val_loss: 0.7480 - val_accuracy: 0.6283\n",
      "Epoch 2577/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8031 - accuracy: 0.6422 - val_loss: 0.7535 - val_accuracy: 0.6417\n",
      "Epoch 2578/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7885 - accuracy: 0.6418 - val_loss: 0.7517 - val_accuracy: 0.6567\n",
      "Epoch 2579/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7959 - accuracy: 0.6410 - val_loss: 0.7478 - val_accuracy: 0.6483\n",
      "Epoch 2580/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7926 - accuracy: 0.6475 - val_loss: 0.7392 - val_accuracy: 0.6667\n",
      "Epoch 2581/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7910 - accuracy: 0.6498 - val_loss: 0.7474 - val_accuracy: 0.6533\n",
      "Epoch 2582/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7870 - accuracy: 0.6518 - val_loss: 0.7437 - val_accuracy: 0.6483\n",
      "Epoch 2583/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7894 - accuracy: 0.6430 - val_loss: 0.7487 - val_accuracy: 0.6583\n",
      "Epoch 2584/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7911 - accuracy: 0.6433 - val_loss: 0.7466 - val_accuracy: 0.6483\n",
      "Epoch 2585/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7939 - accuracy: 0.6397 - val_loss: 0.7457 - val_accuracy: 0.6533\n",
      "Epoch 2586/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7940 - accuracy: 0.6360 - val_loss: 0.7421 - val_accuracy: 0.6417\n",
      "Epoch 2587/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7847 - accuracy: 0.6428 - val_loss: 0.7355 - val_accuracy: 0.6300\n",
      "Epoch 2588/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7779 - accuracy: 0.6407 - val_loss: 0.7401 - val_accuracy: 0.6667\n",
      "Epoch 2589/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7791 - accuracy: 0.6430 - val_loss: 0.7420 - val_accuracy: 0.6567\n",
      "Epoch 2590/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7857 - accuracy: 0.6423 - val_loss: 0.7437 - val_accuracy: 0.6283\n",
      "Epoch 2591/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7823 - accuracy: 0.6400 - val_loss: 0.7380 - val_accuracy: 0.6817\n",
      "Epoch 2592/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7953 - accuracy: 0.6407 - val_loss: 0.7393 - val_accuracy: 0.6583\n",
      "Epoch 2593/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7899 - accuracy: 0.6332 - val_loss: 0.7424 - val_accuracy: 0.6700\n",
      "Epoch 2594/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7912 - accuracy: 0.6473 - val_loss: 0.7387 - val_accuracy: 0.6550\n",
      "Epoch 2595/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7841 - accuracy: 0.6438 - val_loss: 0.7452 - val_accuracy: 0.6583\n",
      "Epoch 2596/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.8054 - accuracy: 0.6360 - val_loss: 0.7386 - val_accuracy: 0.6617\n",
      "Epoch 2597/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7957 - accuracy: 0.6428 - val_loss: 0.7404 - val_accuracy: 0.6417\n",
      "Epoch 2598/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7877 - accuracy: 0.6390 - val_loss: 0.7403 - val_accuracy: 0.6367\n",
      "Epoch 2599/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7932 - accuracy: 0.6495 - val_loss: 0.7366 - val_accuracy: 0.6600\n",
      "Epoch 2600/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7880 - accuracy: 0.6453 - val_loss: 0.7385 - val_accuracy: 0.6517\n",
      "Epoch 2601/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7909 - accuracy: 0.6467 - val_loss: 0.7497 - val_accuracy: 0.6467\n",
      "Epoch 2602/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7924 - accuracy: 0.6462 - val_loss: 0.7385 - val_accuracy: 0.6750\n",
      "Epoch 2603/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7923 - accuracy: 0.6375 - val_loss: 0.7372 - val_accuracy: 0.6350\n",
      "Epoch 2604/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7840 - accuracy: 0.6422 - val_loss: 0.7418 - val_accuracy: 0.6450\n",
      "Epoch 2605/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7901 - accuracy: 0.6395 - val_loss: 0.7297 - val_accuracy: 0.6483\n",
      "Epoch 2606/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7791 - accuracy: 0.6442 - val_loss: 0.7278 - val_accuracy: 0.6483\n",
      "Epoch 2607/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7900 - accuracy: 0.6412 - val_loss: 0.7375 - val_accuracy: 0.6483\n",
      "Epoch 2608/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7842 - accuracy: 0.6403 - val_loss: 0.7370 - val_accuracy: 0.6567\n",
      "Epoch 2609/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7985 - accuracy: 0.6432 - val_loss: 0.7364 - val_accuracy: 0.6600\n",
      "Epoch 2610/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7845 - accuracy: 0.6427 - val_loss: 0.7333 - val_accuracy: 0.6417\n",
      "Epoch 2611/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7865 - accuracy: 0.6483 - val_loss: 0.7291 - val_accuracy: 0.6550\n",
      "Epoch 2612/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7797 - accuracy: 0.6467 - val_loss: 0.7301 - val_accuracy: 0.6350\n",
      "Epoch 2613/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7845 - accuracy: 0.6415 - val_loss: 0.7307 - val_accuracy: 0.6483\n",
      "Epoch 2614/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7828 - accuracy: 0.6512 - val_loss: 0.7383 - val_accuracy: 0.6467\n",
      "Epoch 2615/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7848 - accuracy: 0.6447 - val_loss: 0.7492 - val_accuracy: 0.6500\n",
      "Epoch 2616/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7869 - accuracy: 0.6430 - val_loss: 0.7441 - val_accuracy: 0.6367\n",
      "Epoch 2617/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7818 - accuracy: 0.6522 - val_loss: 0.7467 - val_accuracy: 0.6450\n",
      "Epoch 2618/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7877 - accuracy: 0.6447 - val_loss: 0.7480 - val_accuracy: 0.6633\n",
      "Epoch 2619/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7830 - accuracy: 0.6473 - val_loss: 0.7391 - val_accuracy: 0.6250\n",
      "Epoch 2620/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7930 - accuracy: 0.6460 - val_loss: 0.7479 - val_accuracy: 0.6383\n",
      "Epoch 2621/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7893 - accuracy: 0.6515 - val_loss: 0.7455 - val_accuracy: 0.6683\n",
      "Epoch 2622/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7907 - accuracy: 0.6480 - val_loss: 0.7347 - val_accuracy: 0.6317\n",
      "Epoch 2623/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7817 - accuracy: 0.6478 - val_loss: 0.7408 - val_accuracy: 0.6450\n",
      "Epoch 2624/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7927 - accuracy: 0.6422 - val_loss: 0.7393 - val_accuracy: 0.6483\n",
      "Epoch 2625/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7832 - accuracy: 0.6382 - val_loss: 0.7395 - val_accuracy: 0.6283\n",
      "Epoch 2626/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7950 - accuracy: 0.6387 - val_loss: 0.7432 - val_accuracy: 0.6450\n",
      "Epoch 2627/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7963 - accuracy: 0.6433 - val_loss: 0.7472 - val_accuracy: 0.6383\n",
      "Epoch 2628/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7833 - accuracy: 0.6468 - val_loss: 0.7429 - val_accuracy: 0.6550\n",
      "Epoch 2629/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7842 - accuracy: 0.6490 - val_loss: 0.7375 - val_accuracy: 0.6333\n",
      "Epoch 2630/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7972 - accuracy: 0.6477 - val_loss: 0.7336 - val_accuracy: 0.6200\n",
      "Epoch 2631/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7807 - accuracy: 0.6465 - val_loss: 0.7242 - val_accuracy: 0.6400\n",
      "Epoch 2632/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7877 - accuracy: 0.6412 - val_loss: 0.7157 - val_accuracy: 0.6583\n",
      "Epoch 2633/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7910 - accuracy: 0.6433 - val_loss: 0.7277 - val_accuracy: 0.6517\n",
      "Epoch 2634/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7837 - accuracy: 0.6368 - val_loss: 0.7281 - val_accuracy: 0.6633\n",
      "Epoch 2635/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7720 - accuracy: 0.6500 - val_loss: 0.7361 - val_accuracy: 0.6650\n",
      "Epoch 2636/5000\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.7938 - accuracy: 0.6412 - val_loss: 0.7390 - val_accuracy: 0.6933\n",
      "Epoch 2637/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7946 - accuracy: 0.6380 - val_loss: 0.7225 - val_accuracy: 0.6367\n",
      "Epoch 2638/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7867 - accuracy: 0.6405 - val_loss: 0.7329 - val_accuracy: 0.6450\n",
      "Epoch 2639/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7892 - accuracy: 0.6440 - val_loss: 0.7319 - val_accuracy: 0.6183\n",
      "Epoch 2640/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7928 - accuracy: 0.6382 - val_loss: 0.7349 - val_accuracy: 0.6533\n",
      "Epoch 2641/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7934 - accuracy: 0.6453 - val_loss: 0.7331 - val_accuracy: 0.6517\n",
      "Epoch 2642/5000\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 0.7913 - accuracy: 0.6385 - val_loss: 0.7388 - val_accuracy: 0.6417\n",
      "Epoch 2643/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7946 - accuracy: 0.6322 - val_loss: 0.7442 - val_accuracy: 0.6417\n",
      "Epoch 2644/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7990 - accuracy: 0.6427 - val_loss: 0.7504 - val_accuracy: 0.6583\n",
      "Epoch 2645/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7954 - accuracy: 0.6350 - val_loss: 0.7404 - val_accuracy: 0.6450\n",
      "Epoch 2646/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7957 - accuracy: 0.6415 - val_loss: 0.7362 - val_accuracy: 0.6500\n",
      "Epoch 2647/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7867 - accuracy: 0.6448 - val_loss: 0.7363 - val_accuracy: 0.6467\n",
      "Epoch 2648/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7810 - accuracy: 0.6410 - val_loss: 0.7424 - val_accuracy: 0.6517\n",
      "Epoch 2649/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7968 - accuracy: 0.6390 - val_loss: 0.7450 - val_accuracy: 0.6617\n",
      "Epoch 2650/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7883 - accuracy: 0.6467 - val_loss: 0.7512 - val_accuracy: 0.6383\n",
      "Epoch 2651/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7888 - accuracy: 0.6382 - val_loss: 0.7395 - val_accuracy: 0.6633\n",
      "Epoch 2652/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7970 - accuracy: 0.6425 - val_loss: 0.7346 - val_accuracy: 0.6550\n",
      "Epoch 2653/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7880 - accuracy: 0.6415 - val_loss: 0.7308 - val_accuracy: 0.6550\n",
      "Epoch 2654/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7909 - accuracy: 0.6392 - val_loss: 0.7301 - val_accuracy: 0.6450\n",
      "Epoch 2655/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7979 - accuracy: 0.6505 - val_loss: 0.7465 - val_accuracy: 0.6567\n",
      "Epoch 2656/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7836 - accuracy: 0.6422 - val_loss: 0.7464 - val_accuracy: 0.6500\n",
      "Epoch 2657/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7939 - accuracy: 0.6420 - val_loss: 0.7410 - val_accuracy: 0.6567\n",
      "Epoch 2658/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7781 - accuracy: 0.6437 - val_loss: 0.7333 - val_accuracy: 0.6383\n",
      "Epoch 2659/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7884 - accuracy: 0.6408 - val_loss: 0.7348 - val_accuracy: 0.6600\n",
      "Epoch 2660/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7903 - accuracy: 0.6485 - val_loss: 0.7217 - val_accuracy: 0.6533\n",
      "Epoch 2661/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7933 - accuracy: 0.6383 - val_loss: 0.7354 - val_accuracy: 0.6667\n",
      "Epoch 2662/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7859 - accuracy: 0.6535 - val_loss: 0.7379 - val_accuracy: 0.6583\n",
      "Epoch 2663/5000\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.7793 - accuracy: 0.6428 - val_loss: 0.7432 - val_accuracy: 0.6967\n",
      "Epoch 2664/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7754 - accuracy: 0.6462 - val_loss: 0.7294 - val_accuracy: 0.6533\n",
      "Epoch 2665/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7943 - accuracy: 0.6488 - val_loss: 0.7368 - val_accuracy: 0.6550\n",
      "Epoch 2666/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7833 - accuracy: 0.6463 - val_loss: 0.7358 - val_accuracy: 0.6400\n",
      "Epoch 2667/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7901 - accuracy: 0.6417 - val_loss: 0.7449 - val_accuracy: 0.6583\n",
      "Epoch 2668/5000\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 0.7822 - accuracy: 0.6458 - val_loss: 0.7399 - val_accuracy: 0.6617\n",
      "Epoch 2669/5000\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 0.7909 - accuracy: 0.6458 - val_loss: 0.7381 - val_accuracy: 0.6650\n",
      "Epoch 2670/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7813 - accuracy: 0.6452 - val_loss: 0.7351 - val_accuracy: 0.6683\n",
      "Epoch 2671/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7872 - accuracy: 0.6445 - val_loss: 0.7364 - val_accuracy: 0.6600\n",
      "Epoch 2672/5000\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.7839 - accuracy: 0.6442 - val_loss: 0.7514 - val_accuracy: 0.7100\n",
      "Epoch 2673/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.8016 - accuracy: 0.6422 - val_loss: 0.7402 - val_accuracy: 0.6550\n",
      "Epoch 2674/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7901 - accuracy: 0.6495 - val_loss: 0.7503 - val_accuracy: 0.6833\n",
      "Epoch 2675/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7914 - accuracy: 0.6492 - val_loss: 0.7496 - val_accuracy: 0.6550\n",
      "Epoch 2676/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7838 - accuracy: 0.6478 - val_loss: 0.7524 - val_accuracy: 0.6567\n",
      "Epoch 2677/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7824 - accuracy: 0.6480 - val_loss: 0.7493 - val_accuracy: 0.6767\n",
      "Epoch 2678/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7785 - accuracy: 0.6525 - val_loss: 0.7426 - val_accuracy: 0.6700\n",
      "Epoch 2679/5000\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 0.7741 - accuracy: 0.6462 - val_loss: 0.7358 - val_accuracy: 0.6500\n",
      "Epoch 2680/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7913 - accuracy: 0.6452 - val_loss: 0.7427 - val_accuracy: 0.6767\n",
      "Epoch 2681/5000\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.7974 - accuracy: 0.6348 - val_loss: 0.7477 - val_accuracy: 0.7200\n",
      "Epoch 2682/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.7858 - accuracy: 0.6412 - val_loss: 0.7382 - val_accuracy: 0.6567\n",
      "Epoch 2683/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7924 - accuracy: 0.6408 - val_loss: 0.7404 - val_accuracy: 0.6750\n",
      "Epoch 2684/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8003 - accuracy: 0.6437 - val_loss: 0.7448 - val_accuracy: 0.6633\n",
      "Epoch 2685/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7878 - accuracy: 0.6473 - val_loss: 0.7453 - val_accuracy: 0.6733\n",
      "Epoch 2686/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7891 - accuracy: 0.6538 - val_loss: 0.7424 - val_accuracy: 0.6633\n",
      "Epoch 2687/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6470 - val_loss: 0.7411 - val_accuracy: 0.6483\n",
      "Epoch 2688/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7715 - accuracy: 0.6465 - val_loss: 0.7392 - val_accuracy: 0.6567\n",
      "Epoch 2689/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6525 - val_loss: 0.7401 - val_accuracy: 0.6633\n",
      "Epoch 2690/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7844 - accuracy: 0.6470 - val_loss: 0.7305 - val_accuracy: 0.6500\n",
      "Epoch 2691/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7862 - accuracy: 0.6415 - val_loss: 0.7397 - val_accuracy: 0.6750\n",
      "Epoch 2692/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7822 - accuracy: 0.6482 - val_loss: 0.7291 - val_accuracy: 0.6600\n",
      "Epoch 2693/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7940 - accuracy: 0.6382 - val_loss: 0.7421 - val_accuracy: 0.6617\n",
      "Epoch 2694/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.6497 - val_loss: 0.7429 - val_accuracy: 0.6550\n",
      "Epoch 2695/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7799 - accuracy: 0.6488 - val_loss: 0.7429 - val_accuracy: 0.6683\n",
      "Epoch 2696/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8000 - accuracy: 0.6453 - val_loss: 0.7401 - val_accuracy: 0.6750\n",
      "Epoch 2697/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7816 - accuracy: 0.6437 - val_loss: 0.7382 - val_accuracy: 0.7017\n",
      "Epoch 2698/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7861 - accuracy: 0.6520 - val_loss: 0.7336 - val_accuracy: 0.6783\n",
      "Epoch 2699/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6473 - val_loss: 0.7387 - val_accuracy: 0.6750\n",
      "Epoch 2700/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6375 - val_loss: 0.7330 - val_accuracy: 0.6450\n",
      "Epoch 2701/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6317 - val_loss: 0.7322 - val_accuracy: 0.6517\n",
      "Epoch 2702/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7963 - accuracy: 0.6462 - val_loss: 0.7366 - val_accuracy: 0.6500\n",
      "Epoch 2703/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7825 - accuracy: 0.6487 - val_loss: 0.7388 - val_accuracy: 0.6717\n",
      "Epoch 2704/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7787 - accuracy: 0.6487 - val_loss: 0.7321 - val_accuracy: 0.6650\n",
      "Epoch 2705/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7940 - accuracy: 0.6380 - val_loss: 0.7418 - val_accuracy: 0.6667\n",
      "Epoch 2706/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6363 - val_loss: 0.7396 - val_accuracy: 0.6517\n",
      "Epoch 2707/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7899 - accuracy: 0.6443 - val_loss: 0.7417 - val_accuracy: 0.6317\n",
      "Epoch 2708/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7958 - accuracy: 0.6407 - val_loss: 0.7296 - val_accuracy: 0.6683\n",
      "Epoch 2709/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7930 - accuracy: 0.6447 - val_loss: 0.7277 - val_accuracy: 0.6567\n",
      "Epoch 2710/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7846 - accuracy: 0.6508 - val_loss: 0.7281 - val_accuracy: 0.6450\n",
      "Epoch 2711/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7877 - accuracy: 0.6405 - val_loss: 0.7303 - val_accuracy: 0.6700\n",
      "Epoch 2712/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6470 - val_loss: 0.7233 - val_accuracy: 0.6567\n",
      "Epoch 2713/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7752 - accuracy: 0.6453 - val_loss: 0.7249 - val_accuracy: 0.6733\n",
      "Epoch 2714/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7814 - accuracy: 0.6490 - val_loss: 0.7300 - val_accuracy: 0.6600\n",
      "Epoch 2715/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6512 - val_loss: 0.7304 - val_accuracy: 0.6517\n",
      "Epoch 2716/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6465 - val_loss: 0.7322 - val_accuracy: 0.6850\n",
      "Epoch 2717/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7842 - accuracy: 0.6445 - val_loss: 0.7152 - val_accuracy: 0.6717\n",
      "Epoch 2718/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7706 - accuracy: 0.6473 - val_loss: 0.7175 - val_accuracy: 0.6583\n",
      "Epoch 2719/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7728 - accuracy: 0.6432 - val_loss: 0.7157 - val_accuracy: 0.6550\n",
      "Epoch 2720/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6443 - val_loss: 0.7207 - val_accuracy: 0.6583\n",
      "Epoch 2721/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.6462 - val_loss: 0.7167 - val_accuracy: 0.6533\n",
      "Epoch 2722/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6387 - val_loss: 0.7120 - val_accuracy: 0.6800\n",
      "Epoch 2723/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7952 - accuracy: 0.6373 - val_loss: 0.7319 - val_accuracy: 0.6683\n",
      "Epoch 2724/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7938 - accuracy: 0.6463 - val_loss: 0.7242 - val_accuracy: 0.6450\n",
      "Epoch 2725/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7804 - accuracy: 0.6495 - val_loss: 0.7276 - val_accuracy: 0.6467\n",
      "Epoch 2726/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7949 - accuracy: 0.6363 - val_loss: 0.7283 - val_accuracy: 0.6617\n",
      "Epoch 2727/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7714 - accuracy: 0.6515 - val_loss: 0.7238 - val_accuracy: 0.6433\n",
      "Epoch 2728/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6497 - val_loss: 0.7316 - val_accuracy: 0.6483\n",
      "Epoch 2729/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.6548 - val_loss: 0.7252 - val_accuracy: 0.6600\n",
      "Epoch 2730/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7955 - accuracy: 0.6443 - val_loss: 0.7287 - val_accuracy: 0.6450\n",
      "Epoch 2731/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7875 - accuracy: 0.6463 - val_loss: 0.7395 - val_accuracy: 0.6350\n",
      "Epoch 2732/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6408 - val_loss: 0.7200 - val_accuracy: 0.6617\n",
      "Epoch 2733/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7889 - accuracy: 0.6447 - val_loss: 0.7275 - val_accuracy: 0.6567\n",
      "Epoch 2734/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8012 - accuracy: 0.6517 - val_loss: 0.7234 - val_accuracy: 0.6500\n",
      "Epoch 2735/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7844 - accuracy: 0.6498 - val_loss: 0.7227 - val_accuracy: 0.6567\n",
      "Epoch 2736/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6453 - val_loss: 0.7282 - val_accuracy: 0.6817\n",
      "Epoch 2737/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6483 - val_loss: 0.7217 - val_accuracy: 0.6717\n",
      "Epoch 2738/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7841 - accuracy: 0.6480 - val_loss: 0.7225 - val_accuracy: 0.6733\n",
      "Epoch 2739/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7855 - accuracy: 0.6430 - val_loss: 0.7197 - val_accuracy: 0.6650\n",
      "Epoch 2740/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7820 - accuracy: 0.6458 - val_loss: 0.7203 - val_accuracy: 0.6417\n",
      "Epoch 2741/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7867 - accuracy: 0.6457 - val_loss: 0.7283 - val_accuracy: 0.6467\n",
      "Epoch 2742/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7903 - accuracy: 0.6473 - val_loss: 0.7286 - val_accuracy: 0.6433\n",
      "Epoch 2743/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7912 - accuracy: 0.6408 - val_loss: 0.7240 - val_accuracy: 0.6783\n",
      "Epoch 2744/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7821 - accuracy: 0.6478 - val_loss: 0.7352 - val_accuracy: 0.6450\n",
      "Epoch 2745/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6523 - val_loss: 0.7317 - val_accuracy: 0.6633\n",
      "Epoch 2746/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7985 - accuracy: 0.6397 - val_loss: 0.7407 - val_accuracy: 0.6617\n",
      "Epoch 2747/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7916 - accuracy: 0.6473 - val_loss: 0.7365 - val_accuracy: 0.6583\n",
      "Epoch 2748/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6407 - val_loss: 0.7355 - val_accuracy: 0.6683\n",
      "Epoch 2749/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7962 - accuracy: 0.6475 - val_loss: 0.7446 - val_accuracy: 0.6533\n",
      "Epoch 2750/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.8020 - accuracy: 0.6563 - val_loss: 0.7413 - val_accuracy: 0.6767\n",
      "Epoch 2751/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6427 - val_loss: 0.7548 - val_accuracy: 0.6717\n",
      "Epoch 2752/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7997 - accuracy: 0.6480 - val_loss: 0.7413 - val_accuracy: 0.6800\n",
      "Epoch 2753/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7923 - accuracy: 0.6597 - val_loss: 0.7307 - val_accuracy: 0.6433\n",
      "Epoch 2754/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8006 - accuracy: 0.6462 - val_loss: 0.7438 - val_accuracy: 0.6717\n",
      "Epoch 2755/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7700 - accuracy: 0.6557 - val_loss: 0.7379 - val_accuracy: 0.6767\n",
      "Epoch 2756/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7892 - accuracy: 0.6452 - val_loss: 0.7346 - val_accuracy: 0.6633\n",
      "Epoch 2757/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6387 - val_loss: 0.7237 - val_accuracy: 0.6550\n",
      "Epoch 2758/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6442 - val_loss: 0.7303 - val_accuracy: 0.6467\n",
      "Epoch 2759/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7899 - accuracy: 0.6480 - val_loss: 0.7407 - val_accuracy: 0.6417\n",
      "Epoch 2760/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7797 - accuracy: 0.6433 - val_loss: 0.7395 - val_accuracy: 0.6567\n",
      "Epoch 2761/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7965 - accuracy: 0.6498 - val_loss: 0.7430 - val_accuracy: 0.6600\n",
      "Epoch 2762/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7862 - accuracy: 0.6572 - val_loss: 0.7435 - val_accuracy: 0.6517\n",
      "Epoch 2763/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6400 - val_loss: 0.7414 - val_accuracy: 0.6350\n",
      "Epoch 2764/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7789 - accuracy: 0.6482 - val_loss: 0.7381 - val_accuracy: 0.6633\n",
      "Epoch 2765/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7866 - accuracy: 0.6507 - val_loss: 0.7381 - val_accuracy: 0.6533\n",
      "Epoch 2766/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7873 - accuracy: 0.6507 - val_loss: 0.7351 - val_accuracy: 0.6733\n",
      "Epoch 2767/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7917 - accuracy: 0.6460 - val_loss: 0.7397 - val_accuracy: 0.6533\n",
      "Epoch 2768/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6462 - val_loss: 0.7333 - val_accuracy: 0.6483\n",
      "Epoch 2769/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7736 - accuracy: 0.6552 - val_loss: 0.7276 - val_accuracy: 0.6483\n",
      "Epoch 2770/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6508 - val_loss: 0.7286 - val_accuracy: 0.6433\n",
      "Epoch 2771/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7854 - accuracy: 0.6512 - val_loss: 0.7374 - val_accuracy: 0.6567\n",
      "Epoch 2772/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7929 - accuracy: 0.6425 - val_loss: 0.7395 - val_accuracy: 0.6650\n",
      "Epoch 2773/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7984 - accuracy: 0.6673 - val_loss: 0.7378 - val_accuracy: 0.6400\n",
      "Epoch 2774/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6472 - val_loss: 0.7294 - val_accuracy: 0.6633\n",
      "Epoch 2775/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6530 - val_loss: 0.7328 - val_accuracy: 0.6817\n",
      "Epoch 2776/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6493 - val_loss: 0.7390 - val_accuracy: 0.6533\n",
      "Epoch 2777/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7842 - accuracy: 0.6523 - val_loss: 0.7284 - val_accuracy: 0.6617\n",
      "Epoch 2778/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7960 - accuracy: 0.6372 - val_loss: 0.7394 - val_accuracy: 0.6600\n",
      "Epoch 2779/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7976 - accuracy: 0.6388 - val_loss: 0.7499 - val_accuracy: 0.6917\n",
      "Epoch 2780/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8127 - accuracy: 0.6402 - val_loss: 0.7521 - val_accuracy: 0.6617\n",
      "Epoch 2781/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7904 - accuracy: 0.6505 - val_loss: 0.7521 - val_accuracy: 0.6833\n",
      "Epoch 2782/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7837 - accuracy: 0.6470 - val_loss: 0.7350 - val_accuracy: 0.6833\n",
      "Epoch 2783/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7704 - accuracy: 0.6572 - val_loss: 0.7316 - val_accuracy: 0.6633\n",
      "Epoch 2784/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7775 - accuracy: 0.6607 - val_loss: 0.7387 - val_accuracy: 0.6717\n",
      "Epoch 2785/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7940 - accuracy: 0.6508 - val_loss: 0.7418 - val_accuracy: 0.6783\n",
      "Epoch 2786/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7819 - accuracy: 0.6512 - val_loss: 0.7412 - val_accuracy: 0.6833\n",
      "Epoch 2787/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6563 - val_loss: 0.7372 - val_accuracy: 0.6450\n",
      "Epoch 2788/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7973 - accuracy: 0.6530 - val_loss: 0.7258 - val_accuracy: 0.6517\n",
      "Epoch 2789/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6595 - val_loss: 0.7288 - val_accuracy: 0.6883\n",
      "Epoch 2790/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7893 - accuracy: 0.6557 - val_loss: 0.7411 - val_accuracy: 0.6583\n",
      "Epoch 2791/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7896 - accuracy: 0.6562 - val_loss: 0.7374 - val_accuracy: 0.6517\n",
      "Epoch 2792/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7846 - accuracy: 0.6608 - val_loss: 0.7433 - val_accuracy: 0.7000\n",
      "Epoch 2793/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7942 - accuracy: 0.6588 - val_loss: 0.7526 - val_accuracy: 0.6967\n",
      "Epoch 2794/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7925 - accuracy: 0.6590 - val_loss: 0.7524 - val_accuracy: 0.6883\n",
      "Epoch 2795/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6520 - val_loss: 0.7506 - val_accuracy: 0.6717\n",
      "Epoch 2796/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6478 - val_loss: 0.7357 - val_accuracy: 0.6500\n",
      "Epoch 2797/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7838 - accuracy: 0.6475 - val_loss: 0.7302 - val_accuracy: 0.6450\n",
      "Epoch 2798/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7771 - accuracy: 0.6453 - val_loss: 0.7411 - val_accuracy: 0.6500\n",
      "Epoch 2799/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7907 - accuracy: 0.6393 - val_loss: 0.7398 - val_accuracy: 0.6783\n",
      "Epoch 2800/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7902 - accuracy: 0.6470 - val_loss: 0.7469 - val_accuracy: 0.6383\n",
      "Epoch 2801/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7838 - accuracy: 0.6440 - val_loss: 0.7549 - val_accuracy: 0.6267\n",
      "Epoch 2802/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7923 - accuracy: 0.6443 - val_loss: 0.7465 - val_accuracy: 0.6400\n",
      "Epoch 2803/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7845 - accuracy: 0.6483 - val_loss: 0.7407 - val_accuracy: 0.6483\n",
      "Epoch 2804/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7773 - accuracy: 0.6532 - val_loss: 0.7447 - val_accuracy: 0.6633\n",
      "Epoch 2805/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7934 - accuracy: 0.6452 - val_loss: 0.7392 - val_accuracy: 0.6300\n",
      "Epoch 2806/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6528 - val_loss: 0.7419 - val_accuracy: 0.6533\n",
      "Epoch 2807/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7962 - accuracy: 0.6492 - val_loss: 0.7450 - val_accuracy: 0.6600\n",
      "Epoch 2808/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7905 - accuracy: 0.6473 - val_loss: 0.7389 - val_accuracy: 0.6550\n",
      "Epoch 2809/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7938 - accuracy: 0.6462 - val_loss: 0.7499 - val_accuracy: 0.6733\n",
      "Epoch 2810/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6490 - val_loss: 0.7454 - val_accuracy: 0.6650\n",
      "Epoch 2811/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7857 - accuracy: 0.6447 - val_loss: 0.7472 - val_accuracy: 0.6800\n",
      "Epoch 2812/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.6515 - val_loss: 0.7452 - val_accuracy: 0.6800\n",
      "Epoch 2813/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7782 - accuracy: 0.6483 - val_loss: 0.7395 - val_accuracy: 0.6383\n",
      "Epoch 2814/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.6490 - val_loss: 0.7375 - val_accuracy: 0.6633\n",
      "Epoch 2815/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6455 - val_loss: 0.7372 - val_accuracy: 0.6583\n",
      "Epoch 2816/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7835 - accuracy: 0.6402 - val_loss: 0.7462 - val_accuracy: 0.6617\n",
      "Epoch 2817/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7889 - accuracy: 0.6448 - val_loss: 0.7317 - val_accuracy: 0.6317\n",
      "Epoch 2818/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6442 - val_loss: 0.7361 - val_accuracy: 0.6617\n",
      "Epoch 2819/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6467 - val_loss: 0.7339 - val_accuracy: 0.6350\n",
      "Epoch 2820/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7772 - accuracy: 0.6542 - val_loss: 0.7393 - val_accuracy: 0.6633\n",
      "Epoch 2821/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7909 - accuracy: 0.6530 - val_loss: 0.7367 - val_accuracy: 0.6733\n",
      "Epoch 2822/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7760 - accuracy: 0.6640 - val_loss: 0.7419 - val_accuracy: 0.6467\n",
      "Epoch 2823/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7765 - accuracy: 0.6520 - val_loss: 0.7353 - val_accuracy: 0.6700\n",
      "Epoch 2824/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.6487 - val_loss: 0.7310 - val_accuracy: 0.6483\n",
      "Epoch 2825/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7927 - accuracy: 0.6513 - val_loss: 0.7375 - val_accuracy: 0.6633\n",
      "Epoch 2826/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7784 - accuracy: 0.6423 - val_loss: 0.7322 - val_accuracy: 0.6433\n",
      "Epoch 2827/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6527 - val_loss: 0.7449 - val_accuracy: 0.6617\n",
      "Epoch 2828/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6488 - val_loss: 0.7433 - val_accuracy: 0.6467\n",
      "Epoch 2829/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7936 - accuracy: 0.6490 - val_loss: 0.7439 - val_accuracy: 0.6383\n",
      "Epoch 2830/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7738 - accuracy: 0.6507 - val_loss: 0.7355 - val_accuracy: 0.6500\n",
      "Epoch 2831/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7850 - accuracy: 0.6433 - val_loss: 0.7383 - val_accuracy: 0.6650\n",
      "Epoch 2832/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6475 - val_loss: 0.7419 - val_accuracy: 0.6817\n",
      "Epoch 2833/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6468 - val_loss: 0.7411 - val_accuracy: 0.6550\n",
      "Epoch 2834/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7988 - accuracy: 0.6503 - val_loss: 0.7439 - val_accuracy: 0.6750\n",
      "Epoch 2835/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7890 - accuracy: 0.6497 - val_loss: 0.7398 - val_accuracy: 0.6817\n",
      "Epoch 2836/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6508 - val_loss: 0.7467 - val_accuracy: 0.6433\n",
      "Epoch 2837/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7877 - accuracy: 0.6497 - val_loss: 0.7376 - val_accuracy: 0.6717\n",
      "Epoch 2838/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6435 - val_loss: 0.7418 - val_accuracy: 0.6417\n",
      "Epoch 2839/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6568 - val_loss: 0.7416 - val_accuracy: 0.6550\n",
      "Epoch 2840/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6462 - val_loss: 0.7324 - val_accuracy: 0.6533\n",
      "Epoch 2841/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6503 - val_loss: 0.7345 - val_accuracy: 0.6533\n",
      "Epoch 2842/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7909 - accuracy: 0.6502 - val_loss: 0.7349 - val_accuracy: 0.6433\n",
      "Epoch 2843/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6473 - val_loss: 0.7307 - val_accuracy: 0.6600\n",
      "Epoch 2844/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7767 - accuracy: 0.6432 - val_loss: 0.7431 - val_accuracy: 0.6533\n",
      "Epoch 2845/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7837 - accuracy: 0.6460 - val_loss: 0.7493 - val_accuracy: 0.6333\n",
      "Epoch 2846/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6455 - val_loss: 0.7538 - val_accuracy: 0.6267\n",
      "Epoch 2847/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6545 - val_loss: 0.7409 - val_accuracy: 0.6467\n",
      "Epoch 2848/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7849 - accuracy: 0.6563 - val_loss: 0.7582 - val_accuracy: 0.6550\n",
      "Epoch 2849/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7978 - accuracy: 0.6383 - val_loss: 0.7495 - val_accuracy: 0.6550\n",
      "Epoch 2850/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6477 - val_loss: 0.7412 - val_accuracy: 0.6750\n",
      "Epoch 2851/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7883 - accuracy: 0.6468 - val_loss: 0.7374 - val_accuracy: 0.6600\n",
      "Epoch 2852/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7798 - accuracy: 0.6572 - val_loss: 0.7312 - val_accuracy: 0.6550\n",
      "Epoch 2853/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6528 - val_loss: 0.7341 - val_accuracy: 0.6567\n",
      "Epoch 2854/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.6513 - val_loss: 0.7276 - val_accuracy: 0.6600\n",
      "Epoch 2855/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7795 - accuracy: 0.6525 - val_loss: 0.7329 - val_accuracy: 0.6583\n",
      "Epoch 2856/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7843 - accuracy: 0.6535 - val_loss: 0.7311 - val_accuracy: 0.6783\n",
      "Epoch 2857/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6493 - val_loss: 0.7331 - val_accuracy: 0.6717\n",
      "Epoch 2858/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6543 - val_loss: 0.7325 - val_accuracy: 0.6683\n",
      "Epoch 2859/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7669 - accuracy: 0.6550 - val_loss: 0.7352 - val_accuracy: 0.6750\n",
      "Epoch 2860/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7820 - accuracy: 0.6440 - val_loss: 0.7384 - val_accuracy: 0.6683\n",
      "Epoch 2861/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7801 - accuracy: 0.6518 - val_loss: 0.7369 - val_accuracy: 0.6750\n",
      "Epoch 2862/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7846 - accuracy: 0.6540 - val_loss: 0.7307 - val_accuracy: 0.6617\n",
      "Epoch 2863/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6568 - val_loss: 0.7283 - val_accuracy: 0.6433\n",
      "Epoch 2864/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7936 - accuracy: 0.6490 - val_loss: 0.7387 - val_accuracy: 0.6433\n",
      "Epoch 2865/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7900 - accuracy: 0.6512 - val_loss: 0.7303 - val_accuracy: 0.6500\n",
      "Epoch 2866/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7740 - accuracy: 0.6575 - val_loss: 0.7312 - val_accuracy: 0.6533\n",
      "Epoch 2867/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.8023 - accuracy: 0.6445 - val_loss: 0.7291 - val_accuracy: 0.6783\n",
      "Epoch 2868/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7820 - accuracy: 0.6470 - val_loss: 0.7257 - val_accuracy: 0.6733\n",
      "Epoch 2869/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6487 - val_loss: 0.7329 - val_accuracy: 0.6633\n",
      "Epoch 2870/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7850 - accuracy: 0.6597 - val_loss: 0.7387 - val_accuracy: 0.6567\n",
      "Epoch 2871/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6488 - val_loss: 0.7480 - val_accuracy: 0.6733\n",
      "Epoch 2872/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6567 - val_loss: 0.7492 - val_accuracy: 0.6667\n",
      "Epoch 2873/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7957 - accuracy: 0.6453 - val_loss: 0.7513 - val_accuracy: 0.6667\n",
      "Epoch 2874/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7982 - accuracy: 0.6502 - val_loss: 0.7502 - val_accuracy: 0.6500\n",
      "Epoch 2875/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7839 - accuracy: 0.6532 - val_loss: 0.7432 - val_accuracy: 0.6433\n",
      "Epoch 2876/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7868 - accuracy: 0.6462 - val_loss: 0.7401 - val_accuracy: 0.6650\n",
      "Epoch 2877/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7931 - accuracy: 0.6473 - val_loss: 0.7435 - val_accuracy: 0.6700\n",
      "Epoch 2878/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7839 - accuracy: 0.6577 - val_loss: 0.7384 - val_accuracy: 0.6900\n",
      "Epoch 2879/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7887 - accuracy: 0.6498 - val_loss: 0.7315 - val_accuracy: 0.6533\n",
      "Epoch 2880/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7883 - accuracy: 0.6495 - val_loss: 0.7412 - val_accuracy: 0.6550\n",
      "Epoch 2881/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7953 - accuracy: 0.6473 - val_loss: 0.7466 - val_accuracy: 0.6700\n",
      "Epoch 2882/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6458 - val_loss: 0.7486 - val_accuracy: 0.6700\n",
      "Epoch 2883/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7956 - accuracy: 0.6458 - val_loss: 0.7436 - val_accuracy: 0.6533\n",
      "Epoch 2884/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7878 - accuracy: 0.6458 - val_loss: 0.7399 - val_accuracy: 0.6683\n",
      "Epoch 2885/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6538 - val_loss: 0.7452 - val_accuracy: 0.6633\n",
      "Epoch 2886/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6420 - val_loss: 0.7349 - val_accuracy: 0.6600\n",
      "Epoch 2887/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7927 - accuracy: 0.6402 - val_loss: 0.7447 - val_accuracy: 0.6633\n",
      "Epoch 2888/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7778 - accuracy: 0.6557 - val_loss: 0.7397 - val_accuracy: 0.6933\n",
      "Epoch 2889/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7876 - accuracy: 0.6568 - val_loss: 0.7395 - val_accuracy: 0.6683\n",
      "Epoch 2890/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7969 - accuracy: 0.6485 - val_loss: 0.7462 - val_accuracy: 0.6683\n",
      "Epoch 2891/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.6528 - val_loss: 0.7350 - val_accuracy: 0.6550\n",
      "Epoch 2892/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7785 - accuracy: 0.6580 - val_loss: 0.7348 - val_accuracy: 0.6817\n",
      "Epoch 2893/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7871 - accuracy: 0.6557 - val_loss: 0.7386 - val_accuracy: 0.6633\n",
      "Epoch 2894/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6495 - val_loss: 0.7497 - val_accuracy: 0.6650\n",
      "Epoch 2895/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7878 - accuracy: 0.6563 - val_loss: 0.7400 - val_accuracy: 0.6833\n",
      "Epoch 2896/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7855 - accuracy: 0.6568 - val_loss: 0.7427 - val_accuracy: 0.6833\n",
      "Epoch 2897/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6525 - val_loss: 0.7394 - val_accuracy: 0.6767\n",
      "Epoch 2898/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7929 - accuracy: 0.6498 - val_loss: 0.7344 - val_accuracy: 0.6650\n",
      "Epoch 2899/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7825 - accuracy: 0.6437 - val_loss: 0.7501 - val_accuracy: 0.6483\n",
      "Epoch 2900/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7951 - accuracy: 0.6442 - val_loss: 0.7552 - val_accuracy: 0.6683\n",
      "Epoch 2901/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.6515 - val_loss: 0.7379 - val_accuracy: 0.6817\n",
      "Epoch 2902/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.6513 - val_loss: 0.7385 - val_accuracy: 0.6867\n",
      "Epoch 2903/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7888 - accuracy: 0.6570 - val_loss: 0.7411 - val_accuracy: 0.7167\n",
      "Epoch 2904/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7770 - accuracy: 0.6522 - val_loss: 0.7392 - val_accuracy: 0.6783\n",
      "Epoch 2905/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7839 - accuracy: 0.6415 - val_loss: 0.7388 - val_accuracy: 0.7067\n",
      "Epoch 2906/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7843 - accuracy: 0.6635 - val_loss: 0.7435 - val_accuracy: 0.6850\n",
      "Epoch 2907/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7733 - accuracy: 0.6552 - val_loss: 0.7377 - val_accuracy: 0.6567\n",
      "Epoch 2908/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6563 - val_loss: 0.7369 - val_accuracy: 0.6650\n",
      "Epoch 2909/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8049 - accuracy: 0.6552 - val_loss: 0.7400 - val_accuracy: 0.6767\n",
      "Epoch 2910/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.6605 - val_loss: 0.7394 - val_accuracy: 0.6650\n",
      "Epoch 2911/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6633 - val_loss: 0.7400 - val_accuracy: 0.7033\n",
      "Epoch 2912/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7784 - accuracy: 0.6545 - val_loss: 0.7366 - val_accuracy: 0.6400\n",
      "Epoch 2913/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7922 - accuracy: 0.6550 - val_loss: 0.7353 - val_accuracy: 0.7017\n",
      "Epoch 2914/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6645 - val_loss: 0.7372 - val_accuracy: 0.6817\n",
      "Epoch 2915/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7734 - accuracy: 0.6585 - val_loss: 0.7422 - val_accuracy: 0.6817\n",
      "Epoch 2916/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6588 - val_loss: 0.7461 - val_accuracy: 0.6750\n",
      "Epoch 2917/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7738 - accuracy: 0.6615 - val_loss: 0.7343 - val_accuracy: 0.6650\n",
      "Epoch 2918/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7804 - accuracy: 0.6557 - val_loss: 0.7328 - val_accuracy: 0.6733\n",
      "Epoch 2919/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6548 - val_loss: 0.7373 - val_accuracy: 0.6733\n",
      "Epoch 2920/5000\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.7813 - accuracy: 0.6590 - val_loss: 0.7421 - val_accuracy: 0.7267\n",
      "Epoch 2921/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7933 - accuracy: 0.6563 - val_loss: 0.7413 - val_accuracy: 0.6617\n",
      "Epoch 2922/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6472 - val_loss: 0.7407 - val_accuracy: 0.6633\n",
      "Epoch 2923/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6565 - val_loss: 0.7377 - val_accuracy: 0.6567\n",
      "Epoch 2924/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.6378 - val_loss: 0.7347 - val_accuracy: 0.6783\n",
      "Epoch 2925/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7837 - accuracy: 0.6492 - val_loss: 0.7384 - val_accuracy: 0.6867\n",
      "Epoch 2926/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7698 - accuracy: 0.6503 - val_loss: 0.7424 - val_accuracy: 0.6917\n",
      "Epoch 2927/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6588 - val_loss: 0.7337 - val_accuracy: 0.6717\n",
      "Epoch 2928/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.6475 - val_loss: 0.7299 - val_accuracy: 0.6600\n",
      "Epoch 2929/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.6495 - val_loss: 0.7343 - val_accuracy: 0.6600\n",
      "Epoch 2930/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7833 - accuracy: 0.6543 - val_loss: 0.7361 - val_accuracy: 0.6483\n",
      "Epoch 2931/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7796 - accuracy: 0.6507 - val_loss: 0.7398 - val_accuracy: 0.6550\n",
      "Epoch 2932/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7665 - accuracy: 0.6528 - val_loss: 0.7395 - val_accuracy: 0.6650\n",
      "Epoch 2933/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7902 - accuracy: 0.6503 - val_loss: 0.7452 - val_accuracy: 0.6600\n",
      "Epoch 2934/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7856 - accuracy: 0.6437 - val_loss: 0.7463 - val_accuracy: 0.6550\n",
      "Epoch 2935/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7943 - accuracy: 0.6477 - val_loss: 0.7416 - val_accuracy: 0.6550\n",
      "Epoch 2936/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7873 - accuracy: 0.6498 - val_loss: 0.7453 - val_accuracy: 0.6583\n",
      "Epoch 2937/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7908 - accuracy: 0.6480 - val_loss: 0.7443 - val_accuracy: 0.6450\n",
      "Epoch 2938/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7765 - accuracy: 0.6563 - val_loss: 0.7403 - val_accuracy: 0.6633\n",
      "Epoch 2939/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6437 - val_loss: 0.7453 - val_accuracy: 0.6600\n",
      "Epoch 2940/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.6600 - val_loss: 0.7414 - val_accuracy: 0.6650\n",
      "Epoch 2941/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6488 - val_loss: 0.7368 - val_accuracy: 0.6633\n",
      "Epoch 2942/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7856 - accuracy: 0.6552 - val_loss: 0.7330 - val_accuracy: 0.6700\n",
      "Epoch 2943/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7901 - accuracy: 0.6557 - val_loss: 0.7296 - val_accuracy: 0.6750\n",
      "Epoch 2944/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6550 - val_loss: 0.7338 - val_accuracy: 0.6683\n",
      "Epoch 2945/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.6452 - val_loss: 0.7327 - val_accuracy: 0.6817\n",
      "Epoch 2946/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7594 - accuracy: 0.6455 - val_loss: 0.7335 - val_accuracy: 0.6700\n",
      "Epoch 2947/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7676 - accuracy: 0.6472 - val_loss: 0.7314 - val_accuracy: 0.6717\n",
      "Epoch 2948/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7732 - accuracy: 0.6543 - val_loss: 0.7392 - val_accuracy: 0.6750\n",
      "Epoch 2949/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7885 - accuracy: 0.6457 - val_loss: 0.7419 - val_accuracy: 0.6667\n",
      "Epoch 2950/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6520 - val_loss: 0.7323 - val_accuracy: 0.6783\n",
      "Epoch 2951/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7807 - accuracy: 0.6548 - val_loss: 0.7326 - val_accuracy: 0.6467\n",
      "Epoch 2952/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6437 - val_loss: 0.7401 - val_accuracy: 0.6450\n",
      "Epoch 2953/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7771 - accuracy: 0.6587 - val_loss: 0.7360 - val_accuracy: 0.6400\n",
      "Epoch 2954/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7865 - accuracy: 0.6498 - val_loss: 0.7344 - val_accuracy: 0.6467\n",
      "Epoch 2955/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7954 - accuracy: 0.6470 - val_loss: 0.7338 - val_accuracy: 0.6467\n",
      "Epoch 2956/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6468 - val_loss: 0.7373 - val_accuracy: 0.6667\n",
      "Epoch 2957/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7849 - accuracy: 0.6523 - val_loss: 0.7370 - val_accuracy: 0.6467\n",
      "Epoch 2958/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.6600 - val_loss: 0.7371 - val_accuracy: 0.6567\n",
      "Epoch 2959/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7873 - accuracy: 0.6515 - val_loss: 0.7516 - val_accuracy: 0.6533\n",
      "Epoch 2960/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7912 - accuracy: 0.6462 - val_loss: 0.7423 - val_accuracy: 0.6367\n",
      "Epoch 2961/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7973 - accuracy: 0.6450 - val_loss: 0.7513 - val_accuracy: 0.6417\n",
      "Epoch 2962/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7956 - accuracy: 0.6512 - val_loss: 0.7601 - val_accuracy: 0.6500\n",
      "Epoch 2963/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7875 - accuracy: 0.6592 - val_loss: 0.7498 - val_accuracy: 0.6517\n",
      "Epoch 2964/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7825 - accuracy: 0.6583 - val_loss: 0.7498 - val_accuracy: 0.6317\n",
      "Epoch 2965/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7967 - accuracy: 0.6598 - val_loss: 0.7456 - val_accuracy: 0.6367\n",
      "Epoch 2966/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6478 - val_loss: 0.7515 - val_accuracy: 0.6433\n",
      "Epoch 2967/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7838 - accuracy: 0.6552 - val_loss: 0.7487 - val_accuracy: 0.6500\n",
      "Epoch 2968/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6535 - val_loss: 0.7433 - val_accuracy: 0.6433\n",
      "Epoch 2969/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7845 - accuracy: 0.6573 - val_loss: 0.7410 - val_accuracy: 0.6300\n",
      "Epoch 2970/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7890 - accuracy: 0.6490 - val_loss: 0.7432 - val_accuracy: 0.6483\n",
      "Epoch 2971/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7791 - accuracy: 0.6705 - val_loss: 0.7404 - val_accuracy: 0.6450\n",
      "Epoch 2972/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6725 - val_loss: 0.7415 - val_accuracy: 0.6433\n",
      "Epoch 2973/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6545 - val_loss: 0.7392 - val_accuracy: 0.6433\n",
      "Epoch 2974/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6663 - val_loss: 0.7416 - val_accuracy: 0.6250\n",
      "Epoch 2975/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6442 - val_loss: 0.7387 - val_accuracy: 0.6417\n",
      "Epoch 2976/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7783 - accuracy: 0.6573 - val_loss: 0.7353 - val_accuracy: 0.6467\n",
      "Epoch 2977/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7685 - accuracy: 0.6585 - val_loss: 0.7428 - val_accuracy: 0.6400\n",
      "Epoch 2978/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6588 - val_loss: 0.7357 - val_accuracy: 0.6433\n",
      "Epoch 2979/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7818 - accuracy: 0.6613 - val_loss: 0.7467 - val_accuracy: 0.6500\n",
      "Epoch 2980/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7892 - accuracy: 0.6577 - val_loss: 0.7486 - val_accuracy: 0.6367\n",
      "Epoch 2981/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6508 - val_loss: 0.7421 - val_accuracy: 0.6450\n",
      "Epoch 2982/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7937 - accuracy: 0.6475 - val_loss: 0.7462 - val_accuracy: 0.6633\n",
      "Epoch 2983/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6565 - val_loss: 0.7442 - val_accuracy: 0.6517\n",
      "Epoch 2984/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7805 - accuracy: 0.6663 - val_loss: 0.7341 - val_accuracy: 0.6600\n",
      "Epoch 2985/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6603 - val_loss: 0.7431 - val_accuracy: 0.6733\n",
      "Epoch 2986/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7766 - accuracy: 0.6553 - val_loss: 0.7431 - val_accuracy: 0.6533\n",
      "Epoch 2987/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6498 - val_loss: 0.7361 - val_accuracy: 0.6767\n",
      "Epoch 2988/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7881 - accuracy: 0.6482 - val_loss: 0.7406 - val_accuracy: 0.6733\n",
      "Epoch 2989/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6473 - val_loss: 0.7361 - val_accuracy: 0.6633\n",
      "Epoch 2990/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8030 - accuracy: 0.6522 - val_loss: 0.7335 - val_accuracy: 0.6583\n",
      "Epoch 2991/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.6502 - val_loss: 0.7331 - val_accuracy: 0.6667\n",
      "Epoch 2992/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8006 - accuracy: 0.6535 - val_loss: 0.7338 - val_accuracy: 0.6567\n",
      "Epoch 2993/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7881 - accuracy: 0.6528 - val_loss: 0.7291 - val_accuracy: 0.6950\n",
      "Epoch 2994/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7848 - accuracy: 0.6547 - val_loss: 0.7304 - val_accuracy: 0.6617\n",
      "Epoch 2995/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7904 - accuracy: 0.6520 - val_loss: 0.7201 - val_accuracy: 0.6683\n",
      "Epoch 2996/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6483 - val_loss: 0.7263 - val_accuracy: 0.6733\n",
      "Epoch 2997/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6438 - val_loss: 0.7282 - val_accuracy: 0.6517\n",
      "Epoch 2998/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7713 - accuracy: 0.6558 - val_loss: 0.7268 - val_accuracy: 0.6450\n",
      "Epoch 2999/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7753 - accuracy: 0.6492 - val_loss: 0.7296 - val_accuracy: 0.6533\n",
      "Epoch 3000/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7728 - accuracy: 0.6635 - val_loss: 0.7275 - val_accuracy: 0.6333\n",
      "Epoch 3001/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7724 - accuracy: 0.6563 - val_loss: 0.7447 - val_accuracy: 0.6717\n",
      "Epoch 3002/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7799 - accuracy: 0.6557 - val_loss: 0.7264 - val_accuracy: 0.6667\n",
      "Epoch 3003/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7863 - accuracy: 0.6550 - val_loss: 0.7274 - val_accuracy: 0.6750\n",
      "Epoch 3004/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6573 - val_loss: 0.7434 - val_accuracy: 0.6483\n",
      "Epoch 3005/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6530 - val_loss: 0.7365 - val_accuracy: 0.6500\n",
      "Epoch 3006/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7891 - accuracy: 0.6478 - val_loss: 0.7389 - val_accuracy: 0.6433\n",
      "Epoch 3007/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7909 - accuracy: 0.6593 - val_loss: 0.7396 - val_accuracy: 0.6517\n",
      "Epoch 3008/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6550 - val_loss: 0.7228 - val_accuracy: 0.6400\n",
      "Epoch 3009/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7904 - accuracy: 0.6517 - val_loss: 0.7234 - val_accuracy: 0.6517\n",
      "Epoch 3010/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7857 - accuracy: 0.6632 - val_loss: 0.7205 - val_accuracy: 0.6600\n",
      "Epoch 3011/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7905 - accuracy: 0.6532 - val_loss: 0.7243 - val_accuracy: 0.6650\n",
      "Epoch 3012/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7903 - accuracy: 0.6405 - val_loss: 0.7249 - val_accuracy: 0.6467\n",
      "Epoch 3013/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7805 - accuracy: 0.6457 - val_loss: 0.7202 - val_accuracy: 0.6517\n",
      "Epoch 3014/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7963 - accuracy: 0.6528 - val_loss: 0.7261 - val_accuracy: 0.6633\n",
      "Epoch 3015/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7776 - accuracy: 0.6548 - val_loss: 0.7312 - val_accuracy: 0.6750\n",
      "Epoch 3016/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7972 - accuracy: 0.6475 - val_loss: 0.7339 - val_accuracy: 0.6867\n",
      "Epoch 3017/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7859 - accuracy: 0.6602 - val_loss: 0.7300 - val_accuracy: 0.6717\n",
      "Epoch 3018/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7901 - accuracy: 0.6655 - val_loss: 0.7342 - val_accuracy: 0.6683\n",
      "Epoch 3019/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7909 - accuracy: 0.6592 - val_loss: 0.7417 - val_accuracy: 0.6617\n",
      "Epoch 3020/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7912 - accuracy: 0.6487 - val_loss: 0.7499 - val_accuracy: 0.6683\n",
      "Epoch 3021/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6453 - val_loss: 0.7402 - val_accuracy: 0.6767\n",
      "Epoch 3022/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7801 - accuracy: 0.6552 - val_loss: 0.7492 - val_accuracy: 0.6433\n",
      "Epoch 3023/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6508 - val_loss: 0.7538 - val_accuracy: 0.6583\n",
      "Epoch 3024/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7852 - accuracy: 0.6478 - val_loss: 0.7377 - val_accuracy: 0.6617\n",
      "Epoch 3025/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6487 - val_loss: 0.7437 - val_accuracy: 0.6617\n",
      "Epoch 3026/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7913 - accuracy: 0.6510 - val_loss: 0.7416 - val_accuracy: 0.6633\n",
      "Epoch 3027/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7921 - accuracy: 0.6468 - val_loss: 0.7456 - val_accuracy: 0.6700\n",
      "Epoch 3028/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7955 - accuracy: 0.6565 - val_loss: 0.7505 - val_accuracy: 0.6600\n",
      "Epoch 3029/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7797 - accuracy: 0.6565 - val_loss: 0.7442 - val_accuracy: 0.6583\n",
      "Epoch 3030/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7746 - accuracy: 0.6550 - val_loss: 0.7420 - val_accuracy: 0.6717\n",
      "Epoch 3031/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7919 - accuracy: 0.6503 - val_loss: 0.7599 - val_accuracy: 0.6400\n",
      "Epoch 3032/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7807 - accuracy: 0.6455 - val_loss: 0.7485 - val_accuracy: 0.6217\n",
      "Epoch 3033/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.6517 - val_loss: 0.7567 - val_accuracy: 0.6250\n",
      "Epoch 3034/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7860 - accuracy: 0.6537 - val_loss: 0.7543 - val_accuracy: 0.6700\n",
      "Epoch 3035/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6608 - val_loss: 0.7430 - val_accuracy: 0.6600\n",
      "Epoch 3036/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7901 - accuracy: 0.6483 - val_loss: 0.7500 - val_accuracy: 0.6650\n",
      "Epoch 3037/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6547 - val_loss: 0.7404 - val_accuracy: 0.6633\n",
      "Epoch 3038/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7854 - accuracy: 0.6615 - val_loss: 0.7466 - val_accuracy: 0.6600\n",
      "Epoch 3039/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7775 - accuracy: 0.6573 - val_loss: 0.7399 - val_accuracy: 0.6433\n",
      "Epoch 3040/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.6560 - val_loss: 0.7507 - val_accuracy: 0.6567\n",
      "Epoch 3041/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6527 - val_loss: 0.7489 - val_accuracy: 0.6800\n",
      "Epoch 3042/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6527 - val_loss: 0.7483 - val_accuracy: 0.6650\n",
      "Epoch 3043/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6577 - val_loss: 0.7552 - val_accuracy: 0.6717\n",
      "Epoch 3044/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7956 - accuracy: 0.6518 - val_loss: 0.7711 - val_accuracy: 0.6700\n",
      "Epoch 3045/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7928 - accuracy: 0.6587 - val_loss: 0.7549 - val_accuracy: 0.6483\n",
      "Epoch 3046/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7835 - accuracy: 0.6552 - val_loss: 0.7598 - val_accuracy: 0.6650\n",
      "Epoch 3047/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6567 - val_loss: 0.7538 - val_accuracy: 0.6517\n",
      "Epoch 3048/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7820 - accuracy: 0.6557 - val_loss: 0.7594 - val_accuracy: 0.6583\n",
      "Epoch 3049/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7958 - accuracy: 0.6643 - val_loss: 0.7615 - val_accuracy: 0.6483\n",
      "Epoch 3050/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7877 - accuracy: 0.6508 - val_loss: 0.7551 - val_accuracy: 0.6300\n",
      "Epoch 3051/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7798 - accuracy: 0.6578 - val_loss: 0.7531 - val_accuracy: 0.6500\n",
      "Epoch 3052/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7773 - accuracy: 0.6532 - val_loss: 0.7442 - val_accuracy: 0.6650\n",
      "Epoch 3053/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7899 - accuracy: 0.6580 - val_loss: 0.7549 - val_accuracy: 0.6650\n",
      "Epoch 3054/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7798 - accuracy: 0.6538 - val_loss: 0.7502 - val_accuracy: 0.6617\n",
      "Epoch 3055/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7789 - accuracy: 0.6545 - val_loss: 0.7570 - val_accuracy: 0.6533\n",
      "Epoch 3056/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.6462 - val_loss: 0.7504 - val_accuracy: 0.6400\n",
      "Epoch 3057/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6620 - val_loss: 0.7501 - val_accuracy: 0.6567\n",
      "Epoch 3058/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7852 - accuracy: 0.6547 - val_loss: 0.7440 - val_accuracy: 0.6733\n",
      "Epoch 3059/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7793 - accuracy: 0.6572 - val_loss: 0.7469 - val_accuracy: 0.6550\n",
      "Epoch 3060/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6502 - val_loss: 0.7462 - val_accuracy: 0.6517\n",
      "Epoch 3061/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7728 - accuracy: 0.6618 - val_loss: 0.7452 - val_accuracy: 0.6633\n",
      "Epoch 3062/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7717 - accuracy: 0.6578 - val_loss: 0.7428 - val_accuracy: 0.6400\n",
      "Epoch 3063/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7842 - accuracy: 0.6498 - val_loss: 0.7534 - val_accuracy: 0.6650\n",
      "Epoch 3064/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7784 - accuracy: 0.6533 - val_loss: 0.7499 - val_accuracy: 0.6617\n",
      "Epoch 3065/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7875 - accuracy: 0.6520 - val_loss: 0.7404 - val_accuracy: 0.6650\n",
      "Epoch 3066/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6520 - val_loss: 0.7316 - val_accuracy: 0.6533\n",
      "Epoch 3067/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7742 - accuracy: 0.6625 - val_loss: 0.7398 - val_accuracy: 0.6650\n",
      "Epoch 3068/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7857 - accuracy: 0.6530 - val_loss: 0.7435 - val_accuracy: 0.6433\n",
      "Epoch 3069/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7754 - accuracy: 0.6428 - val_loss: 0.7358 - val_accuracy: 0.6500\n",
      "Epoch 3070/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6500 - val_loss: 0.7414 - val_accuracy: 0.6717\n",
      "Epoch 3071/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.6587 - val_loss: 0.7339 - val_accuracy: 0.6933\n",
      "Epoch 3072/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7893 - accuracy: 0.6642 - val_loss: 0.7315 - val_accuracy: 0.6483\n",
      "Epoch 3073/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6657 - val_loss: 0.7365 - val_accuracy: 0.7000\n",
      "Epoch 3074/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7816 - accuracy: 0.6615 - val_loss: 0.7367 - val_accuracy: 0.6617\n",
      "Epoch 3075/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7756 - accuracy: 0.6603 - val_loss: 0.7359 - val_accuracy: 0.6500\n",
      "Epoch 3076/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7926 - accuracy: 0.6547 - val_loss: 0.7268 - val_accuracy: 0.6350\n",
      "Epoch 3077/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6522 - val_loss: 0.7387 - val_accuracy: 0.6750\n",
      "Epoch 3078/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6527 - val_loss: 0.7406 - val_accuracy: 0.6750\n",
      "Epoch 3079/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7854 - accuracy: 0.6590 - val_loss: 0.7393 - val_accuracy: 0.6500\n",
      "Epoch 3080/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7935 - accuracy: 0.6588 - val_loss: 0.7315 - val_accuracy: 0.6467\n",
      "Epoch 3081/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7807 - accuracy: 0.6533 - val_loss: 0.7228 - val_accuracy: 0.6683\n",
      "Epoch 3082/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.6535 - val_loss: 0.7250 - val_accuracy: 0.6550\n",
      "Epoch 3083/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6503 - val_loss: 0.7267 - val_accuracy: 0.6450\n",
      "Epoch 3084/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.6600 - val_loss: 0.7382 - val_accuracy: 0.6483\n",
      "Epoch 3085/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6582 - val_loss: 0.7359 - val_accuracy: 0.6483\n",
      "Epoch 3086/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7858 - accuracy: 0.6647 - val_loss: 0.7527 - val_accuracy: 0.6800\n",
      "Epoch 3087/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.6712 - val_loss: 0.7335 - val_accuracy: 0.6417\n",
      "Epoch 3088/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6663 - val_loss: 0.7413 - val_accuracy: 0.6467\n",
      "Epoch 3089/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6562 - val_loss: 0.7299 - val_accuracy: 0.6650\n",
      "Epoch 3090/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7850 - accuracy: 0.6562 - val_loss: 0.7317 - val_accuracy: 0.6583\n",
      "Epoch 3091/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6472 - val_loss: 0.7329 - val_accuracy: 0.6633\n",
      "Epoch 3092/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7669 - accuracy: 0.6512 - val_loss: 0.7293 - val_accuracy: 0.6583\n",
      "Epoch 3093/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7920 - accuracy: 0.6505 - val_loss: 0.7467 - val_accuracy: 0.6617\n",
      "Epoch 3094/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6605 - val_loss: 0.7515 - val_accuracy: 0.6633\n",
      "Epoch 3095/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6588 - val_loss: 0.7441 - val_accuracy: 0.6483\n",
      "Epoch 3096/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7800 - accuracy: 0.6528 - val_loss: 0.7447 - val_accuracy: 0.6383\n",
      "Epoch 3097/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7796 - accuracy: 0.6583 - val_loss: 0.7423 - val_accuracy: 0.6317\n",
      "Epoch 3098/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6487 - val_loss: 0.7475 - val_accuracy: 0.6433\n",
      "Epoch 3099/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7869 - accuracy: 0.6487 - val_loss: 0.7513 - val_accuracy: 0.6333\n",
      "Epoch 3100/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7931 - accuracy: 0.6532 - val_loss: 0.7632 - val_accuracy: 0.6517\n",
      "Epoch 3101/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7784 - accuracy: 0.6682 - val_loss: 0.7556 - val_accuracy: 0.6433\n",
      "Epoch 3102/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7768 - accuracy: 0.6507 - val_loss: 0.7637 - val_accuracy: 0.6500\n",
      "Epoch 3103/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7790 - accuracy: 0.6565 - val_loss: 0.7563 - val_accuracy: 0.6467\n",
      "Epoch 3104/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6508 - val_loss: 0.7615 - val_accuracy: 0.6433\n",
      "Epoch 3105/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7977 - accuracy: 0.6505 - val_loss: 0.7502 - val_accuracy: 0.6517\n",
      "Epoch 3106/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7831 - accuracy: 0.6603 - val_loss: 0.7514 - val_accuracy: 0.6367\n",
      "Epoch 3107/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7958 - accuracy: 0.6493 - val_loss: 0.7603 - val_accuracy: 0.6750\n",
      "Epoch 3108/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8053 - accuracy: 0.6543 - val_loss: 0.7557 - val_accuracy: 0.6433\n",
      "Epoch 3109/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6553 - val_loss: 0.7550 - val_accuracy: 0.6317\n",
      "Epoch 3110/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7670 - accuracy: 0.6603 - val_loss: 0.7614 - val_accuracy: 0.6667\n",
      "Epoch 3111/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7732 - accuracy: 0.6475 - val_loss: 0.7539 - val_accuracy: 0.6450\n",
      "Epoch 3112/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7741 - accuracy: 0.6587 - val_loss: 0.7472 - val_accuracy: 0.6367\n",
      "Epoch 3113/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7966 - accuracy: 0.6457 - val_loss: 0.7612 - val_accuracy: 0.6283\n",
      "Epoch 3114/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7945 - accuracy: 0.6417 - val_loss: 0.7649 - val_accuracy: 0.6483\n",
      "Epoch 3115/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7889 - accuracy: 0.6535 - val_loss: 0.7525 - val_accuracy: 0.6467\n",
      "Epoch 3116/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7873 - accuracy: 0.6532 - val_loss: 0.7532 - val_accuracy: 0.6383\n",
      "Epoch 3117/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7714 - accuracy: 0.6542 - val_loss: 0.7463 - val_accuracy: 0.6367\n",
      "Epoch 3118/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7834 - accuracy: 0.6543 - val_loss: 0.7408 - val_accuracy: 0.6350\n",
      "Epoch 3119/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6535 - val_loss: 0.7458 - val_accuracy: 0.6467\n",
      "Epoch 3120/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7862 - accuracy: 0.6557 - val_loss: 0.7451 - val_accuracy: 0.6233\n",
      "Epoch 3121/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.6580 - val_loss: 0.7550 - val_accuracy: 0.6250\n",
      "Epoch 3122/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7793 - accuracy: 0.6540 - val_loss: 0.7569 - val_accuracy: 0.6333\n",
      "Epoch 3123/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7883 - accuracy: 0.6507 - val_loss: 0.7658 - val_accuracy: 0.6483\n",
      "Epoch 3124/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7776 - accuracy: 0.6540 - val_loss: 0.7550 - val_accuracy: 0.6400\n",
      "Epoch 3125/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7769 - accuracy: 0.6553 - val_loss: 0.7525 - val_accuracy: 0.6433\n",
      "Epoch 3126/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6593 - val_loss: 0.7548 - val_accuracy: 0.6450\n",
      "Epoch 3127/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7857 - accuracy: 0.6622 - val_loss: 0.7590 - val_accuracy: 0.6333\n",
      "Epoch 3128/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7689 - accuracy: 0.6595 - val_loss: 0.7592 - val_accuracy: 0.6150\n",
      "Epoch 3129/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7874 - accuracy: 0.6393 - val_loss: 0.7673 - val_accuracy: 0.6250\n",
      "Epoch 3130/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7807 - accuracy: 0.6452 - val_loss: 0.7588 - val_accuracy: 0.6300\n",
      "Epoch 3131/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7948 - accuracy: 0.6528 - val_loss: 0.7527 - val_accuracy: 0.6417\n",
      "Epoch 3132/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6547 - val_loss: 0.7520 - val_accuracy: 0.6383\n",
      "Epoch 3133/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.6578 - val_loss: 0.7466 - val_accuracy: 0.6483\n",
      "Epoch 3134/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7787 - accuracy: 0.6485 - val_loss: 0.7516 - val_accuracy: 0.6483\n",
      "Epoch 3135/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6622 - val_loss: 0.7405 - val_accuracy: 0.6450\n",
      "Epoch 3136/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7758 - accuracy: 0.6617 - val_loss: 0.7453 - val_accuracy: 0.6533\n",
      "Epoch 3137/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7881 - accuracy: 0.6545 - val_loss: 0.7480 - val_accuracy: 0.6367\n",
      "Epoch 3138/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7884 - accuracy: 0.6468 - val_loss: 0.7639 - val_accuracy: 0.6317\n",
      "Epoch 3139/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7917 - accuracy: 0.6492 - val_loss: 0.7480 - val_accuracy: 0.6467\n",
      "Epoch 3140/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7795 - accuracy: 0.6620 - val_loss: 0.7372 - val_accuracy: 0.6400\n",
      "Epoch 3141/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6553 - val_loss: 0.7379 - val_accuracy: 0.6500\n",
      "Epoch 3142/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.6642 - val_loss: 0.7442 - val_accuracy: 0.6383\n",
      "Epoch 3143/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7728 - accuracy: 0.6643 - val_loss: 0.7340 - val_accuracy: 0.6417\n",
      "Epoch 3144/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7575 - accuracy: 0.6530 - val_loss: 0.7384 - val_accuracy: 0.6883\n",
      "Epoch 3145/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7744 - accuracy: 0.6653 - val_loss: 0.7414 - val_accuracy: 0.6483\n",
      "Epoch 3146/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7850 - accuracy: 0.6653 - val_loss: 0.7413 - val_accuracy: 0.6617\n",
      "Epoch 3147/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7690 - accuracy: 0.6570 - val_loss: 0.7340 - val_accuracy: 0.6533\n",
      "Epoch 3148/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7791 - accuracy: 0.6532 - val_loss: 0.7378 - val_accuracy: 0.6567\n",
      "Epoch 3149/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7810 - accuracy: 0.6630 - val_loss: 0.7424 - val_accuracy: 0.6567\n",
      "Epoch 3150/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7773 - accuracy: 0.6665 - val_loss: 0.7466 - val_accuracy: 0.6500\n",
      "Epoch 3151/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7720 - accuracy: 0.6638 - val_loss: 0.7541 - val_accuracy: 0.6700\n",
      "Epoch 3152/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7837 - accuracy: 0.6643 - val_loss: 0.7499 - val_accuracy: 0.6567\n",
      "Epoch 3153/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7705 - accuracy: 0.6588 - val_loss: 0.7453 - val_accuracy: 0.6450\n",
      "Epoch 3154/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7758 - accuracy: 0.6632 - val_loss: 0.7479 - val_accuracy: 0.6417\n",
      "Epoch 3155/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6542 - val_loss: 0.7409 - val_accuracy: 0.6417\n",
      "Epoch 3156/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6557 - val_loss: 0.7440 - val_accuracy: 0.6783\n",
      "Epoch 3157/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7762 - accuracy: 0.6657 - val_loss: 0.7412 - val_accuracy: 0.7017\n",
      "Epoch 3158/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.6698 - val_loss: 0.7383 - val_accuracy: 0.6617\n",
      "Epoch 3159/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7752 - accuracy: 0.6645 - val_loss: 0.7334 - val_accuracy: 0.6483\n",
      "Epoch 3160/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7861 - accuracy: 0.6575 - val_loss: 0.7468 - val_accuracy: 0.6417\n",
      "Epoch 3161/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7793 - accuracy: 0.6567 - val_loss: 0.7466 - val_accuracy: 0.6567\n",
      "Epoch 3162/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7888 - accuracy: 0.6533 - val_loss: 0.7465 - val_accuracy: 0.6517\n",
      "Epoch 3163/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7927 - accuracy: 0.6537 - val_loss: 0.7623 - val_accuracy: 0.6283\n",
      "Epoch 3164/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7789 - accuracy: 0.6568 - val_loss: 0.7556 - val_accuracy: 0.6383\n",
      "Epoch 3165/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7753 - accuracy: 0.6545 - val_loss: 0.7567 - val_accuracy: 0.6367\n",
      "Epoch 3166/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7770 - accuracy: 0.6528 - val_loss: 0.7500 - val_accuracy: 0.6250\n",
      "Epoch 3167/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7826 - accuracy: 0.6552 - val_loss: 0.7463 - val_accuracy: 0.6333\n",
      "Epoch 3168/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7814 - accuracy: 0.6447 - val_loss: 0.7497 - val_accuracy: 0.6367\n",
      "Epoch 3169/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.6497 - val_loss: 0.7521 - val_accuracy: 0.6267\n",
      "Epoch 3170/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7915 - accuracy: 0.6565 - val_loss: 0.7580 - val_accuracy: 0.6300\n",
      "Epoch 3171/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7863 - accuracy: 0.6703 - val_loss: 0.7619 - val_accuracy: 0.6367\n",
      "Epoch 3172/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6555 - val_loss: 0.7571 - val_accuracy: 0.6417\n",
      "Epoch 3173/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6577 - val_loss: 0.7432 - val_accuracy: 0.6317\n",
      "Epoch 3174/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6570 - val_loss: 0.7502 - val_accuracy: 0.6317\n",
      "Epoch 3175/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6625 - val_loss: 0.7480 - val_accuracy: 0.6167\n",
      "Epoch 3176/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6615 - val_loss: 0.7562 - val_accuracy: 0.6283\n",
      "Epoch 3177/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7682 - accuracy: 0.6647 - val_loss: 0.7465 - val_accuracy: 0.6217\n",
      "Epoch 3178/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.6630 - val_loss: 0.7449 - val_accuracy: 0.6483\n",
      "Epoch 3179/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7758 - accuracy: 0.6682 - val_loss: 0.7459 - val_accuracy: 0.6367\n",
      "Epoch 3180/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6652 - val_loss: 0.7556 - val_accuracy: 0.6267\n",
      "Epoch 3181/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7864 - accuracy: 0.6560 - val_loss: 0.7469 - val_accuracy: 0.6400\n",
      "Epoch 3182/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7692 - accuracy: 0.6680 - val_loss: 0.7566 - val_accuracy: 0.6533\n",
      "Epoch 3183/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6668 - val_loss: 0.7575 - val_accuracy: 0.6417\n",
      "Epoch 3184/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7819 - accuracy: 0.6582 - val_loss: 0.7483 - val_accuracy: 0.6433\n",
      "Epoch 3185/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6560 - val_loss: 0.7465 - val_accuracy: 0.6533\n",
      "Epoch 3186/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7751 - accuracy: 0.6690 - val_loss: 0.7572 - val_accuracy: 0.6533\n",
      "Epoch 3187/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7864 - accuracy: 0.6572 - val_loss: 0.7519 - val_accuracy: 0.6383\n",
      "Epoch 3188/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7889 - accuracy: 0.6595 - val_loss: 0.7631 - val_accuracy: 0.6300\n",
      "Epoch 3189/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7795 - accuracy: 0.6737 - val_loss: 0.7546 - val_accuracy: 0.6383\n",
      "Epoch 3190/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6625 - val_loss: 0.7685 - val_accuracy: 0.6350\n",
      "Epoch 3191/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6637 - val_loss: 0.7576 - val_accuracy: 0.6600\n",
      "Epoch 3192/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7776 - accuracy: 0.6623 - val_loss: 0.7488 - val_accuracy: 0.6500\n",
      "Epoch 3193/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7855 - accuracy: 0.6677 - val_loss: 0.7482 - val_accuracy: 0.6550\n",
      "Epoch 3194/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7841 - accuracy: 0.6565 - val_loss: 0.7527 - val_accuracy: 0.6633\n",
      "Epoch 3195/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.6528 - val_loss: 0.7559 - val_accuracy: 0.6500\n",
      "Epoch 3196/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7848 - accuracy: 0.6538 - val_loss: 0.7546 - val_accuracy: 0.6217\n",
      "Epoch 3197/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7818 - accuracy: 0.6530 - val_loss: 0.7612 - val_accuracy: 0.6333\n",
      "Epoch 3198/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7939 - accuracy: 0.6607 - val_loss: 0.7606 - val_accuracy: 0.6483\n",
      "Epoch 3199/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7925 - accuracy: 0.6482 - val_loss: 0.7576 - val_accuracy: 0.6400\n",
      "Epoch 3200/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7997 - accuracy: 0.6478 - val_loss: 0.7634 - val_accuracy: 0.6450\n",
      "Epoch 3201/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7895 - accuracy: 0.6572 - val_loss: 0.7611 - val_accuracy: 0.6517\n",
      "Epoch 3202/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7865 - accuracy: 0.6567 - val_loss: 0.7569 - val_accuracy: 0.6450\n",
      "Epoch 3203/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.6492 - val_loss: 0.7516 - val_accuracy: 0.6467\n",
      "Epoch 3204/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7821 - accuracy: 0.6545 - val_loss: 0.7464 - val_accuracy: 0.6700\n",
      "Epoch 3205/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7676 - accuracy: 0.6725 - val_loss: 0.7479 - val_accuracy: 0.6433\n",
      "Epoch 3206/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7805 - accuracy: 0.6593 - val_loss: 0.7481 - val_accuracy: 0.6483\n",
      "Epoch 3207/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6542 - val_loss: 0.7524 - val_accuracy: 0.6517\n",
      "Epoch 3208/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6520 - val_loss: 0.7531 - val_accuracy: 0.6483\n",
      "Epoch 3209/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7841 - accuracy: 0.6643 - val_loss: 0.7604 - val_accuracy: 0.6467\n",
      "Epoch 3210/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6605 - val_loss: 0.7572 - val_accuracy: 0.6550\n",
      "Epoch 3211/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7855 - accuracy: 0.6602 - val_loss: 0.7590 - val_accuracy: 0.6300\n",
      "Epoch 3212/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7992 - accuracy: 0.6503 - val_loss: 0.7579 - val_accuracy: 0.6450\n",
      "Epoch 3213/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7782 - accuracy: 0.6612 - val_loss: 0.7431 - val_accuracy: 0.6417\n",
      "Epoch 3214/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7913 - accuracy: 0.6535 - val_loss: 0.7535 - val_accuracy: 0.6417\n",
      "Epoch 3215/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7931 - accuracy: 0.6453 - val_loss: 0.7376 - val_accuracy: 0.6367\n",
      "Epoch 3216/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7751 - accuracy: 0.6613 - val_loss: 0.7376 - val_accuracy: 0.6500\n",
      "Epoch 3217/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7714 - accuracy: 0.6628 - val_loss: 0.7491 - val_accuracy: 0.6650\n",
      "Epoch 3218/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.6572 - val_loss: 0.7459 - val_accuracy: 0.6367\n",
      "Epoch 3219/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7878 - accuracy: 0.6628 - val_loss: 0.7480 - val_accuracy: 0.6317\n",
      "Epoch 3220/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7718 - accuracy: 0.6650 - val_loss: 0.7556 - val_accuracy: 0.6550\n",
      "Epoch 3221/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.6527 - val_loss: 0.7371 - val_accuracy: 0.6367\n",
      "Epoch 3222/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6585 - val_loss: 0.7452 - val_accuracy: 0.6550\n",
      "Epoch 3223/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7852 - accuracy: 0.6562 - val_loss: 0.7487 - val_accuracy: 0.6233\n",
      "Epoch 3224/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7846 - accuracy: 0.6478 - val_loss: 0.7534 - val_accuracy: 0.6250\n",
      "Epoch 3225/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7859 - accuracy: 0.6538 - val_loss: 0.7519 - val_accuracy: 0.6200\n",
      "Epoch 3226/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7725 - accuracy: 0.6513 - val_loss: 0.7494 - val_accuracy: 0.6333\n",
      "Epoch 3227/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7917 - accuracy: 0.6523 - val_loss: 0.7562 - val_accuracy: 0.6300\n",
      "Epoch 3228/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.8003 - accuracy: 0.6488 - val_loss: 0.7599 - val_accuracy: 0.6283\n",
      "Epoch 3229/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6565 - val_loss: 0.7595 - val_accuracy: 0.6183\n",
      "Epoch 3230/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7748 - accuracy: 0.6523 - val_loss: 0.7575 - val_accuracy: 0.6483\n",
      "Epoch 3231/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7839 - accuracy: 0.6640 - val_loss: 0.7465 - val_accuracy: 0.6217\n",
      "Epoch 3232/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7818 - accuracy: 0.6618 - val_loss: 0.7464 - val_accuracy: 0.6333\n",
      "Epoch 3233/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7800 - accuracy: 0.6563 - val_loss: 0.7566 - val_accuracy: 0.6217\n",
      "Epoch 3234/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7788 - accuracy: 0.6548 - val_loss: 0.7648 - val_accuracy: 0.6200\n",
      "Epoch 3235/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7791 - accuracy: 0.6590 - val_loss: 0.7687 - val_accuracy: 0.6300\n",
      "Epoch 3236/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6562 - val_loss: 0.7534 - val_accuracy: 0.6233\n",
      "Epoch 3237/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.6562 - val_loss: 0.7553 - val_accuracy: 0.6583\n",
      "Epoch 3238/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7747 - accuracy: 0.6587 - val_loss: 0.7504 - val_accuracy: 0.6317\n",
      "Epoch 3239/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6623 - val_loss: 0.7527 - val_accuracy: 0.6283\n",
      "Epoch 3240/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6542 - val_loss: 0.7451 - val_accuracy: 0.6250\n",
      "Epoch 3241/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6522 - val_loss: 0.7561 - val_accuracy: 0.6300\n",
      "Epoch 3242/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6632 - val_loss: 0.7640 - val_accuracy: 0.6317\n",
      "Epoch 3243/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7754 - accuracy: 0.6517 - val_loss: 0.7619 - val_accuracy: 0.6200\n",
      "Epoch 3244/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7856 - accuracy: 0.6483 - val_loss: 0.7632 - val_accuracy: 0.6133\n",
      "Epoch 3245/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.6637 - val_loss: 0.7554 - val_accuracy: 0.6383\n",
      "Epoch 3246/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7743 - accuracy: 0.6565 - val_loss: 0.7509 - val_accuracy: 0.6367\n",
      "Epoch 3247/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7781 - accuracy: 0.6688 - val_loss: 0.7486 - val_accuracy: 0.6233\n",
      "Epoch 3248/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7771 - accuracy: 0.6545 - val_loss: 0.7446 - val_accuracy: 0.6250\n",
      "Epoch 3249/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7842 - accuracy: 0.6512 - val_loss: 0.7607 - val_accuracy: 0.6417\n",
      "Epoch 3250/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7896 - accuracy: 0.6617 - val_loss: 0.7615 - val_accuracy: 0.6267\n",
      "Epoch 3251/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7751 - accuracy: 0.6605 - val_loss: 0.7622 - val_accuracy: 0.6333\n",
      "Epoch 3252/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.6608 - val_loss: 0.7604 - val_accuracy: 0.6450\n",
      "Epoch 3253/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6680 - val_loss: 0.7633 - val_accuracy: 0.6367\n",
      "Epoch 3254/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7828 - accuracy: 0.6432 - val_loss: 0.7509 - val_accuracy: 0.6417\n",
      "Epoch 3255/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7779 - accuracy: 0.6610 - val_loss: 0.7501 - val_accuracy: 0.6317\n",
      "Epoch 3256/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6612 - val_loss: 0.7511 - val_accuracy: 0.6300\n",
      "Epoch 3257/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.6542 - val_loss: 0.7792 - val_accuracy: 0.6350\n",
      "Epoch 3258/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7837 - accuracy: 0.6517 - val_loss: 0.7641 - val_accuracy: 0.6000\n",
      "Epoch 3259/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7807 - accuracy: 0.6572 - val_loss: 0.7584 - val_accuracy: 0.6300\n",
      "Epoch 3260/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6517 - val_loss: 0.7571 - val_accuracy: 0.6417\n",
      "Epoch 3261/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7930 - accuracy: 0.6477 - val_loss: 0.7584 - val_accuracy: 0.6367\n",
      "Epoch 3262/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7902 - accuracy: 0.6498 - val_loss: 0.7513 - val_accuracy: 0.6433\n",
      "Epoch 3263/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7814 - accuracy: 0.6585 - val_loss: 0.7530 - val_accuracy: 0.6417\n",
      "Epoch 3264/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7820 - accuracy: 0.6625 - val_loss: 0.7429 - val_accuracy: 0.6350\n",
      "Epoch 3265/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7782 - accuracy: 0.6493 - val_loss: 0.7462 - val_accuracy: 0.6317\n",
      "Epoch 3266/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7805 - accuracy: 0.6578 - val_loss: 0.7465 - val_accuracy: 0.6367\n",
      "Epoch 3267/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7657 - accuracy: 0.6610 - val_loss: 0.7300 - val_accuracy: 0.6367\n",
      "Epoch 3268/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7740 - accuracy: 0.6587 - val_loss: 0.7329 - val_accuracy: 0.6217\n",
      "Epoch 3269/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7827 - accuracy: 0.6613 - val_loss: 0.7364 - val_accuracy: 0.6200\n",
      "Epoch 3270/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7697 - accuracy: 0.6588 - val_loss: 0.7346 - val_accuracy: 0.6350\n",
      "Epoch 3271/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7716 - accuracy: 0.6552 - val_loss: 0.7416 - val_accuracy: 0.6250\n",
      "Epoch 3272/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7795 - accuracy: 0.6578 - val_loss: 0.7452 - val_accuracy: 0.6400\n",
      "Epoch 3273/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6568 - val_loss: 0.7524 - val_accuracy: 0.6317\n",
      "Epoch 3274/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7681 - accuracy: 0.6497 - val_loss: 0.7572 - val_accuracy: 0.6267\n",
      "Epoch 3275/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7733 - accuracy: 0.6595 - val_loss: 0.7464 - val_accuracy: 0.6450\n",
      "Epoch 3276/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7658 - accuracy: 0.6788 - val_loss: 0.7466 - val_accuracy: 0.6400\n",
      "Epoch 3277/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7842 - accuracy: 0.6527 - val_loss: 0.7512 - val_accuracy: 0.6367\n",
      "Epoch 3278/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6527 - val_loss: 0.7629 - val_accuracy: 0.6350\n",
      "Epoch 3279/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7648 - accuracy: 0.6522 - val_loss: 0.7507 - val_accuracy: 0.6700\n",
      "Epoch 3280/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7821 - accuracy: 0.6643 - val_loss: 0.7354 - val_accuracy: 0.6483\n",
      "Epoch 3281/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7767 - accuracy: 0.6485 - val_loss: 0.7489 - val_accuracy: 0.6417\n",
      "Epoch 3282/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7841 - accuracy: 0.6618 - val_loss: 0.7508 - val_accuracy: 0.6450\n",
      "Epoch 3283/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7978 - accuracy: 0.6560 - val_loss: 0.7615 - val_accuracy: 0.6483\n",
      "Epoch 3284/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.6480 - val_loss: 0.7454 - val_accuracy: 0.6400\n",
      "Epoch 3285/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7849 - accuracy: 0.6552 - val_loss: 0.7635 - val_accuracy: 0.6617\n",
      "Epoch 3286/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7867 - accuracy: 0.6653 - val_loss: 0.7536 - val_accuracy: 0.6550\n",
      "Epoch 3287/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7897 - accuracy: 0.6650 - val_loss: 0.7610 - val_accuracy: 0.6517\n",
      "Epoch 3288/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7821 - accuracy: 0.6558 - val_loss: 0.7471 - val_accuracy: 0.6367\n",
      "Epoch 3289/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6542 - val_loss: 0.7458 - val_accuracy: 0.6350\n",
      "Epoch 3290/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7897 - accuracy: 0.6668 - val_loss: 0.7655 - val_accuracy: 0.6500\n",
      "Epoch 3291/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7899 - accuracy: 0.6598 - val_loss: 0.7695 - val_accuracy: 0.6467\n",
      "Epoch 3292/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7927 - accuracy: 0.6578 - val_loss: 0.7603 - val_accuracy: 0.6517\n",
      "Epoch 3293/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6683 - val_loss: 0.7568 - val_accuracy: 0.6600\n",
      "Epoch 3294/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6688 - val_loss: 0.7507 - val_accuracy: 0.6917\n",
      "Epoch 3295/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7805 - accuracy: 0.6602 - val_loss: 0.7558 - val_accuracy: 0.6317\n",
      "Epoch 3296/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7875 - accuracy: 0.6618 - val_loss: 0.7515 - val_accuracy: 0.6300\n",
      "Epoch 3297/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6462 - val_loss: 0.7486 - val_accuracy: 0.6267\n",
      "Epoch 3298/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7854 - accuracy: 0.6590 - val_loss: 0.7489 - val_accuracy: 0.6183\n",
      "Epoch 3299/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6608 - val_loss: 0.7558 - val_accuracy: 0.6417\n",
      "Epoch 3300/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7896 - accuracy: 0.6555 - val_loss: 0.7529 - val_accuracy: 0.6250\n",
      "Epoch 3301/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7914 - accuracy: 0.6528 - val_loss: 0.7431 - val_accuracy: 0.6433\n",
      "Epoch 3302/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7916 - accuracy: 0.6565 - val_loss: 0.7554 - val_accuracy: 0.6467\n",
      "Epoch 3303/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7909 - accuracy: 0.6527 - val_loss: 0.7596 - val_accuracy: 0.6600\n",
      "Epoch 3304/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7929 - accuracy: 0.6548 - val_loss: 0.7551 - val_accuracy: 0.6917\n",
      "Epoch 3305/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7821 - accuracy: 0.6632 - val_loss: 0.7434 - val_accuracy: 0.6567\n",
      "Epoch 3306/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.6625 - val_loss: 0.7487 - val_accuracy: 0.6450\n",
      "Epoch 3307/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6653 - val_loss: 0.7517 - val_accuracy: 0.6417\n",
      "Epoch 3308/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6642 - val_loss: 0.7593 - val_accuracy: 0.6233\n",
      "Epoch 3309/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6582 - val_loss: 0.7690 - val_accuracy: 0.6383\n",
      "Epoch 3310/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6613 - val_loss: 0.7557 - val_accuracy: 0.6400\n",
      "Epoch 3311/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7740 - accuracy: 0.6633 - val_loss: 0.7603 - val_accuracy: 0.6417\n",
      "Epoch 3312/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7927 - accuracy: 0.6523 - val_loss: 0.7559 - val_accuracy: 0.6417\n",
      "Epoch 3313/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7868 - accuracy: 0.6617 - val_loss: 0.7418 - val_accuracy: 0.6250\n",
      "Epoch 3314/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7915 - accuracy: 0.6608 - val_loss: 0.7366 - val_accuracy: 0.6317\n",
      "Epoch 3315/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6672 - val_loss: 0.7404 - val_accuracy: 0.6500\n",
      "Epoch 3316/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7931 - accuracy: 0.6622 - val_loss: 0.7559 - val_accuracy: 0.6200\n",
      "Epoch 3317/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7715 - accuracy: 0.6673 - val_loss: 0.7495 - val_accuracy: 0.6283\n",
      "Epoch 3318/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6698 - val_loss: 0.7534 - val_accuracy: 0.6483\n",
      "Epoch 3319/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7756 - accuracy: 0.6610 - val_loss: 0.7564 - val_accuracy: 0.6217\n",
      "Epoch 3320/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7806 - accuracy: 0.6662 - val_loss: 0.7591 - val_accuracy: 0.6433\n",
      "Epoch 3321/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7933 - accuracy: 0.6613 - val_loss: 0.7573 - val_accuracy: 0.6367\n",
      "Epoch 3322/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7871 - accuracy: 0.6637 - val_loss: 0.7631 - val_accuracy: 0.6300\n",
      "Epoch 3323/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6577 - val_loss: 0.7626 - val_accuracy: 0.6417\n",
      "Epoch 3324/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6522 - val_loss: 0.7671 - val_accuracy: 0.6317\n",
      "Epoch 3325/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7867 - accuracy: 0.6597 - val_loss: 0.7554 - val_accuracy: 0.6233\n",
      "Epoch 3326/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7682 - accuracy: 0.6725 - val_loss: 0.7578 - val_accuracy: 0.6333\n",
      "Epoch 3327/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7896 - accuracy: 0.6647 - val_loss: 0.7694 - val_accuracy: 0.6217\n",
      "Epoch 3328/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7775 - accuracy: 0.6645 - val_loss: 0.7708 - val_accuracy: 0.6350\n",
      "Epoch 3329/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6655 - val_loss: 0.7707 - val_accuracy: 0.6300\n",
      "Epoch 3330/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7875 - accuracy: 0.6567 - val_loss: 0.7699 - val_accuracy: 0.6633\n",
      "Epoch 3331/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7705 - accuracy: 0.6773 - val_loss: 0.7691 - val_accuracy: 0.6767\n",
      "Epoch 3332/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7706 - accuracy: 0.6560 - val_loss: 0.7646 - val_accuracy: 0.6467\n",
      "Epoch 3333/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7766 - accuracy: 0.6572 - val_loss: 0.7625 - val_accuracy: 0.6650\n",
      "Epoch 3334/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6627 - val_loss: 0.7583 - val_accuracy: 0.6233\n",
      "Epoch 3335/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.6750 - val_loss: 0.7495 - val_accuracy: 0.6400\n",
      "Epoch 3336/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6585 - val_loss: 0.7558 - val_accuracy: 0.6400\n",
      "Epoch 3337/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7791 - accuracy: 0.6688 - val_loss: 0.7533 - val_accuracy: 0.6350\n",
      "Epoch 3338/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7947 - accuracy: 0.6717 - val_loss: 0.7593 - val_accuracy: 0.6633\n",
      "Epoch 3339/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7897 - accuracy: 0.6665 - val_loss: 0.7620 - val_accuracy: 0.6383\n",
      "Epoch 3340/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7826 - accuracy: 0.6653 - val_loss: 0.7629 - val_accuracy: 0.6283\n",
      "Epoch 3341/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7802 - accuracy: 0.6710 - val_loss: 0.7616 - val_accuracy: 0.6433\n",
      "Epoch 3342/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6550 - val_loss: 0.7564 - val_accuracy: 0.6383\n",
      "Epoch 3343/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7702 - accuracy: 0.6718 - val_loss: 0.7510 - val_accuracy: 0.6350\n",
      "Epoch 3344/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7772 - accuracy: 0.6702 - val_loss: 0.7476 - val_accuracy: 0.6450\n",
      "Epoch 3345/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7790 - accuracy: 0.6710 - val_loss: 0.7469 - val_accuracy: 0.6350\n",
      "Epoch 3346/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.6750 - val_loss: 0.7532 - val_accuracy: 0.6367\n",
      "Epoch 3347/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6685 - val_loss: 0.7630 - val_accuracy: 0.6783\n",
      "Epoch 3348/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6735 - val_loss: 0.7618 - val_accuracy: 0.6733\n",
      "Epoch 3349/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7768 - accuracy: 0.6662 - val_loss: 0.7554 - val_accuracy: 0.6717\n",
      "Epoch 3350/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7819 - accuracy: 0.6722 - val_loss: 0.7517 - val_accuracy: 0.6533\n",
      "Epoch 3351/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7694 - accuracy: 0.6753 - val_loss: 0.7445 - val_accuracy: 0.6583\n",
      "Epoch 3352/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7788 - accuracy: 0.6513 - val_loss: 0.7446 - val_accuracy: 0.6383\n",
      "Epoch 3353/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6562 - val_loss: 0.7637 - val_accuracy: 0.6450\n",
      "Epoch 3354/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6688 - val_loss: 0.7567 - val_accuracy: 0.6500\n",
      "Epoch 3355/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7911 - accuracy: 0.6695 - val_loss: 0.7620 - val_accuracy: 0.6750\n",
      "Epoch 3356/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7888 - accuracy: 0.6543 - val_loss: 0.7568 - val_accuracy: 0.6483\n",
      "Epoch 3357/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7929 - accuracy: 0.6552 - val_loss: 0.7558 - val_accuracy: 0.6533\n",
      "Epoch 3358/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6755 - val_loss: 0.7502 - val_accuracy: 0.7150\n",
      "Epoch 3359/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7701 - accuracy: 0.6828 - val_loss: 0.7475 - val_accuracy: 0.6350\n",
      "Epoch 3360/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6625 - val_loss: 0.7522 - val_accuracy: 0.6450\n",
      "Epoch 3361/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7799 - accuracy: 0.6548 - val_loss: 0.7424 - val_accuracy: 0.6417\n",
      "Epoch 3362/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7716 - accuracy: 0.6693 - val_loss: 0.7482 - val_accuracy: 0.6617\n",
      "Epoch 3363/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7670 - accuracy: 0.6723 - val_loss: 0.7533 - val_accuracy: 0.6833\n",
      "Epoch 3364/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6703 - val_loss: 0.7627 - val_accuracy: 0.6583\n",
      "Epoch 3365/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6760 - val_loss: 0.7570 - val_accuracy: 0.6700\n",
      "Epoch 3366/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7838 - accuracy: 0.6627 - val_loss: 0.7604 - val_accuracy: 0.6417\n",
      "Epoch 3367/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7745 - accuracy: 0.6588 - val_loss: 0.7546 - val_accuracy: 0.6317\n",
      "Epoch 3368/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7796 - accuracy: 0.6678 - val_loss: 0.7401 - val_accuracy: 0.6450\n",
      "Epoch 3369/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7816 - accuracy: 0.6673 - val_loss: 0.7526 - val_accuracy: 0.6517\n",
      "Epoch 3370/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7750 - accuracy: 0.6573 - val_loss: 0.7480 - val_accuracy: 0.6533\n",
      "Epoch 3371/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7818 - accuracy: 0.6645 - val_loss: 0.7558 - val_accuracy: 0.6767\n",
      "Epoch 3372/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7859 - accuracy: 0.6622 - val_loss: 0.7398 - val_accuracy: 0.6467\n",
      "Epoch 3373/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7731 - accuracy: 0.6595 - val_loss: 0.7334 - val_accuracy: 0.6317\n",
      "Epoch 3374/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7769 - accuracy: 0.6728 - val_loss: 0.7457 - val_accuracy: 0.6583\n",
      "Epoch 3375/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7741 - accuracy: 0.6680 - val_loss: 0.7552 - val_accuracy: 0.6567\n",
      "Epoch 3376/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6700 - val_loss: 0.7456 - val_accuracy: 0.6267\n",
      "Epoch 3377/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6657 - val_loss: 0.7484 - val_accuracy: 0.6833\n",
      "Epoch 3378/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.6752 - val_loss: 0.7590 - val_accuracy: 0.6517\n",
      "Epoch 3379/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7801 - accuracy: 0.6557 - val_loss: 0.7565 - val_accuracy: 0.6350\n",
      "Epoch 3380/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7839 - accuracy: 0.6682 - val_loss: 0.7416 - val_accuracy: 0.6383\n",
      "Epoch 3381/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7930 - accuracy: 0.6595 - val_loss: 0.7443 - val_accuracy: 0.6483\n",
      "Epoch 3382/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7849 - accuracy: 0.6667 - val_loss: 0.7445 - val_accuracy: 0.6583\n",
      "Epoch 3383/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7942 - accuracy: 0.6627 - val_loss: 0.7421 - val_accuracy: 0.6683\n",
      "Epoch 3384/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7916 - accuracy: 0.6652 - val_loss: 0.7520 - val_accuracy: 0.6583\n",
      "Epoch 3385/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7964 - accuracy: 0.6633 - val_loss: 0.7497 - val_accuracy: 0.6550\n",
      "Epoch 3386/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7868 - accuracy: 0.6665 - val_loss: 0.7361 - val_accuracy: 0.6383\n",
      "Epoch 3387/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7776 - accuracy: 0.6657 - val_loss: 0.7374 - val_accuracy: 0.6633\n",
      "Epoch 3388/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7690 - accuracy: 0.6732 - val_loss: 0.7393 - val_accuracy: 0.6467\n",
      "Epoch 3389/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7857 - accuracy: 0.6645 - val_loss: 0.7319 - val_accuracy: 0.6817\n",
      "Epoch 3390/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6692 - val_loss: 0.7249 - val_accuracy: 0.6800\n",
      "Epoch 3391/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7780 - accuracy: 0.6665 - val_loss: 0.7338 - val_accuracy: 0.6767\n",
      "Epoch 3392/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7728 - accuracy: 0.6697 - val_loss: 0.7473 - val_accuracy: 0.6700\n",
      "Epoch 3393/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7872 - accuracy: 0.6630 - val_loss: 0.7467 - val_accuracy: 0.6700\n",
      "Epoch 3394/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6712 - val_loss: 0.7492 - val_accuracy: 0.6683\n",
      "Epoch 3395/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7946 - accuracy: 0.6592 - val_loss: 0.7468 - val_accuracy: 0.6767\n",
      "Epoch 3396/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.6765 - val_loss: 0.7467 - val_accuracy: 0.6400\n",
      "Epoch 3397/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7714 - accuracy: 0.6742 - val_loss: 0.7534 - val_accuracy: 0.6667\n",
      "Epoch 3398/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7844 - accuracy: 0.6628 - val_loss: 0.7464 - val_accuracy: 0.6900\n",
      "Epoch 3399/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7667 - accuracy: 0.6818 - val_loss: 0.7475 - val_accuracy: 0.6833\n",
      "Epoch 3400/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6785 - val_loss: 0.7466 - val_accuracy: 0.6700\n",
      "Epoch 3401/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7869 - accuracy: 0.6618 - val_loss: 0.7389 - val_accuracy: 0.6650\n",
      "Epoch 3402/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7752 - accuracy: 0.6687 - val_loss: 0.7376 - val_accuracy: 0.6683\n",
      "Epoch 3403/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7743 - accuracy: 0.6680 - val_loss: 0.7356 - val_accuracy: 0.6600\n",
      "Epoch 3404/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7844 - accuracy: 0.6752 - val_loss: 0.7461 - val_accuracy: 0.6633\n",
      "Epoch 3405/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7820 - accuracy: 0.6745 - val_loss: 0.7558 - val_accuracy: 0.6800\n",
      "Epoch 3406/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7736 - accuracy: 0.6535 - val_loss: 0.7414 - val_accuracy: 0.6483\n",
      "Epoch 3407/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6675 - val_loss: 0.7454 - val_accuracy: 0.6467\n",
      "Epoch 3408/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7957 - accuracy: 0.6592 - val_loss: 0.7494 - val_accuracy: 0.6667\n",
      "Epoch 3409/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.6660 - val_loss: 0.7346 - val_accuracy: 0.6633\n",
      "Epoch 3410/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7965 - accuracy: 0.6628 - val_loss: 0.7467 - val_accuracy: 0.6467\n",
      "Epoch 3411/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7762 - accuracy: 0.6735 - val_loss: 0.7459 - val_accuracy: 0.6467\n",
      "Epoch 3412/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6732 - val_loss: 0.7423 - val_accuracy: 0.7100\n",
      "Epoch 3413/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7738 - accuracy: 0.6712 - val_loss: 0.7466 - val_accuracy: 0.6333\n",
      "Epoch 3414/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7813 - accuracy: 0.6663 - val_loss: 0.7520 - val_accuracy: 0.6533\n",
      "Epoch 3415/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6790 - val_loss: 0.7401 - val_accuracy: 0.6883\n",
      "Epoch 3416/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7770 - accuracy: 0.6693 - val_loss: 0.7450 - val_accuracy: 0.6717\n",
      "Epoch 3417/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7854 - accuracy: 0.6698 - val_loss: 0.7413 - val_accuracy: 0.6650\n",
      "Epoch 3418/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7938 - accuracy: 0.6645 - val_loss: 0.7422 - val_accuracy: 0.6750\n",
      "Epoch 3419/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8015 - accuracy: 0.6775 - val_loss: 0.7608 - val_accuracy: 0.6467\n",
      "Epoch 3420/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7895 - accuracy: 0.6682 - val_loss: 0.7468 - val_accuracy: 0.6583\n",
      "Epoch 3421/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7785 - accuracy: 0.6687 - val_loss: 0.7421 - val_accuracy: 0.6883\n",
      "Epoch 3422/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6575 - val_loss: 0.7394 - val_accuracy: 0.6633\n",
      "Epoch 3423/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7776 - accuracy: 0.6720 - val_loss: 0.7335 - val_accuracy: 0.6450\n",
      "Epoch 3424/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7844 - accuracy: 0.6587 - val_loss: 0.7360 - val_accuracy: 0.6583\n",
      "Epoch 3425/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7827 - accuracy: 0.6728 - val_loss: 0.7394 - val_accuracy: 0.6367\n",
      "Epoch 3426/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7937 - accuracy: 0.6605 - val_loss: 0.7504 - val_accuracy: 0.6383\n",
      "Epoch 3427/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7878 - accuracy: 0.6585 - val_loss: 0.7399 - val_accuracy: 0.6467\n",
      "Epoch 3428/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7861 - accuracy: 0.6828 - val_loss: 0.7429 - val_accuracy: 0.6833\n",
      "Epoch 3429/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7737 - accuracy: 0.6732 - val_loss: 0.7413 - val_accuracy: 0.6433\n",
      "Epoch 3430/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7901 - accuracy: 0.6787 - val_loss: 0.7347 - val_accuracy: 0.6400\n",
      "Epoch 3431/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7742 - accuracy: 0.6695 - val_loss: 0.7434 - val_accuracy: 0.6617\n",
      "Epoch 3432/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7852 - accuracy: 0.6617 - val_loss: 0.7374 - val_accuracy: 0.6667\n",
      "Epoch 3433/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.6535 - val_loss: 0.7331 - val_accuracy: 0.6667\n",
      "Epoch 3434/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7717 - accuracy: 0.6767 - val_loss: 0.7477 - val_accuracy: 0.6717\n",
      "Epoch 3435/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7801 - accuracy: 0.6605 - val_loss: 0.7477 - val_accuracy: 0.6517\n",
      "Epoch 3436/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7705 - accuracy: 0.6677 - val_loss: 0.7398 - val_accuracy: 0.6417\n",
      "Epoch 3437/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7989 - accuracy: 0.6582 - val_loss: 0.7404 - val_accuracy: 0.6983\n",
      "Epoch 3438/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7845 - accuracy: 0.6808 - val_loss: 0.7564 - val_accuracy: 0.6600\n",
      "Epoch 3439/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7972 - accuracy: 0.6747 - val_loss: 0.7554 - val_accuracy: 0.6600\n",
      "Epoch 3440/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6558 - val_loss: 0.7461 - val_accuracy: 0.6333\n",
      "Epoch 3441/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7873 - accuracy: 0.6685 - val_loss: 0.7507 - val_accuracy: 0.6500\n",
      "Epoch 3442/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7701 - accuracy: 0.6662 - val_loss: 0.7365 - val_accuracy: 0.6417\n",
      "Epoch 3443/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7776 - accuracy: 0.6650 - val_loss: 0.7435 - val_accuracy: 0.6600\n",
      "Epoch 3444/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7900 - accuracy: 0.6740 - val_loss: 0.7449 - val_accuracy: 0.6683\n",
      "Epoch 3445/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7849 - accuracy: 0.6773 - val_loss: 0.7475 - val_accuracy: 0.6933\n",
      "Epoch 3446/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7839 - accuracy: 0.6813 - val_loss: 0.7513 - val_accuracy: 0.6500\n",
      "Epoch 3447/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6763 - val_loss: 0.7423 - val_accuracy: 0.6350\n",
      "Epoch 3448/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7893 - accuracy: 0.6652 - val_loss: 0.7417 - val_accuracy: 0.6700\n",
      "Epoch 3449/5000\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.7874 - accuracy: 0.6815 - val_loss: 0.7423 - val_accuracy: 0.7283\n",
      "Epoch 3450/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7860 - accuracy: 0.6773 - val_loss: 0.7545 - val_accuracy: 0.6517\n",
      "Epoch 3451/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7836 - accuracy: 0.6615 - val_loss: 0.7431 - val_accuracy: 0.6183\n",
      "Epoch 3452/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7826 - accuracy: 0.6700 - val_loss: 0.7535 - val_accuracy: 0.6800\n",
      "Epoch 3453/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7758 - accuracy: 0.6712 - val_loss: 0.7362 - val_accuracy: 0.6200\n",
      "Epoch 3454/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7860 - accuracy: 0.6668 - val_loss: 0.7374 - val_accuracy: 0.6417\n",
      "Epoch 3455/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7790 - accuracy: 0.6663 - val_loss: 0.7372 - val_accuracy: 0.6317\n",
      "Epoch 3456/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7823 - accuracy: 0.6642 - val_loss: 0.7389 - val_accuracy: 0.6300\n",
      "Epoch 3457/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7785 - accuracy: 0.6725 - val_loss: 0.7310 - val_accuracy: 0.6583\n",
      "Epoch 3458/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7798 - accuracy: 0.6843 - val_loss: 0.7369 - val_accuracy: 0.6283\n",
      "Epoch 3459/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7744 - accuracy: 0.6793 - val_loss: 0.7469 - val_accuracy: 0.6267\n",
      "Epoch 3460/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7833 - accuracy: 0.6677 - val_loss: 0.7456 - val_accuracy: 0.6467\n",
      "Epoch 3461/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6642 - val_loss: 0.7364 - val_accuracy: 0.6417\n",
      "Epoch 3462/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7859 - accuracy: 0.6582 - val_loss: 0.7408 - val_accuracy: 0.6950\n",
      "Epoch 3463/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7842 - accuracy: 0.6710 - val_loss: 0.7487 - val_accuracy: 0.6317\n",
      "Epoch 3464/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7776 - accuracy: 0.6690 - val_loss: 0.7433 - val_accuracy: 0.6400\n",
      "Epoch 3465/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7908 - accuracy: 0.6618 - val_loss: 0.7408 - val_accuracy: 0.6333\n",
      "Epoch 3466/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6732 - val_loss: 0.7397 - val_accuracy: 0.6467\n",
      "Epoch 3467/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7971 - accuracy: 0.6533 - val_loss: 0.7369 - val_accuracy: 0.6517\n",
      "Epoch 3468/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7772 - accuracy: 0.6775 - val_loss: 0.7383 - val_accuracy: 0.6533\n",
      "Epoch 3469/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7694 - accuracy: 0.6695 - val_loss: 0.7413 - val_accuracy: 0.6433\n",
      "Epoch 3470/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7866 - accuracy: 0.6632 - val_loss: 0.7266 - val_accuracy: 0.6383\n",
      "Epoch 3471/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.6735 - val_loss: 0.7416 - val_accuracy: 0.6500\n",
      "Epoch 3472/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.6663 - val_loss: 0.7403 - val_accuracy: 0.6483\n",
      "Epoch 3473/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7850 - accuracy: 0.6707 - val_loss: 0.7364 - val_accuracy: 0.6700\n",
      "Epoch 3474/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7740 - accuracy: 0.6738 - val_loss: 0.7370 - val_accuracy: 0.6467\n",
      "Epoch 3475/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7754 - accuracy: 0.6842 - val_loss: 0.7314 - val_accuracy: 0.6633\n",
      "Epoch 3476/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.6658 - val_loss: 0.7280 - val_accuracy: 0.6467\n",
      "Epoch 3477/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7914 - accuracy: 0.6723 - val_loss: 0.7344 - val_accuracy: 0.6833\n",
      "Epoch 3478/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7640 - accuracy: 0.6683 - val_loss: 0.7246 - val_accuracy: 0.6383\n",
      "Epoch 3479/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7695 - accuracy: 0.6695 - val_loss: 0.7233 - val_accuracy: 0.6467\n",
      "Epoch 3480/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7678 - accuracy: 0.6713 - val_loss: 0.7246 - val_accuracy: 0.6717\n",
      "Epoch 3481/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7842 - accuracy: 0.6735 - val_loss: 0.7278 - val_accuracy: 0.7100\n",
      "Epoch 3482/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6738 - val_loss: 0.7331 - val_accuracy: 0.6933\n",
      "Epoch 3483/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7707 - accuracy: 0.6822 - val_loss: 0.7340 - val_accuracy: 0.6733\n",
      "Epoch 3484/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6638 - val_loss: 0.7335 - val_accuracy: 0.6783\n",
      "Epoch 3485/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7911 - accuracy: 0.6745 - val_loss: 0.7340 - val_accuracy: 0.6383\n",
      "Epoch 3486/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.6637 - val_loss: 0.7541 - val_accuracy: 0.6533\n",
      "Epoch 3487/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7912 - accuracy: 0.6652 - val_loss: 0.7475 - val_accuracy: 0.6617\n",
      "Epoch 3488/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6657 - val_loss: 0.7566 - val_accuracy: 0.6617\n",
      "Epoch 3489/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6595 - val_loss: 0.7418 - val_accuracy: 0.6650\n",
      "Epoch 3490/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6607 - val_loss: 0.7510 - val_accuracy: 0.6767\n",
      "Epoch 3491/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6688 - val_loss: 0.7406 - val_accuracy: 0.6750\n",
      "Epoch 3492/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7821 - accuracy: 0.6650 - val_loss: 0.7482 - val_accuracy: 0.7233\n",
      "Epoch 3493/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7762 - accuracy: 0.6642 - val_loss: 0.7409 - val_accuracy: 0.6617\n",
      "Epoch 3494/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.6825 - val_loss: 0.7321 - val_accuracy: 0.6617\n",
      "Epoch 3495/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6807 - val_loss: 0.7412 - val_accuracy: 0.6767\n",
      "Epoch 3496/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.6758 - val_loss: 0.7618 - val_accuracy: 0.6583\n",
      "Epoch 3497/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.6695 - val_loss: 0.7470 - val_accuracy: 0.6700\n",
      "Epoch 3498/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7674 - accuracy: 0.6845 - val_loss: 0.7443 - val_accuracy: 0.6400\n",
      "Epoch 3499/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7922 - accuracy: 0.6735 - val_loss: 0.7519 - val_accuracy: 0.7083\n",
      "Epoch 3500/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7832 - accuracy: 0.6760 - val_loss: 0.7397 - val_accuracy: 0.6500\n",
      "Epoch 3501/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7861 - accuracy: 0.6773 - val_loss: 0.7449 - val_accuracy: 0.6867\n",
      "Epoch 3502/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6800 - val_loss: 0.7379 - val_accuracy: 0.6383\n",
      "Epoch 3503/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6863 - val_loss: 0.7419 - val_accuracy: 0.6600\n",
      "Epoch 3504/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6715 - val_loss: 0.7475 - val_accuracy: 0.6417\n",
      "Epoch 3505/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7865 - accuracy: 0.6712 - val_loss: 0.7394 - val_accuracy: 0.6383\n",
      "Epoch 3506/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7759 - accuracy: 0.6762 - val_loss: 0.7360 - val_accuracy: 0.6550\n",
      "Epoch 3507/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.6628 - val_loss: 0.7325 - val_accuracy: 0.6633\n",
      "Epoch 3508/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6838 - val_loss: 0.7293 - val_accuracy: 0.7067\n",
      "Epoch 3509/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6713 - val_loss: 0.7359 - val_accuracy: 0.6583\n",
      "Epoch 3510/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6623 - val_loss: 0.7371 - val_accuracy: 0.6933\n",
      "Epoch 3511/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7858 - accuracy: 0.6717 - val_loss: 0.7432 - val_accuracy: 0.6817\n",
      "Epoch 3512/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6860 - val_loss: 0.7357 - val_accuracy: 0.6767\n",
      "Epoch 3513/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7905 - accuracy: 0.6862 - val_loss: 0.7368 - val_accuracy: 0.6617\n",
      "Epoch 3514/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6818 - val_loss: 0.7419 - val_accuracy: 0.6350\n",
      "Epoch 3515/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7700 - accuracy: 0.6888 - val_loss: 0.7395 - val_accuracy: 0.6900\n",
      "Epoch 3516/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7785 - accuracy: 0.6722 - val_loss: 0.7337 - val_accuracy: 0.6450\n",
      "Epoch 3517/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6803 - val_loss: 0.7387 - val_accuracy: 0.6383\n",
      "Epoch 3518/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7783 - accuracy: 0.6740 - val_loss: 0.7364 - val_accuracy: 0.6667\n",
      "Epoch 3519/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7769 - accuracy: 0.6758 - val_loss: 0.7400 - val_accuracy: 0.6683\n",
      "Epoch 3520/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6807 - val_loss: 0.7430 - val_accuracy: 0.6933\n",
      "Epoch 3521/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7688 - accuracy: 0.6787 - val_loss: 0.7459 - val_accuracy: 0.6400\n",
      "Epoch 3522/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7785 - accuracy: 0.6655 - val_loss: 0.7357 - val_accuracy: 0.6317\n",
      "Epoch 3523/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7781 - accuracy: 0.6793 - val_loss: 0.7488 - val_accuracy: 0.6800\n",
      "Epoch 3524/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7648 - accuracy: 0.6832 - val_loss: 0.7482 - val_accuracy: 0.7233\n",
      "Epoch 3525/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7735 - accuracy: 0.6695 - val_loss: 0.7448 - val_accuracy: 0.6917\n",
      "Epoch 3526/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7820 - accuracy: 0.6738 - val_loss: 0.7478 - val_accuracy: 0.6683\n",
      "Epoch 3527/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.6718 - val_loss: 0.7413 - val_accuracy: 0.6333\n",
      "Epoch 3528/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.6852 - val_loss: 0.7382 - val_accuracy: 0.6400\n",
      "Epoch 3529/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6755 - val_loss: 0.7305 - val_accuracy: 0.6400\n",
      "Epoch 3530/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7822 - accuracy: 0.6758 - val_loss: 0.7343 - val_accuracy: 0.6750\n",
      "Epoch 3531/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.6897 - val_loss: 0.7345 - val_accuracy: 0.6683\n",
      "Epoch 3532/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7611 - accuracy: 0.6845 - val_loss: 0.7279 - val_accuracy: 0.6500\n",
      "Epoch 3533/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7707 - accuracy: 0.6753 - val_loss: 0.7297 - val_accuracy: 0.6500\n",
      "Epoch 3534/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7750 - accuracy: 0.6745 - val_loss: 0.7339 - val_accuracy: 0.6900\n",
      "Epoch 3535/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7771 - accuracy: 0.6765 - val_loss: 0.7305 - val_accuracy: 0.6500\n",
      "Epoch 3536/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7781 - accuracy: 0.6727 - val_loss: 0.7263 - val_accuracy: 0.6550\n",
      "Epoch 3537/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.6718 - val_loss: 0.7267 - val_accuracy: 0.6500\n",
      "Epoch 3538/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6837 - val_loss: 0.7306 - val_accuracy: 0.6833\n",
      "Epoch 3539/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7808 - accuracy: 0.6882 - val_loss: 0.7293 - val_accuracy: 0.6567\n",
      "Epoch 3540/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6738 - val_loss: 0.7325 - val_accuracy: 0.6617\n",
      "Epoch 3541/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.6883 - val_loss: 0.7314 - val_accuracy: 0.6533\n",
      "Epoch 3542/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.6763 - val_loss: 0.7373 - val_accuracy: 0.6667\n",
      "Epoch 3543/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6673 - val_loss: 0.7412 - val_accuracy: 0.6567\n",
      "Epoch 3544/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.6747 - val_loss: 0.7345 - val_accuracy: 0.6417\n",
      "Epoch 3545/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7737 - accuracy: 0.6665 - val_loss: 0.7278 - val_accuracy: 0.7217\n",
      "Epoch 3546/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7984 - accuracy: 0.6823 - val_loss: 0.7281 - val_accuracy: 0.6633\n",
      "Epoch 3547/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7983 - accuracy: 0.6807 - val_loss: 0.7345 - val_accuracy: 0.6517\n",
      "Epoch 3548/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7805 - accuracy: 0.6752 - val_loss: 0.7320 - val_accuracy: 0.6533\n",
      "Epoch 3549/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7788 - accuracy: 0.6798 - val_loss: 0.7329 - val_accuracy: 0.6900\n",
      "Epoch 3550/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7692 - accuracy: 0.6720 - val_loss: 0.7348 - val_accuracy: 0.6750\n",
      "Epoch 3551/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7630 - accuracy: 0.6772 - val_loss: 0.7317 - val_accuracy: 0.6533\n",
      "Epoch 3552/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7899 - accuracy: 0.6657 - val_loss: 0.7431 - val_accuracy: 0.6733\n",
      "Epoch 3553/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7827 - accuracy: 0.6785 - val_loss: 0.7267 - val_accuracy: 0.6767\n",
      "Epoch 3554/5000\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.7908 - accuracy: 0.6823 - val_loss: 0.7384 - val_accuracy: 0.7417\n",
      "Epoch 3555/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6950 - val_loss: 0.7361 - val_accuracy: 0.6817\n",
      "Epoch 3556/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6772 - val_loss: 0.7349 - val_accuracy: 0.6700\n",
      "Epoch 3557/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7789 - accuracy: 0.6932 - val_loss: 0.7373 - val_accuracy: 0.6633\n",
      "Epoch 3558/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7911 - accuracy: 0.6802 - val_loss: 0.7380 - val_accuracy: 0.7017\n",
      "Epoch 3559/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.6830 - val_loss: 0.7392 - val_accuracy: 0.6483\n",
      "Epoch 3560/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7822 - accuracy: 0.6743 - val_loss: 0.7406 - val_accuracy: 0.6950\n",
      "Epoch 3561/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7785 - accuracy: 0.6733 - val_loss: 0.7457 - val_accuracy: 0.6650\n",
      "Epoch 3562/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7779 - accuracy: 0.6783 - val_loss: 0.7333 - val_accuracy: 0.6333\n",
      "Epoch 3563/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7776 - accuracy: 0.6777 - val_loss: 0.7267 - val_accuracy: 0.6600\n",
      "Epoch 3564/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7763 - accuracy: 0.6848 - val_loss: 0.7210 - val_accuracy: 0.6533\n",
      "Epoch 3565/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7707 - accuracy: 0.6815 - val_loss: 0.7272 - val_accuracy: 0.6683\n",
      "Epoch 3566/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.6812 - val_loss: 0.7336 - val_accuracy: 0.7033\n",
      "Epoch 3567/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7910 - accuracy: 0.6912 - val_loss: 0.7358 - val_accuracy: 0.6967\n",
      "Epoch 3568/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6638 - val_loss: 0.7290 - val_accuracy: 0.6600\n",
      "Epoch 3569/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7717 - accuracy: 0.6895 - val_loss: 0.7276 - val_accuracy: 0.6517\n",
      "Epoch 3570/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7785 - accuracy: 0.6800 - val_loss: 0.7397 - val_accuracy: 0.7033\n",
      "Epoch 3571/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7792 - accuracy: 0.6838 - val_loss: 0.7456 - val_accuracy: 0.6650\n",
      "Epoch 3572/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.6800 - val_loss: 0.7478 - val_accuracy: 0.6850\n",
      "Epoch 3573/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7916 - accuracy: 0.6755 - val_loss: 0.7426 - val_accuracy: 0.6900\n",
      "Epoch 3574/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7789 - accuracy: 0.6698 - val_loss: 0.7321 - val_accuracy: 0.6817\n",
      "Epoch 3575/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7893 - accuracy: 0.6765 - val_loss: 0.7487 - val_accuracy: 0.6683\n",
      "Epoch 3576/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7938 - accuracy: 0.6792 - val_loss: 0.7509 - val_accuracy: 0.7417\n",
      "Epoch 3577/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7917 - accuracy: 0.6848 - val_loss: 0.7440 - val_accuracy: 0.6867\n",
      "Epoch 3578/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7812 - accuracy: 0.6897 - val_loss: 0.7517 - val_accuracy: 0.6717\n",
      "Epoch 3579/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7914 - accuracy: 0.6825 - val_loss: 0.7449 - val_accuracy: 0.6950\n",
      "Epoch 3580/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7792 - accuracy: 0.6903 - val_loss: 0.7439 - val_accuracy: 0.7133\n",
      "Epoch 3581/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7818 - accuracy: 0.6808 - val_loss: 0.7390 - val_accuracy: 0.6967\n",
      "Epoch 3582/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.7065 - val_loss: 0.7481 - val_accuracy: 0.6983\n",
      "Epoch 3583/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7940 - accuracy: 0.6867 - val_loss: 0.7559 - val_accuracy: 0.7333\n",
      "Epoch 3584/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7748 - accuracy: 0.6867 - val_loss: 0.7423 - val_accuracy: 0.6683\n",
      "Epoch 3585/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7796 - accuracy: 0.6725 - val_loss: 0.7440 - val_accuracy: 0.7117\n",
      "Epoch 3586/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7683 - accuracy: 0.6870 - val_loss: 0.7458 - val_accuracy: 0.6750\n",
      "Epoch 3587/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7896 - accuracy: 0.6755 - val_loss: 0.7458 - val_accuracy: 0.6933\n",
      "Epoch 3588/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.6923 - val_loss: 0.7418 - val_accuracy: 0.6600\n",
      "Epoch 3589/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7852 - accuracy: 0.6858 - val_loss: 0.7492 - val_accuracy: 0.6633\n",
      "Epoch 3590/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6692 - val_loss: 0.7462 - val_accuracy: 0.6750\n",
      "Epoch 3591/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7729 - accuracy: 0.6847 - val_loss: 0.7456 - val_accuracy: 0.6867\n",
      "Epoch 3592/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6930 - val_loss: 0.7499 - val_accuracy: 0.6500\n",
      "Epoch 3593/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7883 - accuracy: 0.6900 - val_loss: 0.7421 - val_accuracy: 0.6483\n",
      "Epoch 3594/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7755 - accuracy: 0.6853 - val_loss: 0.7538 - val_accuracy: 0.6600\n",
      "Epoch 3595/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.6857 - val_loss: 0.7573 - val_accuracy: 0.6867\n",
      "Epoch 3596/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7802 - accuracy: 0.6865 - val_loss: 0.7497 - val_accuracy: 0.6850\n",
      "Epoch 3597/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7815 - accuracy: 0.6973 - val_loss: 0.7481 - val_accuracy: 0.6617\n",
      "Epoch 3598/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7767 - accuracy: 0.6818 - val_loss: 0.7457 - val_accuracy: 0.6650\n",
      "Epoch 3599/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6743 - val_loss: 0.7565 - val_accuracy: 0.7150\n",
      "Epoch 3600/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7827 - accuracy: 0.6757 - val_loss: 0.7530 - val_accuracy: 0.6467\n",
      "Epoch 3601/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6860 - val_loss: 0.7580 - val_accuracy: 0.6667\n",
      "Epoch 3602/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7871 - accuracy: 0.6847 - val_loss: 0.7558 - val_accuracy: 0.7167\n",
      "Epoch 3603/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7733 - accuracy: 0.6852 - val_loss: 0.7489 - val_accuracy: 0.6600\n",
      "Epoch 3604/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7764 - accuracy: 0.6728 - val_loss: 0.7515 - val_accuracy: 0.6500\n",
      "Epoch 3605/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7781 - accuracy: 0.6783 - val_loss: 0.7547 - val_accuracy: 0.7283\n",
      "Epoch 3606/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7766 - accuracy: 0.6908 - val_loss: 0.7438 - val_accuracy: 0.6500\n",
      "Epoch 3607/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.6842 - val_loss: 0.7550 - val_accuracy: 0.7117\n",
      "Epoch 3608/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6908 - val_loss: 0.7536 - val_accuracy: 0.6300\n",
      "Epoch 3609/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6743 - val_loss: 0.7567 - val_accuracy: 0.6683\n",
      "Epoch 3610/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7940 - accuracy: 0.6768 - val_loss: 0.7477 - val_accuracy: 0.6567\n",
      "Epoch 3611/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6847 - val_loss: 0.7312 - val_accuracy: 0.6467\n",
      "Epoch 3612/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7899 - accuracy: 0.6880 - val_loss: 0.7438 - val_accuracy: 0.6517\n",
      "Epoch 3613/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7710 - accuracy: 0.6890 - val_loss: 0.7400 - val_accuracy: 0.6850\n",
      "Epoch 3614/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.6965 - val_loss: 0.7298 - val_accuracy: 0.6667\n",
      "Epoch 3615/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7722 - accuracy: 0.6877 - val_loss: 0.7157 - val_accuracy: 0.6767\n",
      "Epoch 3616/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7748 - accuracy: 0.6817 - val_loss: 0.7279 - val_accuracy: 0.6683\n",
      "Epoch 3617/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7815 - accuracy: 0.7027 - val_loss: 0.7309 - val_accuracy: 0.6733\n",
      "Epoch 3618/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.6818 - val_loss: 0.7412 - val_accuracy: 0.7017\n",
      "Epoch 3619/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.6913 - val_loss: 0.7339 - val_accuracy: 0.7017\n",
      "Epoch 3620/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7822 - accuracy: 0.7003 - val_loss: 0.7445 - val_accuracy: 0.6883\n",
      "Epoch 3621/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7733 - accuracy: 0.6863 - val_loss: 0.7433 - val_accuracy: 0.6433\n",
      "Epoch 3622/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7845 - accuracy: 0.6968 - val_loss: 0.7407 - val_accuracy: 0.6967\n",
      "Epoch 3623/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6728 - val_loss: 0.7387 - val_accuracy: 0.6867\n",
      "Epoch 3624/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6897 - val_loss: 0.7322 - val_accuracy: 0.7050\n",
      "Epoch 3625/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7809 - accuracy: 0.6943 - val_loss: 0.7388 - val_accuracy: 0.6550\n",
      "Epoch 3626/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7804 - accuracy: 0.6690 - val_loss: 0.7374 - val_accuracy: 0.6517\n",
      "Epoch 3627/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7918 - accuracy: 0.6848 - val_loss: 0.7436 - val_accuracy: 0.6533\n",
      "Epoch 3628/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7889 - accuracy: 0.6770 - val_loss: 0.7348 - val_accuracy: 0.6583\n",
      "Epoch 3629/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7821 - accuracy: 0.6807 - val_loss: 0.7361 - val_accuracy: 0.6800\n",
      "Epoch 3630/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7819 - accuracy: 0.6858 - val_loss: 0.7379 - val_accuracy: 0.7083\n",
      "Epoch 3631/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7853 - accuracy: 0.6943 - val_loss: 0.7399 - val_accuracy: 0.7383\n",
      "Epoch 3632/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7936 - accuracy: 0.6845 - val_loss: 0.7417 - val_accuracy: 0.6450\n",
      "Epoch 3633/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7820 - accuracy: 0.6857 - val_loss: 0.7488 - val_accuracy: 0.6983\n",
      "Epoch 3634/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7800 - accuracy: 0.6952 - val_loss: 0.7459 - val_accuracy: 0.7117\n",
      "Epoch 3635/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7816 - accuracy: 0.6867 - val_loss: 0.7301 - val_accuracy: 0.6700\n",
      "Epoch 3636/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7865 - accuracy: 0.6797 - val_loss: 0.7390 - val_accuracy: 0.7283\n",
      "Epoch 3637/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7830 - accuracy: 0.6802 - val_loss: 0.7395 - val_accuracy: 0.6617\n",
      "Epoch 3638/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6818 - val_loss: 0.7421 - val_accuracy: 0.6817\n",
      "Epoch 3639/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7727 - accuracy: 0.6832 - val_loss: 0.7350 - val_accuracy: 0.6733\n",
      "Epoch 3640/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.6925 - val_loss: 0.7377 - val_accuracy: 0.6933\n",
      "Epoch 3641/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7791 - accuracy: 0.6882 - val_loss: 0.7329 - val_accuracy: 0.6967\n",
      "Epoch 3642/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6928 - val_loss: 0.7342 - val_accuracy: 0.7283\n",
      "Epoch 3643/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7762 - accuracy: 0.6972 - val_loss: 0.7343 - val_accuracy: 0.7150\n",
      "Epoch 3644/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7873 - accuracy: 0.6937 - val_loss: 0.7353 - val_accuracy: 0.6733\n",
      "Epoch 3645/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7690 - accuracy: 0.6827 - val_loss: 0.7243 - val_accuracy: 0.6533\n",
      "Epoch 3646/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.6802 - val_loss: 0.7335 - val_accuracy: 0.7150\n",
      "Epoch 3647/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.6875 - val_loss: 0.7402 - val_accuracy: 0.7050\n",
      "Epoch 3648/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7741 - accuracy: 0.6845 - val_loss: 0.7278 - val_accuracy: 0.7417\n",
      "Epoch 3649/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7702 - accuracy: 0.6950 - val_loss: 0.7337 - val_accuracy: 0.7200\n",
      "Epoch 3650/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7820 - accuracy: 0.6983 - val_loss: 0.7310 - val_accuracy: 0.7317\n",
      "Epoch 3651/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7799 - accuracy: 0.6917 - val_loss: 0.7340 - val_accuracy: 0.7050\n",
      "Epoch 3652/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7823 - accuracy: 0.7053 - val_loss: 0.7299 - val_accuracy: 0.7167\n",
      "Epoch 3653/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6858 - val_loss: 0.7383 - val_accuracy: 0.7100\n",
      "Epoch 3654/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6945 - val_loss: 0.7295 - val_accuracy: 0.7333\n",
      "Epoch 3655/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7807 - accuracy: 0.6953 - val_loss: 0.7354 - val_accuracy: 0.6833\n",
      "Epoch 3656/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7868 - accuracy: 0.6877 - val_loss: 0.7456 - val_accuracy: 0.6967\n",
      "Epoch 3657/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7754 - accuracy: 0.6962 - val_loss: 0.7360 - val_accuracy: 0.7350\n",
      "Epoch 3658/5000\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.7919 - accuracy: 0.6980 - val_loss: 0.7421 - val_accuracy: 0.7567\n",
      "Epoch 3659/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6952 - val_loss: 0.7337 - val_accuracy: 0.6900\n",
      "Epoch 3660/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7821 - accuracy: 0.6713 - val_loss: 0.7376 - val_accuracy: 0.6933\n",
      "Epoch 3661/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7808 - accuracy: 0.6848 - val_loss: 0.7394 - val_accuracy: 0.7483\n",
      "Epoch 3662/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7764 - accuracy: 0.6922 - val_loss: 0.7319 - val_accuracy: 0.6967\n",
      "Epoch 3663/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7679 - accuracy: 0.6958 - val_loss: 0.7349 - val_accuracy: 0.7350\n",
      "Epoch 3664/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7620 - accuracy: 0.6955 - val_loss: 0.7395 - val_accuracy: 0.6567\n",
      "Epoch 3665/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.6848 - val_loss: 0.7266 - val_accuracy: 0.6983\n",
      "Epoch 3666/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7747 - accuracy: 0.6998 - val_loss: 0.7355 - val_accuracy: 0.7200\n",
      "Epoch 3667/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7737 - accuracy: 0.7073 - val_loss: 0.7284 - val_accuracy: 0.7117\n",
      "Epoch 3668/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7761 - accuracy: 0.6905 - val_loss: 0.7303 - val_accuracy: 0.7217\n",
      "Epoch 3669/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7826 - accuracy: 0.6912 - val_loss: 0.7385 - val_accuracy: 0.7267\n",
      "Epoch 3670/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7854 - accuracy: 0.7000 - val_loss: 0.7472 - val_accuracy: 0.6700\n",
      "Epoch 3671/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7922 - accuracy: 0.6885 - val_loss: 0.7567 - val_accuracy: 0.7417\n",
      "Epoch 3672/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6973 - val_loss: 0.7429 - val_accuracy: 0.7167\n",
      "Epoch 3673/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7829 - accuracy: 0.7017 - val_loss: 0.7424 - val_accuracy: 0.7033\n",
      "Epoch 3674/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7706 - accuracy: 0.6922 - val_loss: 0.7424 - val_accuracy: 0.6900\n",
      "Epoch 3675/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7702 - accuracy: 0.6883 - val_loss: 0.7353 - val_accuracy: 0.7067\n",
      "Epoch 3676/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.6950 - val_loss: 0.7388 - val_accuracy: 0.6800\n",
      "Epoch 3677/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7669 - accuracy: 0.6842 - val_loss: 0.7431 - val_accuracy: 0.6767\n",
      "Epoch 3678/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6953 - val_loss: 0.7282 - val_accuracy: 0.7250\n",
      "Epoch 3679/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7639 - accuracy: 0.6853 - val_loss: 0.7291 - val_accuracy: 0.7000\n",
      "Epoch 3680/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6937 - val_loss: 0.7421 - val_accuracy: 0.7317\n",
      "Epoch 3681/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7808 - accuracy: 0.6897 - val_loss: 0.7522 - val_accuracy: 0.7133\n",
      "Epoch 3682/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7740 - accuracy: 0.6853 - val_loss: 0.7378 - val_accuracy: 0.7000\n",
      "Epoch 3683/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7791 - accuracy: 0.6937 - val_loss: 0.7449 - val_accuracy: 0.7000\n",
      "Epoch 3684/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7685 - accuracy: 0.6937 - val_loss: 0.7396 - val_accuracy: 0.7267\n",
      "Epoch 3685/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7650 - accuracy: 0.7013 - val_loss: 0.7361 - val_accuracy: 0.7567\n",
      "Epoch 3686/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7795 - accuracy: 0.6837 - val_loss: 0.7315 - val_accuracy: 0.6917\n",
      "Epoch 3687/5000\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.7768 - accuracy: 0.6928 - val_loss: 0.7359 - val_accuracy: 0.7683\n",
      "Epoch 3688/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7851 - accuracy: 0.6920 - val_loss: 0.7335 - val_accuracy: 0.7317\n",
      "Epoch 3689/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6945 - val_loss: 0.7331 - val_accuracy: 0.7517\n",
      "Epoch 3690/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7862 - accuracy: 0.6973 - val_loss: 0.7360 - val_accuracy: 0.7233\n",
      "Epoch 3691/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.7007 - val_loss: 0.7359 - val_accuracy: 0.6983\n",
      "Epoch 3692/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7856 - accuracy: 0.6947 - val_loss: 0.7378 - val_accuracy: 0.6983\n",
      "Epoch 3693/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7878 - accuracy: 0.6923 - val_loss: 0.7421 - val_accuracy: 0.6717\n",
      "Epoch 3694/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7820 - accuracy: 0.6960 - val_loss: 0.7400 - val_accuracy: 0.7167\n",
      "Epoch 3695/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7750 - accuracy: 0.6933 - val_loss: 0.7345 - val_accuracy: 0.6783\n",
      "Epoch 3696/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7746 - accuracy: 0.6868 - val_loss: 0.7367 - val_accuracy: 0.6783\n",
      "Epoch 3697/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7776 - accuracy: 0.6823 - val_loss: 0.7398 - val_accuracy: 0.6617\n",
      "Epoch 3698/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7933 - accuracy: 0.6900 - val_loss: 0.7372 - val_accuracy: 0.7017\n",
      "Epoch 3699/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7841 - accuracy: 0.6800 - val_loss: 0.7361 - val_accuracy: 0.6783\n",
      "Epoch 3700/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6893 - val_loss: 0.7270 - val_accuracy: 0.7167\n",
      "Epoch 3701/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7885 - accuracy: 0.7028 - val_loss: 0.7360 - val_accuracy: 0.7067\n",
      "Epoch 3702/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7860 - accuracy: 0.7043 - val_loss: 0.7415 - val_accuracy: 0.7367\n",
      "Epoch 3703/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7821 - accuracy: 0.6975 - val_loss: 0.7393 - val_accuracy: 0.6600\n",
      "Epoch 3704/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6923 - val_loss: 0.7416 - val_accuracy: 0.7117\n",
      "Epoch 3705/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7874 - accuracy: 0.6938 - val_loss: 0.7394 - val_accuracy: 0.7100\n",
      "Epoch 3706/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.6993 - val_loss: 0.7414 - val_accuracy: 0.7250\n",
      "Epoch 3707/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7868 - accuracy: 0.6980 - val_loss: 0.7422 - val_accuracy: 0.7433\n",
      "Epoch 3708/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6973 - val_loss: 0.7404 - val_accuracy: 0.7133\n",
      "Epoch 3709/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.7027 - val_loss: 0.7334 - val_accuracy: 0.7117\n",
      "Epoch 3710/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.7040 - val_loss: 0.7311 - val_accuracy: 0.7333\n",
      "Epoch 3711/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7872 - accuracy: 0.7035 - val_loss: 0.7314 - val_accuracy: 0.6933\n",
      "Epoch 3712/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7912 - accuracy: 0.6895 - val_loss: 0.7506 - val_accuracy: 0.7383\n",
      "Epoch 3713/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7897 - accuracy: 0.6890 - val_loss: 0.7403 - val_accuracy: 0.7250\n",
      "Epoch 3714/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7822 - accuracy: 0.6910 - val_loss: 0.7419 - val_accuracy: 0.7400\n",
      "Epoch 3715/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7734 - accuracy: 0.7073 - val_loss: 0.7326 - val_accuracy: 0.6633\n",
      "Epoch 3716/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7777 - accuracy: 0.7040 - val_loss: 0.7292 - val_accuracy: 0.7383\n",
      "Epoch 3717/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7908 - accuracy: 0.7010 - val_loss: 0.7371 - val_accuracy: 0.7400\n",
      "Epoch 3718/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7796 - accuracy: 0.7108 - val_loss: 0.7404 - val_accuracy: 0.7500\n",
      "Epoch 3719/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7804 - accuracy: 0.7168 - val_loss: 0.7377 - val_accuracy: 0.6867\n",
      "Epoch 3720/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7897 - accuracy: 0.6973 - val_loss: 0.7422 - val_accuracy: 0.7183\n",
      "Epoch 3721/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7796 - accuracy: 0.6980 - val_loss: 0.7423 - val_accuracy: 0.7283\n",
      "Epoch 3722/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7825 - accuracy: 0.7053 - val_loss: 0.7368 - val_accuracy: 0.7117\n",
      "Epoch 3723/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7725 - accuracy: 0.6972 - val_loss: 0.7371 - val_accuracy: 0.7583\n",
      "Epoch 3724/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7850 - accuracy: 0.7068 - val_loss: 0.7362 - val_accuracy: 0.7167\n",
      "Epoch 3725/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7876 - accuracy: 0.7072 - val_loss: 0.7284 - val_accuracy: 0.7617\n",
      "Epoch 3726/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7839 - accuracy: 0.6993 - val_loss: 0.7377 - val_accuracy: 0.7617\n",
      "Epoch 3727/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7790 - accuracy: 0.7057 - val_loss: 0.7399 - val_accuracy: 0.6800\n",
      "Epoch 3728/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7871 - accuracy: 0.7020 - val_loss: 0.7374 - val_accuracy: 0.7283\n",
      "Epoch 3729/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7863 - accuracy: 0.6937 - val_loss: 0.7348 - val_accuracy: 0.7383\n",
      "Epoch 3730/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7792 - accuracy: 0.7077 - val_loss: 0.7387 - val_accuracy: 0.6883\n",
      "Epoch 3731/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7730 - accuracy: 0.6928 - val_loss: 0.7402 - val_accuracy: 0.7450\n",
      "Epoch 3732/5000\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.7793 - accuracy: 0.7200 - val_loss: 0.7359 - val_accuracy: 0.7733\n",
      "Epoch 3733/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7748 - accuracy: 0.7023 - val_loss: 0.7366 - val_accuracy: 0.7017\n",
      "Epoch 3734/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.7162 - val_loss: 0.7199 - val_accuracy: 0.7567\n",
      "Epoch 3735/5000\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.7881 - accuracy: 0.7095 - val_loss: 0.7259 - val_accuracy: 0.7767\n",
      "Epoch 3736/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7816 - accuracy: 0.7058 - val_loss: 0.7153 - val_accuracy: 0.7200\n",
      "Epoch 3737/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7795 - accuracy: 0.7148 - val_loss: 0.7294 - val_accuracy: 0.7400\n",
      "Epoch 3738/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7731 - accuracy: 0.7025 - val_loss: 0.7232 - val_accuracy: 0.7733\n",
      "Epoch 3739/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7786 - accuracy: 0.7315 - val_loss: 0.7308 - val_accuracy: 0.7600\n",
      "Epoch 3740/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7834 - accuracy: 0.7113 - val_loss: 0.7314 - val_accuracy: 0.7733\n",
      "Epoch 3741/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7767 - accuracy: 0.6927 - val_loss: 0.7289 - val_accuracy: 0.7500\n",
      "Epoch 3742/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7797 - accuracy: 0.6955 - val_loss: 0.7278 - val_accuracy: 0.7350\n",
      "Epoch 3743/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7741 - accuracy: 0.7162 - val_loss: 0.7203 - val_accuracy: 0.7417\n",
      "Epoch 3744/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.7093 - val_loss: 0.7271 - val_accuracy: 0.7200\n",
      "Epoch 3745/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7881 - accuracy: 0.6948 - val_loss: 0.7311 - val_accuracy: 0.7117\n",
      "Epoch 3746/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7735 - accuracy: 0.7078 - val_loss: 0.7232 - val_accuracy: 0.7650\n",
      "Epoch 3747/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7639 - accuracy: 0.7135 - val_loss: 0.7249 - val_accuracy: 0.7667\n",
      "Epoch 3748/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.6910 - val_loss: 0.7273 - val_accuracy: 0.7300\n",
      "Epoch 3749/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7724 - accuracy: 0.6950 - val_loss: 0.7256 - val_accuracy: 0.7650\n",
      "Epoch 3750/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7707 - accuracy: 0.7192 - val_loss: 0.7220 - val_accuracy: 0.7700\n",
      "Epoch 3751/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7852 - accuracy: 0.7052 - val_loss: 0.7270 - val_accuracy: 0.7567\n",
      "Epoch 3752/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7663 - accuracy: 0.7127 - val_loss: 0.7235 - val_accuracy: 0.7517\n",
      "Epoch 3753/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.7050 - val_loss: 0.7357 - val_accuracy: 0.6900\n",
      "Epoch 3754/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7603 - accuracy: 0.7010 - val_loss: 0.7227 - val_accuracy: 0.7467\n",
      "Epoch 3755/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7619 - accuracy: 0.7007 - val_loss: 0.7237 - val_accuracy: 0.7433\n",
      "Epoch 3756/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7543 - accuracy: 0.6992 - val_loss: 0.7136 - val_accuracy: 0.7167\n",
      "Epoch 3757/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7700 - accuracy: 0.7130 - val_loss: 0.7146 - val_accuracy: 0.7383\n",
      "Epoch 3758/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7705 - accuracy: 0.7110 - val_loss: 0.7180 - val_accuracy: 0.7417\n",
      "Epoch 3759/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7683 - accuracy: 0.7148 - val_loss: 0.7201 - val_accuracy: 0.7500\n",
      "Epoch 3760/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7684 - accuracy: 0.7248 - val_loss: 0.7217 - val_accuracy: 0.7433\n",
      "Epoch 3761/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7697 - accuracy: 0.7188 - val_loss: 0.7215 - val_accuracy: 0.7217\n",
      "Epoch 3762/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.7152 - val_loss: 0.7335 - val_accuracy: 0.7533\n",
      "Epoch 3763/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7808 - accuracy: 0.7202 - val_loss: 0.7354 - val_accuracy: 0.7633\n",
      "Epoch 3764/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7799 - accuracy: 0.7140 - val_loss: 0.7334 - val_accuracy: 0.7600\n",
      "Epoch 3765/5000\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.7760 - accuracy: 0.7200 - val_loss: 0.7287 - val_accuracy: 0.7883\n",
      "Epoch 3766/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7947 - accuracy: 0.7138 - val_loss: 0.7299 - val_accuracy: 0.7500\n",
      "Epoch 3767/5000\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.7876 - accuracy: 0.7192 - val_loss: 0.7211 - val_accuracy: 0.7950\n",
      "Epoch 3768/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.7173 - val_loss: 0.7291 - val_accuracy: 0.7483\n",
      "Epoch 3769/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.7047 - val_loss: 0.7243 - val_accuracy: 0.7550\n",
      "Epoch 3770/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.6983 - val_loss: 0.7241 - val_accuracy: 0.6917\n",
      "Epoch 3771/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7838 - accuracy: 0.7090 - val_loss: 0.7244 - val_accuracy: 0.7150\n",
      "Epoch 3772/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7745 - accuracy: 0.7155 - val_loss: 0.7237 - val_accuracy: 0.7183\n",
      "Epoch 3773/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7712 - accuracy: 0.7245 - val_loss: 0.7147 - val_accuracy: 0.7517\n",
      "Epoch 3774/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7727 - accuracy: 0.7235 - val_loss: 0.7117 - val_accuracy: 0.7717\n",
      "Epoch 3775/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7821 - accuracy: 0.7187 - val_loss: 0.7200 - val_accuracy: 0.7250\n",
      "Epoch 3776/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7695 - accuracy: 0.7240 - val_loss: 0.7220 - val_accuracy: 0.7750\n",
      "Epoch 3777/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7769 - accuracy: 0.7203 - val_loss: 0.7269 - val_accuracy: 0.7833\n",
      "Epoch 3778/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7651 - accuracy: 0.7218 - val_loss: 0.7304 - val_accuracy: 0.7483\n",
      "Epoch 3779/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7800 - accuracy: 0.7325 - val_loss: 0.7233 - val_accuracy: 0.7150\n",
      "Epoch 3780/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7792 - accuracy: 0.7192 - val_loss: 0.7238 - val_accuracy: 0.7767\n",
      "Epoch 3781/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7858 - accuracy: 0.7245 - val_loss: 0.7249 - val_accuracy: 0.7433\n",
      "Epoch 3782/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7710 - accuracy: 0.7147 - val_loss: 0.7255 - val_accuracy: 0.7650\n",
      "Epoch 3783/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7697 - accuracy: 0.7183 - val_loss: 0.7261 - val_accuracy: 0.7483\n",
      "Epoch 3784/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.7185 - val_loss: 0.7275 - val_accuracy: 0.7400\n",
      "Epoch 3785/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7797 - accuracy: 0.7300 - val_loss: 0.7308 - val_accuracy: 0.7633\n",
      "Epoch 3786/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.7273 - val_loss: 0.7379 - val_accuracy: 0.7817\n",
      "Epoch 3787/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7935 - accuracy: 0.7297 - val_loss: 0.7402 - val_accuracy: 0.7617\n",
      "Epoch 3788/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7888 - accuracy: 0.7368 - val_loss: 0.7507 - val_accuracy: 0.7633\n",
      "Epoch 3789/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7976 - accuracy: 0.7225 - val_loss: 0.7376 - val_accuracy: 0.7533\n",
      "Epoch 3790/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.7192 - val_loss: 0.7230 - val_accuracy: 0.7667\n",
      "Epoch 3791/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.7300 - val_loss: 0.7257 - val_accuracy: 0.7817\n",
      "Epoch 3792/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7792 - accuracy: 0.7258 - val_loss: 0.7270 - val_accuracy: 0.7317\n",
      "Epoch 3793/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.7200 - val_loss: 0.7418 - val_accuracy: 0.7100\n",
      "Epoch 3794/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7787 - accuracy: 0.7247 - val_loss: 0.7445 - val_accuracy: 0.7367\n",
      "Epoch 3795/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7801 - accuracy: 0.7315 - val_loss: 0.7503 - val_accuracy: 0.7517\n",
      "Epoch 3796/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7927 - accuracy: 0.7175 - val_loss: 0.7472 - val_accuracy: 0.7017\n",
      "Epoch 3797/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.7192 - val_loss: 0.7352 - val_accuracy: 0.7450\n",
      "Epoch 3798/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7699 - accuracy: 0.7295 - val_loss: 0.7284 - val_accuracy: 0.7783\n",
      "Epoch 3799/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7726 - accuracy: 0.7222 - val_loss: 0.7234 - val_accuracy: 0.7833\n",
      "Epoch 3800/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7808 - accuracy: 0.7218 - val_loss: 0.7198 - val_accuracy: 0.7167\n",
      "Epoch 3801/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7839 - accuracy: 0.7147 - val_loss: 0.7182 - val_accuracy: 0.7200\n",
      "Epoch 3802/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7747 - accuracy: 0.7277 - val_loss: 0.7304 - val_accuracy: 0.7583\n",
      "Epoch 3803/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7696 - accuracy: 0.7342 - val_loss: 0.7345 - val_accuracy: 0.7817\n",
      "Epoch 3804/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.7265 - val_loss: 0.7212 - val_accuracy: 0.7433\n",
      "Epoch 3805/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.7313 - val_loss: 0.7274 - val_accuracy: 0.7750\n",
      "Epoch 3806/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7709 - accuracy: 0.7337 - val_loss: 0.7264 - val_accuracy: 0.7750\n",
      "Epoch 3807/5000\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.7730 - accuracy: 0.7358 - val_loss: 0.7345 - val_accuracy: 0.8067\n",
      "Epoch 3808/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7866 - accuracy: 0.7208 - val_loss: 0.7368 - val_accuracy: 0.7683\n",
      "Epoch 3809/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7773 - accuracy: 0.7340 - val_loss: 0.7371 - val_accuracy: 0.7383\n",
      "Epoch 3810/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7924 - accuracy: 0.7323 - val_loss: 0.7455 - val_accuracy: 0.7783\n",
      "Epoch 3811/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7915 - accuracy: 0.7332 - val_loss: 0.7537 - val_accuracy: 0.7833\n",
      "Epoch 3812/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7837 - accuracy: 0.7322 - val_loss: 0.7476 - val_accuracy: 0.7467\n",
      "Epoch 3813/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7912 - accuracy: 0.7327 - val_loss: 0.7418 - val_accuracy: 0.7933\n",
      "Epoch 3814/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7909 - accuracy: 0.7273 - val_loss: 0.7551 - val_accuracy: 0.7633\n",
      "Epoch 3815/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7987 - accuracy: 0.7308 - val_loss: 0.7567 - val_accuracy: 0.7917\n",
      "Epoch 3816/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7791 - accuracy: 0.7388 - val_loss: 0.7489 - val_accuracy: 0.7450\n",
      "Epoch 3817/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7809 - accuracy: 0.7305 - val_loss: 0.7462 - val_accuracy: 0.7817\n",
      "Epoch 3818/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7827 - accuracy: 0.7268 - val_loss: 0.7415 - val_accuracy: 0.7767\n",
      "Epoch 3819/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7935 - accuracy: 0.7373 - val_loss: 0.7453 - val_accuracy: 0.7750\n",
      "Epoch 3820/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7759 - accuracy: 0.7382 - val_loss: 0.7358 - val_accuracy: 0.7750\n",
      "Epoch 3821/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.7353 - val_loss: 0.7351 - val_accuracy: 0.7717\n",
      "Epoch 3822/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7754 - accuracy: 0.7412 - val_loss: 0.7317 - val_accuracy: 0.7617\n",
      "Epoch 3823/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7752 - accuracy: 0.7345 - val_loss: 0.7448 - val_accuracy: 0.7767\n",
      "Epoch 3824/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7863 - accuracy: 0.7360 - val_loss: 0.7379 - val_accuracy: 0.7617\n",
      "Epoch 3825/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7777 - accuracy: 0.7377 - val_loss: 0.7427 - val_accuracy: 0.7583\n",
      "Epoch 3826/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7738 - accuracy: 0.7462 - val_loss: 0.7378 - val_accuracy: 0.7783\n",
      "Epoch 3827/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7776 - accuracy: 0.7487 - val_loss: 0.7353 - val_accuracy: 0.7617\n",
      "Epoch 3828/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7635 - accuracy: 0.7558 - val_loss: 0.7348 - val_accuracy: 0.7667\n",
      "Epoch 3829/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7727 - accuracy: 0.7433 - val_loss: 0.7365 - val_accuracy: 0.7767\n",
      "Epoch 3830/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7645 - accuracy: 0.7453 - val_loss: 0.7411 - val_accuracy: 0.7700\n",
      "Epoch 3831/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7759 - accuracy: 0.7453 - val_loss: 0.7425 - val_accuracy: 0.7817\n",
      "Epoch 3832/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7786 - accuracy: 0.7555 - val_loss: 0.7594 - val_accuracy: 0.7483\n",
      "Epoch 3833/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7768 - accuracy: 0.7507 - val_loss: 0.7433 - val_accuracy: 0.7617\n",
      "Epoch 3834/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.7550 - val_loss: 0.7511 - val_accuracy: 0.7500\n",
      "Epoch 3835/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.7450 - val_loss: 0.7361 - val_accuracy: 0.7800\n",
      "Epoch 3836/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.7438 - val_loss: 0.7505 - val_accuracy: 0.7350\n",
      "Epoch 3837/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.7558 - val_loss: 0.7447 - val_accuracy: 0.7817\n",
      "Epoch 3838/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7769 - accuracy: 0.7558 - val_loss: 0.7446 - val_accuracy: 0.7900\n",
      "Epoch 3839/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.7493 - val_loss: 0.7529 - val_accuracy: 0.7550\n",
      "Epoch 3840/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.7452 - val_loss: 0.7552 - val_accuracy: 0.7717\n",
      "Epoch 3841/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7776 - accuracy: 0.7552 - val_loss: 0.7475 - val_accuracy: 0.8000\n",
      "Epoch 3842/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7768 - accuracy: 0.7605 - val_loss: 0.7525 - val_accuracy: 0.7917\n",
      "Epoch 3843/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7833 - accuracy: 0.7640 - val_loss: 0.7509 - val_accuracy: 0.7983\n",
      "Epoch 3844/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.7572 - val_loss: 0.7590 - val_accuracy: 0.7617\n",
      "Epoch 3845/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7765 - accuracy: 0.7632 - val_loss: 0.7427 - val_accuracy: 0.8067\n",
      "Epoch 3846/5000\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.7830 - accuracy: 0.7617 - val_loss: 0.7475 - val_accuracy: 0.8117\n",
      "Epoch 3847/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7784 - accuracy: 0.7502 - val_loss: 0.7440 - val_accuracy: 0.7850\n",
      "Epoch 3848/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7741 - accuracy: 0.7620 - val_loss: 0.7420 - val_accuracy: 0.8033\n",
      "Epoch 3849/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7732 - accuracy: 0.7660 - val_loss: 0.7517 - val_accuracy: 0.8000\n",
      "Epoch 3850/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7869 - accuracy: 0.7660 - val_loss: 0.7456 - val_accuracy: 0.8017\n",
      "Epoch 3851/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7793 - accuracy: 0.7712 - val_loss: 0.7481 - val_accuracy: 0.8000\n",
      "Epoch 3852/5000\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.7851 - accuracy: 0.7652 - val_loss: 0.7474 - val_accuracy: 0.8200\n",
      "Epoch 3853/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7749 - accuracy: 0.7702 - val_loss: 0.7406 - val_accuracy: 0.8167\n",
      "Epoch 3854/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7724 - accuracy: 0.7767 - val_loss: 0.7466 - val_accuracy: 0.8167\n",
      "Epoch 3855/5000\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.7706 - accuracy: 0.7807 - val_loss: 0.7512 - val_accuracy: 0.8267\n",
      "Epoch 3856/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7702 - accuracy: 0.7793 - val_loss: 0.7421 - val_accuracy: 0.8150\n",
      "Epoch 3857/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7664 - accuracy: 0.7750 - val_loss: 0.7351 - val_accuracy: 0.8083\n",
      "Epoch 3858/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7701 - accuracy: 0.7800 - val_loss: 0.7329 - val_accuracy: 0.8083\n",
      "Epoch 3859/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.7683 - val_loss: 0.7322 - val_accuracy: 0.7983\n",
      "Epoch 3860/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7779 - accuracy: 0.7708 - val_loss: 0.7251 - val_accuracy: 0.8067\n",
      "Epoch 3861/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7643 - accuracy: 0.7808 - val_loss: 0.7285 - val_accuracy: 0.7967\n",
      "Epoch 3862/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7655 - accuracy: 0.7737 - val_loss: 0.7445 - val_accuracy: 0.8117\n",
      "Epoch 3863/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7657 - accuracy: 0.7810 - val_loss: 0.7423 - val_accuracy: 0.8233\n",
      "Epoch 3864/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7799 - accuracy: 0.7722 - val_loss: 0.7460 - val_accuracy: 0.8133\n",
      "Epoch 3865/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7875 - accuracy: 0.7727 - val_loss: 0.7591 - val_accuracy: 0.8067\n",
      "Epoch 3866/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7868 - accuracy: 0.7733 - val_loss: 0.7433 - val_accuracy: 0.8017\n",
      "Epoch 3867/5000\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.7693 - accuracy: 0.7870 - val_loss: 0.7414 - val_accuracy: 0.8283\n",
      "Epoch 3868/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.7847 - val_loss: 0.7421 - val_accuracy: 0.7900\n",
      "Epoch 3869/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7793 - accuracy: 0.7802 - val_loss: 0.7234 - val_accuracy: 0.8267\n",
      "Epoch 3870/5000\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.7755 - accuracy: 0.7850 - val_loss: 0.7353 - val_accuracy: 0.8417\n",
      "Epoch 3871/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.7873 - val_loss: 0.7304 - val_accuracy: 0.8167\n",
      "Epoch 3872/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7819 - accuracy: 0.7753 - val_loss: 0.7358 - val_accuracy: 0.8067\n",
      "Epoch 3873/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.7785 - val_loss: 0.7500 - val_accuracy: 0.8083\n",
      "Epoch 3874/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.8103 - accuracy: 0.7812 - val_loss: 0.7333 - val_accuracy: 0.8117\n",
      "Epoch 3875/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7992 - accuracy: 0.7750 - val_loss: 0.7324 - val_accuracy: 0.8183\n",
      "Epoch 3876/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7975 - accuracy: 0.7778 - val_loss: 0.7328 - val_accuracy: 0.8417\n",
      "Epoch 3877/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7869 - accuracy: 0.7868 - val_loss: 0.7423 - val_accuracy: 0.8100\n",
      "Epoch 3878/5000\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.7822 - accuracy: 0.7833 - val_loss: 0.7538 - val_accuracy: 0.8083\n",
      "Epoch 3879/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7979 - accuracy: 0.7815 - val_loss: 0.7405 - val_accuracy: 0.8050\n",
      "Epoch 3880/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7678 - accuracy: 0.7993 - val_loss: 0.7343 - val_accuracy: 0.8233\n",
      "Epoch 3881/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7653 - accuracy: 0.7952 - val_loss: 0.7284 - val_accuracy: 0.8283\n",
      "Epoch 3882/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7689 - accuracy: 0.7952 - val_loss: 0.7297 - val_accuracy: 0.8383\n",
      "Epoch 3883/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7801 - accuracy: 0.7873 - val_loss: 0.7263 - val_accuracy: 0.8300\n",
      "Epoch 3884/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7656 - accuracy: 0.7993 - val_loss: 0.7278 - val_accuracy: 0.8050\n",
      "Epoch 3885/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7715 - accuracy: 0.7902 - val_loss: 0.7245 - val_accuracy: 0.8250\n",
      "Epoch 3886/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.7938 - val_loss: 0.7257 - val_accuracy: 0.8167\n",
      "Epoch 3887/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7625 - accuracy: 0.8040 - val_loss: 0.7225 - val_accuracy: 0.8217\n",
      "Epoch 3888/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.7988 - val_loss: 0.7261 - val_accuracy: 0.8100\n",
      "Epoch 3889/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7645 - accuracy: 0.7968 - val_loss: 0.7233 - val_accuracy: 0.8383\n",
      "Epoch 3890/5000\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.7641 - accuracy: 0.7995 - val_loss: 0.7246 - val_accuracy: 0.8583\n",
      "Epoch 3891/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7681 - accuracy: 0.7997 - val_loss: 0.7164 - val_accuracy: 0.8450\n",
      "Epoch 3892/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7555 - accuracy: 0.8030 - val_loss: 0.7337 - val_accuracy: 0.8017\n",
      "Epoch 3893/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7793 - accuracy: 0.7967 - val_loss: 0.7238 - val_accuracy: 0.8400\n",
      "Epoch 3894/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.8032 - val_loss: 0.7145 - val_accuracy: 0.8283\n",
      "Epoch 3895/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7740 - accuracy: 0.8045 - val_loss: 0.7177 - val_accuracy: 0.8300\n",
      "Epoch 3896/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7681 - accuracy: 0.8080 - val_loss: 0.7235 - val_accuracy: 0.8100\n",
      "Epoch 3897/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7756 - accuracy: 0.8027 - val_loss: 0.7251 - val_accuracy: 0.8167\n",
      "Epoch 3898/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7627 - accuracy: 0.8153 - val_loss: 0.7162 - val_accuracy: 0.8017\n",
      "Epoch 3899/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7853 - accuracy: 0.8087 - val_loss: 0.7216 - val_accuracy: 0.8367\n",
      "Epoch 3900/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7722 - accuracy: 0.8065 - val_loss: 0.7202 - val_accuracy: 0.8267\n",
      "Epoch 3901/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7694 - accuracy: 0.8123 - val_loss: 0.7174 - val_accuracy: 0.8267\n",
      "Epoch 3902/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7581 - accuracy: 0.8125 - val_loss: 0.7109 - val_accuracy: 0.8383\n",
      "Epoch 3903/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7642 - accuracy: 0.8098 - val_loss: 0.7228 - val_accuracy: 0.8233\n",
      "Epoch 3904/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7715 - accuracy: 0.8095 - val_loss: 0.7294 - val_accuracy: 0.8233\n",
      "Epoch 3905/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7670 - accuracy: 0.8115 - val_loss: 0.7174 - val_accuracy: 0.8417\n",
      "Epoch 3906/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7563 - accuracy: 0.8137 - val_loss: 0.7196 - val_accuracy: 0.8283\n",
      "Epoch 3907/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7708 - accuracy: 0.8102 - val_loss: 0.7340 - val_accuracy: 0.8467\n",
      "Epoch 3908/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7576 - accuracy: 0.8193 - val_loss: 0.7401 - val_accuracy: 0.8117\n",
      "Epoch 3909/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7719 - accuracy: 0.8137 - val_loss: 0.7370 - val_accuracy: 0.8117\n",
      "Epoch 3910/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7761 - accuracy: 0.8187 - val_loss: 0.7364 - val_accuracy: 0.8283\n",
      "Epoch 3911/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7750 - accuracy: 0.8080 - val_loss: 0.7345 - val_accuracy: 0.8450\n",
      "Epoch 3912/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7683 - accuracy: 0.8178 - val_loss: 0.7367 - val_accuracy: 0.8117\n",
      "Epoch 3913/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7728 - accuracy: 0.8228 - val_loss: 0.7329 - val_accuracy: 0.8233\n",
      "Epoch 3914/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7663 - accuracy: 0.8273 - val_loss: 0.7124 - val_accuracy: 0.8317\n",
      "Epoch 3915/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7549 - accuracy: 0.8265 - val_loss: 0.7237 - val_accuracy: 0.8383\n",
      "Epoch 3916/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.8190 - val_loss: 0.7350 - val_accuracy: 0.8183\n",
      "Epoch 3917/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7590 - accuracy: 0.8222 - val_loss: 0.7302 - val_accuracy: 0.8333\n",
      "Epoch 3918/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7657 - accuracy: 0.8218 - val_loss: 0.7236 - val_accuracy: 0.8267\n",
      "Epoch 3919/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7682 - accuracy: 0.8213 - val_loss: 0.7355 - val_accuracy: 0.8033\n",
      "Epoch 3920/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7655 - accuracy: 0.8193 - val_loss: 0.7105 - val_accuracy: 0.8483\n",
      "Epoch 3921/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7637 - accuracy: 0.8218 - val_loss: 0.7438 - val_accuracy: 0.8200\n",
      "Epoch 3922/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7631 - accuracy: 0.8220 - val_loss: 0.7278 - val_accuracy: 0.8233\n",
      "Epoch 3923/5000\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.7562 - accuracy: 0.8242 - val_loss: 0.7123 - val_accuracy: 0.8600\n",
      "Epoch 3924/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7506 - accuracy: 0.8317 - val_loss: 0.7272 - val_accuracy: 0.8383\n",
      "Epoch 3925/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7594 - accuracy: 0.8287 - val_loss: 0.7378 - val_accuracy: 0.8333\n",
      "Epoch 3926/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7578 - accuracy: 0.8227 - val_loss: 0.7388 - val_accuracy: 0.8250\n",
      "Epoch 3927/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7607 - accuracy: 0.8248 - val_loss: 0.7267 - val_accuracy: 0.8267\n",
      "Epoch 3928/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7624 - accuracy: 0.8283 - val_loss: 0.7216 - val_accuracy: 0.8400\n",
      "Epoch 3929/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7618 - accuracy: 0.8267 - val_loss: 0.7218 - val_accuracy: 0.8433\n",
      "Epoch 3930/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7458 - accuracy: 0.8353 - val_loss: 0.7171 - val_accuracy: 0.8317\n",
      "Epoch 3931/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7551 - accuracy: 0.8340 - val_loss: 0.7252 - val_accuracy: 0.8100\n",
      "Epoch 3932/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7538 - accuracy: 0.8313 - val_loss: 0.7334 - val_accuracy: 0.8233\n",
      "Epoch 3933/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7513 - accuracy: 0.8353 - val_loss: 0.7277 - val_accuracy: 0.8133\n",
      "Epoch 3934/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7450 - accuracy: 0.8353 - val_loss: 0.7252 - val_accuracy: 0.8267\n",
      "Epoch 3935/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7576 - accuracy: 0.8305 - val_loss: 0.7290 - val_accuracy: 0.8100\n",
      "Epoch 3936/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7499 - accuracy: 0.8358 - val_loss: 0.7272 - val_accuracy: 0.8317\n",
      "Epoch 3937/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7526 - accuracy: 0.8333 - val_loss: 0.7229 - val_accuracy: 0.8450\n",
      "Epoch 3938/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7519 - accuracy: 0.8360 - val_loss: 0.7368 - val_accuracy: 0.8383\n",
      "Epoch 3939/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7693 - accuracy: 0.8288 - val_loss: 0.7276 - val_accuracy: 0.8233\n",
      "Epoch 3940/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7593 - accuracy: 0.8328 - val_loss: 0.7224 - val_accuracy: 0.8250\n",
      "Epoch 3941/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7462 - accuracy: 0.8368 - val_loss: 0.7278 - val_accuracy: 0.8367\n",
      "Epoch 3942/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7570 - accuracy: 0.8330 - val_loss: 0.7333 - val_accuracy: 0.8267\n",
      "Epoch 3943/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7518 - accuracy: 0.8395 - val_loss: 0.7265 - val_accuracy: 0.8050\n",
      "Epoch 3944/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7598 - accuracy: 0.8320 - val_loss: 0.7160 - val_accuracy: 0.8267\n",
      "Epoch 3945/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7538 - accuracy: 0.8393 - val_loss: 0.7385 - val_accuracy: 0.8300\n",
      "Epoch 3946/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7655 - accuracy: 0.8392 - val_loss: 0.7469 - val_accuracy: 0.7833\n",
      "Epoch 3947/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7621 - accuracy: 0.8365 - val_loss: 0.7224 - val_accuracy: 0.8083\n",
      "Epoch 3948/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7463 - accuracy: 0.8390 - val_loss: 0.7166 - val_accuracy: 0.8300\n",
      "Epoch 3949/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7428 - accuracy: 0.8432 - val_loss: 0.7170 - val_accuracy: 0.8167\n",
      "Epoch 3950/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7379 - accuracy: 0.8470 - val_loss: 0.7138 - val_accuracy: 0.8350\n",
      "Epoch 3951/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7237 - accuracy: 0.8470 - val_loss: 0.7139 - val_accuracy: 0.8300\n",
      "Epoch 3952/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7522 - accuracy: 0.8438 - val_loss: 0.7336 - val_accuracy: 0.8100\n",
      "Epoch 3953/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7419 - accuracy: 0.8473 - val_loss: 0.7227 - val_accuracy: 0.8100\n",
      "Epoch 3954/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7398 - accuracy: 0.8487 - val_loss: 0.7133 - val_accuracy: 0.8250\n",
      "Epoch 3955/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7399 - accuracy: 0.8400 - val_loss: 0.6972 - val_accuracy: 0.8417\n",
      "Epoch 3956/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7395 - accuracy: 0.8427 - val_loss: 0.7294 - val_accuracy: 0.8083\n",
      "Epoch 3957/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7431 - accuracy: 0.8442 - val_loss: 0.7161 - val_accuracy: 0.8333\n",
      "Epoch 3958/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7572 - accuracy: 0.8390 - val_loss: 0.7085 - val_accuracy: 0.8333\n",
      "Epoch 3959/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7288 - accuracy: 0.8445 - val_loss: 0.6983 - val_accuracy: 0.8300\n",
      "Epoch 3960/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7341 - accuracy: 0.8517 - val_loss: 0.7086 - val_accuracy: 0.8267\n",
      "Epoch 3961/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7326 - accuracy: 0.8485 - val_loss: 0.7095 - val_accuracy: 0.8267\n",
      "Epoch 3962/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7462 - accuracy: 0.8437 - val_loss: 0.7313 - val_accuracy: 0.8167\n",
      "Epoch 3963/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7333 - accuracy: 0.8413 - val_loss: 0.7057 - val_accuracy: 0.8450\n",
      "Epoch 3964/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7406 - accuracy: 0.8442 - val_loss: 0.7164 - val_accuracy: 0.8433\n",
      "Epoch 3965/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7288 - accuracy: 0.8480 - val_loss: 0.7265 - val_accuracy: 0.8233\n",
      "Epoch 3966/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7405 - accuracy: 0.8518 - val_loss: 0.7244 - val_accuracy: 0.8200\n",
      "Epoch 3967/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7223 - accuracy: 0.8500 - val_loss: 0.7079 - val_accuracy: 0.8117\n",
      "Epoch 3968/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7309 - accuracy: 0.8552 - val_loss: 0.6964 - val_accuracy: 0.8550\n",
      "Epoch 3969/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7309 - accuracy: 0.8515 - val_loss: 0.7145 - val_accuracy: 0.8433\n",
      "Epoch 3970/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7291 - accuracy: 0.8512 - val_loss: 0.7145 - val_accuracy: 0.8200\n",
      "Epoch 3971/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7305 - accuracy: 0.8457 - val_loss: 0.7121 - val_accuracy: 0.8150\n",
      "Epoch 3972/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7447 - accuracy: 0.8483 - val_loss: 0.7115 - val_accuracy: 0.8317\n",
      "Epoch 3973/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7231 - accuracy: 0.8488 - val_loss: 0.6935 - val_accuracy: 0.8300\n",
      "Epoch 3974/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7295 - accuracy: 0.8528 - val_loss: 0.7095 - val_accuracy: 0.8250\n",
      "Epoch 3975/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7211 - accuracy: 0.8523 - val_loss: 0.6912 - val_accuracy: 0.8517\n",
      "Epoch 3976/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7279 - accuracy: 0.8503 - val_loss: 0.7063 - val_accuracy: 0.8150\n",
      "Epoch 3977/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7347 - accuracy: 0.8555 - val_loss: 0.7048 - val_accuracy: 0.8467\n",
      "Epoch 3978/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7275 - accuracy: 0.8528 - val_loss: 0.7048 - val_accuracy: 0.8300\n",
      "Epoch 3979/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7297 - accuracy: 0.8522 - val_loss: 0.7068 - val_accuracy: 0.8250\n",
      "Epoch 3980/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7261 - accuracy: 0.8535 - val_loss: 0.7167 - val_accuracy: 0.8183\n",
      "Epoch 3981/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7223 - accuracy: 0.8572 - val_loss: 0.7023 - val_accuracy: 0.8117\n",
      "Epoch 3982/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7288 - accuracy: 0.8532 - val_loss: 0.7002 - val_accuracy: 0.8283\n",
      "Epoch 3983/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7170 - accuracy: 0.8558 - val_loss: 0.7092 - val_accuracy: 0.8150\n",
      "Epoch 3984/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7231 - accuracy: 0.8550 - val_loss: 0.7103 - val_accuracy: 0.8083\n",
      "Epoch 3985/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7337 - accuracy: 0.8520 - val_loss: 0.6992 - val_accuracy: 0.8333\n",
      "Epoch 3986/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7251 - accuracy: 0.8592 - val_loss: 0.7325 - val_accuracy: 0.8067\n",
      "Epoch 3987/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7373 - accuracy: 0.8512 - val_loss: 0.7200 - val_accuracy: 0.7867\n",
      "Epoch 3988/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7220 - accuracy: 0.8563 - val_loss: 0.7096 - val_accuracy: 0.8117\n",
      "Epoch 3989/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7430 - accuracy: 0.8540 - val_loss: 0.7166 - val_accuracy: 0.8367\n",
      "Epoch 3990/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7458 - accuracy: 0.8552 - val_loss: 0.7256 - val_accuracy: 0.8100\n",
      "Epoch 3991/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7304 - accuracy: 0.8555 - val_loss: 0.7308 - val_accuracy: 0.7967\n",
      "Epoch 3992/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7137 - accuracy: 0.8600 - val_loss: 0.7160 - val_accuracy: 0.8083\n",
      "Epoch 3993/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7163 - accuracy: 0.8585 - val_loss: 0.7209 - val_accuracy: 0.7983\n",
      "Epoch 3994/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7361 - accuracy: 0.8562 - val_loss: 0.7159 - val_accuracy: 0.8100\n",
      "Epoch 3995/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7212 - accuracy: 0.8537 - val_loss: 0.7317 - val_accuracy: 0.7933\n",
      "Epoch 3996/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7397 - accuracy: 0.8542 - val_loss: 0.7240 - val_accuracy: 0.8233\n",
      "Epoch 3997/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7278 - accuracy: 0.8570 - val_loss: 0.7297 - val_accuracy: 0.8117\n",
      "Epoch 3998/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7066 - accuracy: 0.8653 - val_loss: 0.7349 - val_accuracy: 0.8033\n",
      "Epoch 3999/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7333 - accuracy: 0.8572 - val_loss: 0.7155 - val_accuracy: 0.8200\n",
      "Epoch 4000/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7121 - accuracy: 0.8615 - val_loss: 0.7280 - val_accuracy: 0.8017\n",
      "Epoch 4001/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7160 - accuracy: 0.8573 - val_loss: 0.7065 - val_accuracy: 0.8133\n",
      "Epoch 4002/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7005 - accuracy: 0.8675 - val_loss: 0.7032 - val_accuracy: 0.8233\n",
      "Epoch 4003/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7266 - accuracy: 0.8588 - val_loss: 0.7200 - val_accuracy: 0.8167\n",
      "Epoch 4004/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7253 - accuracy: 0.8560 - val_loss: 0.7496 - val_accuracy: 0.8133\n",
      "Epoch 4005/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7262 - accuracy: 0.8557 - val_loss: 0.7433 - val_accuracy: 0.8033\n",
      "Epoch 4006/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7234 - accuracy: 0.8568 - val_loss: 0.7155 - val_accuracy: 0.8367\n",
      "Epoch 4007/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7220 - accuracy: 0.8567 - val_loss: 0.7393 - val_accuracy: 0.7933\n",
      "Epoch 4008/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7100 - accuracy: 0.8662 - val_loss: 0.7199 - val_accuracy: 0.8333\n",
      "Epoch 4009/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7025 - accuracy: 0.8718 - val_loss: 0.7040 - val_accuracy: 0.8433\n",
      "Epoch 4010/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6868 - accuracy: 0.8708 - val_loss: 0.7167 - val_accuracy: 0.8133\n",
      "Epoch 4011/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7081 - accuracy: 0.8650 - val_loss: 0.6996 - val_accuracy: 0.8467\n",
      "Epoch 4012/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7227 - accuracy: 0.8585 - val_loss: 0.7099 - val_accuracy: 0.8300\n",
      "Epoch 4013/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7173 - accuracy: 0.8643 - val_loss: 0.7366 - val_accuracy: 0.8100\n",
      "Epoch 4014/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7393 - accuracy: 0.8592 - val_loss: 0.7179 - val_accuracy: 0.8283\n",
      "Epoch 4015/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7205 - accuracy: 0.8618 - val_loss: 0.7273 - val_accuracy: 0.8033\n",
      "Epoch 4016/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7072 - accuracy: 0.8682 - val_loss: 0.7333 - val_accuracy: 0.8000\n",
      "Epoch 4017/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7215 - accuracy: 0.8580 - val_loss: 0.7188 - val_accuracy: 0.8033\n",
      "Epoch 4018/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7255 - accuracy: 0.8547 - val_loss: 0.7251 - val_accuracy: 0.8050\n",
      "Epoch 4019/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7065 - accuracy: 0.8638 - val_loss: 0.6904 - val_accuracy: 0.8333\n",
      "Epoch 4020/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6938 - accuracy: 0.8665 - val_loss: 0.7026 - val_accuracy: 0.8233\n",
      "Epoch 4021/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7000 - accuracy: 0.8655 - val_loss: 0.7031 - val_accuracy: 0.8400\n",
      "Epoch 4022/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7243 - accuracy: 0.8658 - val_loss: 0.7323 - val_accuracy: 0.8167\n",
      "Epoch 4023/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7362 - accuracy: 0.8625 - val_loss: 0.7450 - val_accuracy: 0.8317\n",
      "Epoch 4024/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7217 - accuracy: 0.8592 - val_loss: 0.7203 - val_accuracy: 0.7967\n",
      "Epoch 4025/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7218 - accuracy: 0.8703 - val_loss: 0.7302 - val_accuracy: 0.8067\n",
      "Epoch 4026/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7073 - accuracy: 0.8657 - val_loss: 0.7184 - val_accuracy: 0.8250\n",
      "Epoch 4027/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7007 - accuracy: 0.8720 - val_loss: 0.7221 - val_accuracy: 0.8167\n",
      "Epoch 4028/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7116 - accuracy: 0.8652 - val_loss: 0.7035 - val_accuracy: 0.8417\n",
      "Epoch 4029/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7020 - accuracy: 0.8672 - val_loss: 0.7037 - val_accuracy: 0.8500\n",
      "Epoch 4030/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7197 - accuracy: 0.8603 - val_loss: 0.7083 - val_accuracy: 0.8167\n",
      "Epoch 4031/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7193 - accuracy: 0.8622 - val_loss: 0.7209 - val_accuracy: 0.7983\n",
      "Epoch 4032/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7308 - accuracy: 0.8600 - val_loss: 0.7221 - val_accuracy: 0.8383\n",
      "Epoch 4033/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7115 - accuracy: 0.8663 - val_loss: 0.7235 - val_accuracy: 0.8317\n",
      "Epoch 4034/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7109 - accuracy: 0.8653 - val_loss: 0.7217 - val_accuracy: 0.8367\n",
      "Epoch 4035/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7159 - accuracy: 0.8672 - val_loss: 0.7352 - val_accuracy: 0.8200\n",
      "Epoch 4036/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7380 - accuracy: 0.8583 - val_loss: 0.7458 - val_accuracy: 0.8167\n",
      "Epoch 4037/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7281 - accuracy: 0.8668 - val_loss: 0.7283 - val_accuracy: 0.8450\n",
      "Epoch 4038/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7090 - accuracy: 0.8693 - val_loss: 0.7363 - val_accuracy: 0.8217\n",
      "Epoch 4039/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7083 - accuracy: 0.8665 - val_loss: 0.7341 - val_accuracy: 0.8183\n",
      "Epoch 4040/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7053 - accuracy: 0.8717 - val_loss: 0.7217 - val_accuracy: 0.8100\n",
      "Epoch 4041/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7125 - accuracy: 0.8667 - val_loss: 0.7245 - val_accuracy: 0.8217\n",
      "Epoch 4042/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7261 - accuracy: 0.8618 - val_loss: 0.7127 - val_accuracy: 0.8133\n",
      "Epoch 4043/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6872 - accuracy: 0.8717 - val_loss: 0.7100 - val_accuracy: 0.8200\n",
      "Epoch 4044/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7090 - accuracy: 0.8643 - val_loss: 0.7032 - val_accuracy: 0.8200\n",
      "Epoch 4045/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7256 - accuracy: 0.8630 - val_loss: 0.7299 - val_accuracy: 0.8067\n",
      "Epoch 4046/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7139 - accuracy: 0.8645 - val_loss: 0.7241 - val_accuracy: 0.7967\n",
      "Epoch 4047/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7040 - accuracy: 0.8725 - val_loss: 0.7115 - val_accuracy: 0.8283\n",
      "Epoch 4048/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7037 - accuracy: 0.8715 - val_loss: 0.7208 - val_accuracy: 0.8367\n",
      "Epoch 4049/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7303 - accuracy: 0.8702 - val_loss: 0.7472 - val_accuracy: 0.8100\n",
      "Epoch 4050/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7266 - accuracy: 0.8702 - val_loss: 0.7354 - val_accuracy: 0.8200\n",
      "Epoch 4051/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7185 - accuracy: 0.8727 - val_loss: 0.7167 - val_accuracy: 0.8450\n",
      "Epoch 4052/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7060 - accuracy: 0.8703 - val_loss: 0.7281 - val_accuracy: 0.8200\n",
      "Epoch 4053/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7297 - accuracy: 0.8630 - val_loss: 0.7284 - val_accuracy: 0.8300\n",
      "Epoch 4054/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7122 - accuracy: 0.8673 - val_loss: 0.7085 - val_accuracy: 0.8500\n",
      "Epoch 4055/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7035 - accuracy: 0.8668 - val_loss: 0.7115 - val_accuracy: 0.8267\n",
      "Epoch 4056/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7058 - accuracy: 0.8702 - val_loss: 0.7293 - val_accuracy: 0.8017\n",
      "Epoch 4057/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7060 - accuracy: 0.8680 - val_loss: 0.7168 - val_accuracy: 0.8150\n",
      "Epoch 4058/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7133 - accuracy: 0.8662 - val_loss: 0.6983 - val_accuracy: 0.8483\n",
      "Epoch 4059/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6984 - accuracy: 0.8688 - val_loss: 0.6841 - val_accuracy: 0.8467\n",
      "Epoch 4060/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6940 - accuracy: 0.8678 - val_loss: 0.7267 - val_accuracy: 0.8283\n",
      "Epoch 4061/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6942 - accuracy: 0.8707 - val_loss: 0.7246 - val_accuracy: 0.8217\n",
      "Epoch 4062/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7120 - accuracy: 0.8723 - val_loss: 0.7273 - val_accuracy: 0.8283\n",
      "Epoch 4063/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6947 - accuracy: 0.8767 - val_loss: 0.7319 - val_accuracy: 0.8383\n",
      "Epoch 4064/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7068 - accuracy: 0.8737 - val_loss: 0.7171 - val_accuracy: 0.8333\n",
      "Epoch 4065/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7044 - accuracy: 0.8733 - val_loss: 0.7683 - val_accuracy: 0.8067\n",
      "Epoch 4066/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6953 - accuracy: 0.8757 - val_loss: 0.7284 - val_accuracy: 0.8067\n",
      "Epoch 4067/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7022 - accuracy: 0.8670 - val_loss: 0.7335 - val_accuracy: 0.8033\n",
      "Epoch 4068/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7228 - accuracy: 0.8662 - val_loss: 0.7072 - val_accuracy: 0.8233\n",
      "Epoch 4069/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6954 - accuracy: 0.8712 - val_loss: 0.7060 - val_accuracy: 0.8333\n",
      "Epoch 4070/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6924 - accuracy: 0.8772 - val_loss: 0.7089 - val_accuracy: 0.8283\n",
      "Epoch 4071/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7042 - accuracy: 0.8760 - val_loss: 0.7026 - val_accuracy: 0.8200\n",
      "Epoch 4072/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7029 - accuracy: 0.8768 - val_loss: 0.7106 - val_accuracy: 0.8100\n",
      "Epoch 4073/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7068 - accuracy: 0.8720 - val_loss: 0.7061 - val_accuracy: 0.8150\n",
      "Epoch 4074/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7010 - accuracy: 0.8715 - val_loss: 0.6934 - val_accuracy: 0.8367\n",
      "Epoch 4075/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6852 - accuracy: 0.8763 - val_loss: 0.7135 - val_accuracy: 0.8133\n",
      "Epoch 4076/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.8753 - val_loss: 0.7051 - val_accuracy: 0.8183\n",
      "Epoch 4077/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7223 - accuracy: 0.8697 - val_loss: 0.6930 - val_accuracy: 0.8333\n",
      "Epoch 4078/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6998 - accuracy: 0.8810 - val_loss: 0.7178 - val_accuracy: 0.8017\n",
      "Epoch 4079/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6995 - accuracy: 0.8757 - val_loss: 0.7046 - val_accuracy: 0.8350\n",
      "Epoch 4080/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7073 - accuracy: 0.8723 - val_loss: 0.6820 - val_accuracy: 0.8500\n",
      "Epoch 4081/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7084 - accuracy: 0.8723 - val_loss: 0.7125 - val_accuracy: 0.8433\n",
      "Epoch 4082/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7172 - accuracy: 0.8713 - val_loss: 0.7104 - val_accuracy: 0.8500\n",
      "Epoch 4083/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6981 - accuracy: 0.8765 - val_loss: 0.7030 - val_accuracy: 0.8467\n",
      "Epoch 4084/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6830 - accuracy: 0.8805 - val_loss: 0.7043 - val_accuracy: 0.8350\n",
      "Epoch 4085/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7072 - accuracy: 0.8698 - val_loss: 0.7187 - val_accuracy: 0.8317\n",
      "Epoch 4086/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7277 - accuracy: 0.8667 - val_loss: 0.7182 - val_accuracy: 0.8383\n",
      "Epoch 4087/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7062 - accuracy: 0.8700 - val_loss: 0.7337 - val_accuracy: 0.8283\n",
      "Epoch 4088/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7016 - accuracy: 0.8703 - val_loss: 0.7036 - val_accuracy: 0.8317\n",
      "Epoch 4089/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6890 - accuracy: 0.8820 - val_loss: 0.7191 - val_accuracy: 0.8333\n",
      "Epoch 4090/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7021 - accuracy: 0.8735 - val_loss: 0.7133 - val_accuracy: 0.8583\n",
      "Epoch 4091/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7392 - accuracy: 0.8652 - val_loss: 0.7598 - val_accuracy: 0.8300\n",
      "Epoch 4092/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6969 - accuracy: 0.8762 - val_loss: 0.7075 - val_accuracy: 0.8333\n",
      "Epoch 4093/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6973 - accuracy: 0.8723 - val_loss: 0.7291 - val_accuracy: 0.8350\n",
      "Epoch 4094/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7003 - accuracy: 0.8780 - val_loss: 0.7264 - val_accuracy: 0.8133\n",
      "Epoch 4095/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7197 - accuracy: 0.8712 - val_loss: 0.7436 - val_accuracy: 0.8283\n",
      "Epoch 4096/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7265 - accuracy: 0.8652 - val_loss: 0.7202 - val_accuracy: 0.8267\n",
      "Epoch 4097/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.8802 - val_loss: 0.7125 - val_accuracy: 0.8500\n",
      "Epoch 4098/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6927 - accuracy: 0.8735 - val_loss: 0.7333 - val_accuracy: 0.8283\n",
      "Epoch 4099/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7039 - accuracy: 0.8758 - val_loss: 0.7307 - val_accuracy: 0.8300\n",
      "Epoch 4100/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7262 - accuracy: 0.8700 - val_loss: 0.7066 - val_accuracy: 0.8433\n",
      "Epoch 4101/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.8713 - val_loss: 0.7430 - val_accuracy: 0.8383\n",
      "Epoch 4102/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6831 - accuracy: 0.8800 - val_loss: 0.7156 - val_accuracy: 0.8383\n",
      "Epoch 4103/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7123 - accuracy: 0.8740 - val_loss: 0.7321 - val_accuracy: 0.8183\n",
      "Epoch 4104/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.8757 - val_loss: 0.7424 - val_accuracy: 0.8033\n",
      "Epoch 4105/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.8772 - val_loss: 0.7105 - val_accuracy: 0.8367\n",
      "Epoch 4106/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6742 - accuracy: 0.8777 - val_loss: 0.6979 - val_accuracy: 0.8317\n",
      "Epoch 4107/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6835 - accuracy: 0.8760 - val_loss: 0.7167 - val_accuracy: 0.8050\n",
      "Epoch 4108/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6807 - accuracy: 0.8813 - val_loss: 0.7087 - val_accuracy: 0.8283\n",
      "Epoch 4109/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7031 - accuracy: 0.8780 - val_loss: 0.6904 - val_accuracy: 0.8367\n",
      "Epoch 4110/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6847 - accuracy: 0.8777 - val_loss: 0.7010 - val_accuracy: 0.8317\n",
      "Epoch 4111/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6839 - accuracy: 0.8775 - val_loss: 0.6800 - val_accuracy: 0.8283\n",
      "Epoch 4112/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.8783 - val_loss: 0.6956 - val_accuracy: 0.8317\n",
      "Epoch 4113/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.8790 - val_loss: 0.7157 - val_accuracy: 0.8067\n",
      "Epoch 4114/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6831 - accuracy: 0.8812 - val_loss: 0.7269 - val_accuracy: 0.8100\n",
      "Epoch 4115/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.8757 - val_loss: 0.7081 - val_accuracy: 0.8367\n",
      "Epoch 4116/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7024 - accuracy: 0.8777 - val_loss: 0.7082 - val_accuracy: 0.8283\n",
      "Epoch 4117/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7048 - accuracy: 0.8763 - val_loss: 0.7199 - val_accuracy: 0.8417\n",
      "Epoch 4118/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7078 - accuracy: 0.8737 - val_loss: 0.7173 - val_accuracy: 0.8283\n",
      "Epoch 4119/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7094 - accuracy: 0.8728 - val_loss: 0.7374 - val_accuracy: 0.8300\n",
      "Epoch 4120/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.8773 - val_loss: 0.7288 - val_accuracy: 0.8267\n",
      "Epoch 4121/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7071 - accuracy: 0.8812 - val_loss: 0.7394 - val_accuracy: 0.8183\n",
      "Epoch 4122/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6915 - accuracy: 0.8732 - val_loss: 0.7211 - val_accuracy: 0.8167\n",
      "Epoch 4123/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6967 - accuracy: 0.8735 - val_loss: 0.7271 - val_accuracy: 0.8267\n",
      "Epoch 4124/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7083 - accuracy: 0.8758 - val_loss: 0.7291 - val_accuracy: 0.8250\n",
      "Epoch 4125/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6825 - accuracy: 0.8788 - val_loss: 0.7057 - val_accuracy: 0.8400\n",
      "Epoch 4126/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6812 - accuracy: 0.8778 - val_loss: 0.7223 - val_accuracy: 0.8467\n",
      "Epoch 4127/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6979 - accuracy: 0.8778 - val_loss: 0.7205 - val_accuracy: 0.8333\n",
      "Epoch 4128/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6929 - accuracy: 0.8812 - val_loss: 0.7340 - val_accuracy: 0.8083\n",
      "Epoch 4129/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7116 - accuracy: 0.8770 - val_loss: 0.7058 - val_accuracy: 0.8467\n",
      "Epoch 4130/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6850 - accuracy: 0.8807 - val_loss: 0.7145 - val_accuracy: 0.8317\n",
      "Epoch 4131/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6698 - accuracy: 0.8832 - val_loss: 0.7444 - val_accuracy: 0.8233\n",
      "Epoch 4132/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6972 - accuracy: 0.8795 - val_loss: 0.7584 - val_accuracy: 0.8300\n",
      "Epoch 4133/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.8800 - val_loss: 0.7577 - val_accuracy: 0.8250\n",
      "Epoch 4134/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7068 - accuracy: 0.8772 - val_loss: 0.7478 - val_accuracy: 0.8067\n",
      "Epoch 4135/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7128 - accuracy: 0.8748 - val_loss: 0.7651 - val_accuracy: 0.8317\n",
      "Epoch 4136/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6800 - accuracy: 0.8813 - val_loss: 0.7672 - val_accuracy: 0.8417\n",
      "Epoch 4137/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7171 - accuracy: 0.8762 - val_loss: 0.7560 - val_accuracy: 0.8250\n",
      "Epoch 4138/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.8850 - val_loss: 0.7628 - val_accuracy: 0.8267\n",
      "Epoch 4139/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6972 - accuracy: 0.8855 - val_loss: 0.7462 - val_accuracy: 0.8317\n",
      "Epoch 4140/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6972 - accuracy: 0.8782 - val_loss: 0.7720 - val_accuracy: 0.8283\n",
      "Epoch 4141/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.8870 - val_loss: 0.7484 - val_accuracy: 0.8383\n",
      "Epoch 4142/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6927 - accuracy: 0.8835 - val_loss: 0.7295 - val_accuracy: 0.8300\n",
      "Epoch 4143/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6826 - accuracy: 0.8830 - val_loss: 0.7185 - val_accuracy: 0.8350\n",
      "Epoch 4144/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6999 - accuracy: 0.8792 - val_loss: 0.7351 - val_accuracy: 0.8283\n",
      "Epoch 4145/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6810 - accuracy: 0.8888 - val_loss: 0.7327 - val_accuracy: 0.8350\n",
      "Epoch 4146/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6697 - accuracy: 0.8880 - val_loss: 0.7766 - val_accuracy: 0.8233\n",
      "Epoch 4147/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.8825 - val_loss: 0.7562 - val_accuracy: 0.8200\n",
      "Epoch 4148/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6894 - accuracy: 0.8755 - val_loss: 0.7477 - val_accuracy: 0.8333\n",
      "Epoch 4149/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6657 - accuracy: 0.8925 - val_loss: 0.7547 - val_accuracy: 0.8267\n",
      "Epoch 4150/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6859 - accuracy: 0.8827 - val_loss: 0.7573 - val_accuracy: 0.8250\n",
      "Epoch 4151/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 0.8823 - val_loss: 0.7765 - val_accuracy: 0.8083\n",
      "Epoch 4152/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6941 - accuracy: 0.8790 - val_loss: 0.7690 - val_accuracy: 0.8300\n",
      "Epoch 4153/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.8785 - val_loss: 0.7641 - val_accuracy: 0.8117\n",
      "Epoch 4154/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6853 - accuracy: 0.8825 - val_loss: 0.7670 - val_accuracy: 0.8100\n",
      "Epoch 4155/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6787 - accuracy: 0.8852 - val_loss: 0.7206 - val_accuracy: 0.8600\n",
      "Epoch 4156/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6871 - accuracy: 0.8815 - val_loss: 0.7704 - val_accuracy: 0.8233\n",
      "Epoch 4157/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6779 - accuracy: 0.8857 - val_loss: 0.7234 - val_accuracy: 0.8350\n",
      "Epoch 4158/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6699 - accuracy: 0.8833 - val_loss: 0.7290 - val_accuracy: 0.8233\n",
      "Epoch 4159/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6585 - accuracy: 0.8852 - val_loss: 0.7422 - val_accuracy: 0.8417\n",
      "Epoch 4160/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6678 - accuracy: 0.8888 - val_loss: 0.7458 - val_accuracy: 0.8450\n",
      "Epoch 4161/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6823 - accuracy: 0.8820 - val_loss: 0.7128 - val_accuracy: 0.8467\n",
      "Epoch 4162/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6824 - accuracy: 0.8780 - val_loss: 0.7531 - val_accuracy: 0.8217\n",
      "Epoch 4163/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6616 - accuracy: 0.8905 - val_loss: 0.7404 - val_accuracy: 0.8283\n",
      "Epoch 4164/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6804 - accuracy: 0.8810 - val_loss: 0.7113 - val_accuracy: 0.8400\n",
      "Epoch 4165/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6746 - accuracy: 0.8807 - val_loss: 0.7314 - val_accuracy: 0.8467\n",
      "Epoch 4166/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6745 - accuracy: 0.8862 - val_loss: 0.7302 - val_accuracy: 0.8300\n",
      "Epoch 4167/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6689 - accuracy: 0.8890 - val_loss: 0.7220 - val_accuracy: 0.8300\n",
      "Epoch 4168/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6733 - accuracy: 0.8860 - val_loss: 0.7145 - val_accuracy: 0.8533\n",
      "Epoch 4169/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7100 - accuracy: 0.8778 - val_loss: 0.7594 - val_accuracy: 0.8100\n",
      "Epoch 4170/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7164 - accuracy: 0.8753 - val_loss: 0.7409 - val_accuracy: 0.8183\n",
      "Epoch 4171/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6872 - accuracy: 0.8840 - val_loss: 0.7325 - val_accuracy: 0.8233\n",
      "Epoch 4172/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6645 - accuracy: 0.8828 - val_loss: 0.7309 - val_accuracy: 0.8150\n",
      "Epoch 4173/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6651 - accuracy: 0.8915 - val_loss: 0.7336 - val_accuracy: 0.8233\n",
      "Epoch 4174/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6659 - accuracy: 0.8892 - val_loss: 0.7262 - val_accuracy: 0.8300\n",
      "Epoch 4175/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6670 - accuracy: 0.8913 - val_loss: 0.7160 - val_accuracy: 0.8233\n",
      "Epoch 4176/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6833 - accuracy: 0.8817 - val_loss: 0.7509 - val_accuracy: 0.8067\n",
      "Epoch 4177/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6848 - accuracy: 0.8855 - val_loss: 0.7606 - val_accuracy: 0.8367\n",
      "Epoch 4178/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.8918 - val_loss: 0.7300 - val_accuracy: 0.8267\n",
      "Epoch 4179/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6803 - accuracy: 0.8847 - val_loss: 0.7543 - val_accuracy: 0.8300\n",
      "Epoch 4180/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6752 - accuracy: 0.8857 - val_loss: 0.7622 - val_accuracy: 0.8083\n",
      "Epoch 4181/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6717 - accuracy: 0.8872 - val_loss: 0.7481 - val_accuracy: 0.8150\n",
      "Epoch 4182/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6720 - accuracy: 0.8885 - val_loss: 0.7402 - val_accuracy: 0.8317\n",
      "Epoch 4183/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6979 - accuracy: 0.8887 - val_loss: 0.7744 - val_accuracy: 0.8033\n",
      "Epoch 4184/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6994 - accuracy: 0.8782 - val_loss: 0.7938 - val_accuracy: 0.8233\n",
      "Epoch 4185/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6720 - accuracy: 0.8888 - val_loss: 0.8101 - val_accuracy: 0.7917\n",
      "Epoch 4186/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6814 - accuracy: 0.8853 - val_loss: 0.7954 - val_accuracy: 0.7900\n",
      "Epoch 4187/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6808 - accuracy: 0.8900 - val_loss: 0.7405 - val_accuracy: 0.8317\n",
      "Epoch 4188/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6860 - accuracy: 0.8913 - val_loss: 0.7297 - val_accuracy: 0.8133\n",
      "Epoch 4189/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6722 - accuracy: 0.8890 - val_loss: 0.7384 - val_accuracy: 0.8267\n",
      "Epoch 4190/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6949 - accuracy: 0.8833 - val_loss: 0.7437 - val_accuracy: 0.8217\n",
      "Epoch 4191/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6784 - accuracy: 0.8863 - val_loss: 0.7769 - val_accuracy: 0.8050\n",
      "Epoch 4192/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6636 - accuracy: 0.8857 - val_loss: 0.7294 - val_accuracy: 0.8233\n",
      "Epoch 4193/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6642 - accuracy: 0.8845 - val_loss: 0.7367 - val_accuracy: 0.8367\n",
      "Epoch 4194/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6774 - accuracy: 0.8903 - val_loss: 0.7242 - val_accuracy: 0.8233\n",
      "Epoch 4195/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6931 - accuracy: 0.8862 - val_loss: 0.7398 - val_accuracy: 0.8267\n",
      "Epoch 4196/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6800 - accuracy: 0.8948 - val_loss: 0.7608 - val_accuracy: 0.8150\n",
      "Epoch 4197/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6852 - accuracy: 0.8858 - val_loss: 0.7498 - val_accuracy: 0.8233\n",
      "Epoch 4198/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6659 - accuracy: 0.8877 - val_loss: 0.7659 - val_accuracy: 0.8267\n",
      "Epoch 4199/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6735 - accuracy: 0.8837 - val_loss: 0.7319 - val_accuracy: 0.8350\n",
      "Epoch 4200/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6657 - accuracy: 0.8875 - val_loss: 0.7352 - val_accuracy: 0.8400\n",
      "Epoch 4201/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6673 - accuracy: 0.8842 - val_loss: 0.7207 - val_accuracy: 0.8517\n",
      "Epoch 4202/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6991 - accuracy: 0.8865 - val_loss: 0.7241 - val_accuracy: 0.8383\n",
      "Epoch 4203/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.8813 - val_loss: 0.7410 - val_accuracy: 0.8317\n",
      "Epoch 4204/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6778 - accuracy: 0.8848 - val_loss: 0.7605 - val_accuracy: 0.8183\n",
      "Epoch 4205/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6950 - accuracy: 0.8810 - val_loss: 0.7333 - val_accuracy: 0.8383\n",
      "Epoch 4206/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6710 - accuracy: 0.8853 - val_loss: 0.7329 - val_accuracy: 0.8233\n",
      "Epoch 4207/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6696 - accuracy: 0.8888 - val_loss: 0.7551 - val_accuracy: 0.8183\n",
      "Epoch 4208/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6739 - accuracy: 0.8853 - val_loss: 0.7410 - val_accuracy: 0.8250\n",
      "Epoch 4209/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6803 - accuracy: 0.8910 - val_loss: 0.7603 - val_accuracy: 0.8083\n",
      "Epoch 4210/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6710 - accuracy: 0.8917 - val_loss: 0.7634 - val_accuracy: 0.8233\n",
      "Epoch 4211/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6930 - accuracy: 0.8925 - val_loss: 0.7790 - val_accuracy: 0.8217\n",
      "Epoch 4212/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6836 - accuracy: 0.8907 - val_loss: 0.7779 - val_accuracy: 0.8233\n",
      "Epoch 4213/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.8835 - val_loss: 0.7765 - val_accuracy: 0.8300\n",
      "Epoch 4214/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7070 - accuracy: 0.8845 - val_loss: 0.7630 - val_accuracy: 0.8317\n",
      "Epoch 4215/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6765 - accuracy: 0.8867 - val_loss: 0.7683 - val_accuracy: 0.8133\n",
      "Epoch 4216/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6844 - accuracy: 0.8880 - val_loss: 0.7676 - val_accuracy: 0.8150\n",
      "Epoch 4217/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6734 - accuracy: 0.8913 - val_loss: 0.7438 - val_accuracy: 0.8233\n",
      "Epoch 4218/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7047 - accuracy: 0.8873 - val_loss: 0.7849 - val_accuracy: 0.8317\n",
      "Epoch 4219/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6884 - accuracy: 0.8883 - val_loss: 0.7745 - val_accuracy: 0.8200\n",
      "Epoch 4220/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6618 - accuracy: 0.8907 - val_loss: 0.7849 - val_accuracy: 0.8233\n",
      "Epoch 4221/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7025 - accuracy: 0.8893 - val_loss: 0.7852 - val_accuracy: 0.8317\n",
      "Epoch 4222/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7099 - accuracy: 0.8855 - val_loss: 0.7904 - val_accuracy: 0.8250\n",
      "Epoch 4223/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.8862 - val_loss: 0.8076 - val_accuracy: 0.8233\n",
      "Epoch 4224/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7022 - accuracy: 0.8928 - val_loss: 0.8142 - val_accuracy: 0.8267\n",
      "Epoch 4225/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7033 - accuracy: 0.8873 - val_loss: 0.7983 - val_accuracy: 0.8267\n",
      "Epoch 4226/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.8880 - val_loss: 0.7937 - val_accuracy: 0.8233\n",
      "Epoch 4227/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6851 - accuracy: 0.8877 - val_loss: 0.7911 - val_accuracy: 0.8167\n",
      "Epoch 4228/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6710 - accuracy: 0.8915 - val_loss: 0.7430 - val_accuracy: 0.8317\n",
      "Epoch 4229/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6942 - accuracy: 0.8828 - val_loss: 0.7673 - val_accuracy: 0.8367\n",
      "Epoch 4230/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6843 - accuracy: 0.8848 - val_loss: 0.7897 - val_accuracy: 0.8217\n",
      "Epoch 4231/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6579 - accuracy: 0.8917 - val_loss: 0.7792 - val_accuracy: 0.8300\n",
      "Epoch 4232/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6924 - accuracy: 0.8915 - val_loss: 0.7932 - val_accuracy: 0.8383\n",
      "Epoch 4233/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6761 - accuracy: 0.8897 - val_loss: 0.8064 - val_accuracy: 0.8383\n",
      "Epoch 4234/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7061 - accuracy: 0.8807 - val_loss: 0.8247 - val_accuracy: 0.8250\n",
      "Epoch 4235/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7006 - accuracy: 0.8910 - val_loss: 0.8374 - val_accuracy: 0.8283\n",
      "Epoch 4236/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6764 - accuracy: 0.8942 - val_loss: 0.8425 - val_accuracy: 0.8017\n",
      "Epoch 4237/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6775 - accuracy: 0.8925 - val_loss: 0.7928 - val_accuracy: 0.8333\n",
      "Epoch 4238/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6600 - accuracy: 0.8983 - val_loss: 0.7873 - val_accuracy: 0.8267\n",
      "Epoch 4239/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6721 - accuracy: 0.8928 - val_loss: 0.8225 - val_accuracy: 0.8167\n",
      "Epoch 4240/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6695 - accuracy: 0.8892 - val_loss: 0.7799 - val_accuracy: 0.8433\n",
      "Epoch 4241/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6833 - accuracy: 0.8957 - val_loss: 0.7923 - val_accuracy: 0.8200\n",
      "Epoch 4242/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6631 - accuracy: 0.8940 - val_loss: 0.8077 - val_accuracy: 0.7983\n",
      "Epoch 4243/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6584 - accuracy: 0.8938 - val_loss: 0.7931 - val_accuracy: 0.8217\n",
      "Epoch 4244/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6678 - accuracy: 0.8943 - val_loss: 0.8040 - val_accuracy: 0.8117\n",
      "Epoch 4245/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6592 - accuracy: 0.8972 - val_loss: 0.7889 - val_accuracy: 0.8283\n",
      "Epoch 4246/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6875 - accuracy: 0.8883 - val_loss: 0.7724 - val_accuracy: 0.8250\n",
      "Epoch 4247/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6878 - accuracy: 0.8892 - val_loss: 0.7961 - val_accuracy: 0.8233\n",
      "Epoch 4248/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6883 - accuracy: 0.8893 - val_loss: 0.7854 - val_accuracy: 0.8283\n",
      "Epoch 4249/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6758 - accuracy: 0.8922 - val_loss: 0.7723 - val_accuracy: 0.8233\n",
      "Epoch 4250/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6845 - accuracy: 0.8920 - val_loss: 0.7958 - val_accuracy: 0.8217\n",
      "Epoch 4251/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6764 - accuracy: 0.8928 - val_loss: 0.7820 - val_accuracy: 0.8300\n",
      "Epoch 4252/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6706 - accuracy: 0.8957 - val_loss: 0.7719 - val_accuracy: 0.8250\n",
      "Epoch 4253/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6757 - accuracy: 0.8947 - val_loss: 0.7634 - val_accuracy: 0.8233\n",
      "Epoch 4254/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6934 - accuracy: 0.8850 - val_loss: 0.7727 - val_accuracy: 0.8450\n",
      "Epoch 4255/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6663 - accuracy: 0.9000 - val_loss: 0.7733 - val_accuracy: 0.8317\n",
      "Epoch 4256/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6754 - accuracy: 0.8920 - val_loss: 0.7327 - val_accuracy: 0.8450\n",
      "Epoch 4257/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6645 - accuracy: 0.8933 - val_loss: 0.7577 - val_accuracy: 0.8350\n",
      "Epoch 4258/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6845 - accuracy: 0.8908 - val_loss: 0.7774 - val_accuracy: 0.8250\n",
      "Epoch 4259/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.8923 - val_loss: 0.7527 - val_accuracy: 0.8400\n",
      "Epoch 4260/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6639 - accuracy: 0.8940 - val_loss: 0.7729 - val_accuracy: 0.8333\n",
      "Epoch 4261/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6724 - accuracy: 0.8917 - val_loss: 0.7491 - val_accuracy: 0.8350\n",
      "Epoch 4262/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6766 - accuracy: 0.8912 - val_loss: 0.7928 - val_accuracy: 0.8233\n",
      "Epoch 4263/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6556 - accuracy: 0.8912 - val_loss: 0.8089 - val_accuracy: 0.8200\n",
      "Epoch 4264/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6899 - accuracy: 0.8857 - val_loss: 0.8025 - val_accuracy: 0.8367\n",
      "Epoch 4265/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6832 - accuracy: 0.8893 - val_loss: 0.7719 - val_accuracy: 0.8400\n",
      "Epoch 4266/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6733 - accuracy: 0.8907 - val_loss: 0.7657 - val_accuracy: 0.8367\n",
      "Epoch 4267/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.8907 - val_loss: 0.7486 - val_accuracy: 0.8150\n",
      "Epoch 4268/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6623 - accuracy: 0.8932 - val_loss: 0.7945 - val_accuracy: 0.8067\n",
      "Epoch 4269/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6677 - accuracy: 0.8945 - val_loss: 0.7693 - val_accuracy: 0.8333\n",
      "Epoch 4270/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6808 - accuracy: 0.8955 - val_loss: 0.7708 - val_accuracy: 0.8133\n",
      "Epoch 4271/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.8850 - val_loss: 0.7459 - val_accuracy: 0.8267\n",
      "Epoch 4272/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6603 - accuracy: 0.8932 - val_loss: 0.7538 - val_accuracy: 0.8450\n",
      "Epoch 4273/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6619 - accuracy: 0.8932 - val_loss: 0.7351 - val_accuracy: 0.8250\n",
      "Epoch 4274/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6527 - accuracy: 0.8978 - val_loss: 0.7635 - val_accuracy: 0.8100\n",
      "Epoch 4275/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6651 - accuracy: 0.8907 - val_loss: 0.7597 - val_accuracy: 0.8217\n",
      "Epoch 4276/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6530 - accuracy: 0.8935 - val_loss: 0.7396 - val_accuracy: 0.8283\n",
      "Epoch 4277/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6579 - accuracy: 0.8980 - val_loss: 0.7536 - val_accuracy: 0.8050\n",
      "Epoch 4278/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6458 - accuracy: 0.8963 - val_loss: 0.7303 - val_accuracy: 0.8300\n",
      "Epoch 4279/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6555 - accuracy: 0.8925 - val_loss: 0.7280 - val_accuracy: 0.8467\n",
      "Epoch 4280/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6576 - accuracy: 0.8943 - val_loss: 0.7852 - val_accuracy: 0.8333\n",
      "Epoch 4281/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6739 - accuracy: 0.8900 - val_loss: 0.7897 - val_accuracy: 0.8217\n",
      "Epoch 4282/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6767 - accuracy: 0.8952 - val_loss: 0.7421 - val_accuracy: 0.8250\n",
      "Epoch 4283/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6741 - accuracy: 0.8887 - val_loss: 0.7316 - val_accuracy: 0.8450\n",
      "Epoch 4284/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6761 - accuracy: 0.8900 - val_loss: 0.7799 - val_accuracy: 0.8467\n",
      "Epoch 4285/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6973 - accuracy: 0.8878 - val_loss: 0.7754 - val_accuracy: 0.8250\n",
      "Epoch 4286/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6664 - accuracy: 0.8925 - val_loss: 0.7989 - val_accuracy: 0.8117\n",
      "Epoch 4287/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6807 - accuracy: 0.8885 - val_loss: 0.7770 - val_accuracy: 0.8200\n",
      "Epoch 4288/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6988 - accuracy: 0.8852 - val_loss: 0.7629 - val_accuracy: 0.8250\n",
      "Epoch 4289/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6807 - accuracy: 0.8913 - val_loss: 0.7616 - val_accuracy: 0.8283\n",
      "Epoch 4290/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6689 - accuracy: 0.8925 - val_loss: 0.7163 - val_accuracy: 0.8417\n",
      "Epoch 4291/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6528 - accuracy: 0.8953 - val_loss: 0.7536 - val_accuracy: 0.8183\n",
      "Epoch 4292/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6623 - accuracy: 0.8927 - val_loss: 0.7801 - val_accuracy: 0.8100\n",
      "Epoch 4293/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6703 - accuracy: 0.8887 - val_loss: 0.7725 - val_accuracy: 0.8350\n",
      "Epoch 4294/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6680 - accuracy: 0.8928 - val_loss: 0.7659 - val_accuracy: 0.8433\n",
      "Epoch 4295/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6855 - accuracy: 0.8935 - val_loss: 0.7701 - val_accuracy: 0.8250\n",
      "Epoch 4296/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.8878 - val_loss: 0.7505 - val_accuracy: 0.8200\n",
      "Epoch 4297/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.8913 - val_loss: 0.7855 - val_accuracy: 0.8167\n",
      "Epoch 4298/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6810 - accuracy: 0.8952 - val_loss: 0.7700 - val_accuracy: 0.8083\n",
      "Epoch 4299/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6747 - accuracy: 0.8978 - val_loss: 0.7553 - val_accuracy: 0.8317\n",
      "Epoch 4300/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6541 - accuracy: 0.8988 - val_loss: 0.7654 - val_accuracy: 0.8233\n",
      "Epoch 4301/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6750 - accuracy: 0.8980 - val_loss: 0.7704 - val_accuracy: 0.8233\n",
      "Epoch 4302/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6874 - accuracy: 0.8945 - val_loss: 0.7839 - val_accuracy: 0.8200\n",
      "Epoch 4303/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6565 - accuracy: 0.9025 - val_loss: 0.7589 - val_accuracy: 0.8283\n",
      "Epoch 4304/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6654 - accuracy: 0.8983 - val_loss: 0.7948 - val_accuracy: 0.8317\n",
      "Epoch 4305/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6881 - accuracy: 0.8953 - val_loss: 0.7745 - val_accuracy: 0.8333\n",
      "Epoch 4306/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6743 - accuracy: 0.8950 - val_loss: 0.7888 - val_accuracy: 0.8367\n",
      "Epoch 4307/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6635 - accuracy: 0.8918 - val_loss: 0.7546 - val_accuracy: 0.8433\n",
      "Epoch 4308/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6828 - accuracy: 0.8943 - val_loss: 0.8319 - val_accuracy: 0.8067\n",
      "Epoch 4309/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7048 - accuracy: 0.8885 - val_loss: 0.7884 - val_accuracy: 0.8267\n",
      "Epoch 4310/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6628 - accuracy: 0.8923 - val_loss: 0.7516 - val_accuracy: 0.8267\n",
      "Epoch 4311/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6981 - accuracy: 0.8835 - val_loss: 0.7808 - val_accuracy: 0.8300\n",
      "Epoch 4312/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6664 - accuracy: 0.8935 - val_loss: 0.7498 - val_accuracy: 0.8400\n",
      "Epoch 4313/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6502 - accuracy: 0.8930 - val_loss: 0.7510 - val_accuracy: 0.8217\n",
      "Epoch 4314/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6668 - accuracy: 0.8992 - val_loss: 0.7863 - val_accuracy: 0.8300\n",
      "Epoch 4315/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6509 - accuracy: 0.9012 - val_loss: 0.7513 - val_accuracy: 0.8317\n",
      "Epoch 4316/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6762 - accuracy: 0.8892 - val_loss: 0.7860 - val_accuracy: 0.8283\n",
      "Epoch 4317/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6695 - accuracy: 0.8920 - val_loss: 0.7579 - val_accuracy: 0.8400\n",
      "Epoch 4318/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6638 - accuracy: 0.8933 - val_loss: 0.7674 - val_accuracy: 0.8383\n",
      "Epoch 4319/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6778 - accuracy: 0.8913 - val_loss: 0.7690 - val_accuracy: 0.8383\n",
      "Epoch 4320/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6548 - accuracy: 0.8943 - val_loss: 0.7715 - val_accuracy: 0.8317\n",
      "Epoch 4321/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6739 - accuracy: 0.8997 - val_loss: 0.7697 - val_accuracy: 0.8283\n",
      "Epoch 4322/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6781 - accuracy: 0.8920 - val_loss: 0.7751 - val_accuracy: 0.8383\n",
      "Epoch 4323/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6854 - accuracy: 0.8888 - val_loss: 0.7799 - val_accuracy: 0.8150\n",
      "Epoch 4324/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6803 - accuracy: 0.8930 - val_loss: 0.7785 - val_accuracy: 0.8417\n",
      "Epoch 4325/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.8902 - val_loss: 0.7969 - val_accuracy: 0.8383\n",
      "Epoch 4326/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6806 - accuracy: 0.8962 - val_loss: 0.8110 - val_accuracy: 0.8400\n",
      "Epoch 4327/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6743 - accuracy: 0.8942 - val_loss: 0.8311 - val_accuracy: 0.8167\n",
      "Epoch 4328/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6815 - accuracy: 0.8963 - val_loss: 0.8083 - val_accuracy: 0.8133\n",
      "Epoch 4329/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6676 - accuracy: 0.9003 - val_loss: 0.8108 - val_accuracy: 0.8067\n",
      "Epoch 4330/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6675 - accuracy: 0.8975 - val_loss: 0.7740 - val_accuracy: 0.8267\n",
      "Epoch 4331/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6608 - accuracy: 0.8997 - val_loss: 0.7883 - val_accuracy: 0.8267\n",
      "Epoch 4332/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6485 - accuracy: 0.8968 - val_loss: 0.7629 - val_accuracy: 0.8267\n",
      "Epoch 4333/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6715 - accuracy: 0.8978 - val_loss: 0.7759 - val_accuracy: 0.8317\n",
      "Epoch 4334/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6595 - accuracy: 0.8992 - val_loss: 0.8046 - val_accuracy: 0.8233\n",
      "Epoch 4335/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6382 - accuracy: 0.9025 - val_loss: 0.7820 - val_accuracy: 0.8150\n",
      "Epoch 4336/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6825 - accuracy: 0.8955 - val_loss: 0.7897 - val_accuracy: 0.8167\n",
      "Epoch 4337/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6761 - accuracy: 0.9022 - val_loss: 0.7879 - val_accuracy: 0.8050\n",
      "Epoch 4338/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6539 - accuracy: 0.8985 - val_loss: 0.7918 - val_accuracy: 0.8083\n",
      "Epoch 4339/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6697 - accuracy: 0.8937 - val_loss: 0.7650 - val_accuracy: 0.8200\n",
      "Epoch 4340/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6537 - accuracy: 0.8977 - val_loss: 0.7813 - val_accuracy: 0.8233\n",
      "Epoch 4341/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6692 - accuracy: 0.8947 - val_loss: 0.7634 - val_accuracy: 0.8300\n",
      "Epoch 4342/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6810 - accuracy: 0.8925 - val_loss: 0.7976 - val_accuracy: 0.8267\n",
      "Epoch 4343/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6707 - accuracy: 0.8910 - val_loss: 0.7900 - val_accuracy: 0.8150\n",
      "Epoch 4344/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6576 - accuracy: 0.8983 - val_loss: 0.7636 - val_accuracy: 0.8300\n",
      "Epoch 4345/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.8933 - val_loss: 0.7660 - val_accuracy: 0.8283\n",
      "Epoch 4346/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.8925 - val_loss: 0.8139 - val_accuracy: 0.8200\n",
      "Epoch 4347/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6773 - accuracy: 0.8938 - val_loss: 0.8328 - val_accuracy: 0.8083\n",
      "Epoch 4348/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6693 - accuracy: 0.8937 - val_loss: 0.7936 - val_accuracy: 0.8367\n",
      "Epoch 4349/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6717 - accuracy: 0.9003 - val_loss: 0.8143 - val_accuracy: 0.8183\n",
      "Epoch 4350/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6678 - accuracy: 0.8975 - val_loss: 0.8207 - val_accuracy: 0.8317\n",
      "Epoch 4351/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6564 - accuracy: 0.8968 - val_loss: 0.8472 - val_accuracy: 0.8183\n",
      "Epoch 4352/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6792 - accuracy: 0.8995 - val_loss: 0.8322 - val_accuracy: 0.8333\n",
      "Epoch 4353/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6621 - accuracy: 0.8987 - val_loss: 0.8132 - val_accuracy: 0.8167\n",
      "Epoch 4354/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6648 - accuracy: 0.8975 - val_loss: 0.8314 - val_accuracy: 0.8367\n",
      "Epoch 4355/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6487 - accuracy: 0.8998 - val_loss: 0.8071 - val_accuracy: 0.8350\n",
      "Epoch 4356/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6624 - accuracy: 0.8955 - val_loss: 0.7709 - val_accuracy: 0.8367\n",
      "Epoch 4357/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6586 - accuracy: 0.8980 - val_loss: 0.8364 - val_accuracy: 0.8050\n",
      "Epoch 4358/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6473 - accuracy: 0.8983 - val_loss: 0.7796 - val_accuracy: 0.8200\n",
      "Epoch 4359/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6985 - accuracy: 0.8865 - val_loss: 0.7888 - val_accuracy: 0.8050\n",
      "Epoch 4360/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6772 - accuracy: 0.8942 - val_loss: 0.8154 - val_accuracy: 0.8083\n",
      "Epoch 4361/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6642 - accuracy: 0.8947 - val_loss: 0.7753 - val_accuracy: 0.8117\n",
      "Epoch 4362/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6755 - accuracy: 0.8912 - val_loss: 0.7852 - val_accuracy: 0.8283\n",
      "Epoch 4363/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6581 - accuracy: 0.8935 - val_loss: 0.7871 - val_accuracy: 0.8233\n",
      "Epoch 4364/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6839 - accuracy: 0.8948 - val_loss: 0.7713 - val_accuracy: 0.8333\n",
      "Epoch 4365/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6507 - accuracy: 0.9048 - val_loss: 0.7712 - val_accuracy: 0.8183\n",
      "Epoch 4366/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6633 - accuracy: 0.8993 - val_loss: 0.7768 - val_accuracy: 0.8233\n",
      "Epoch 4367/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6680 - accuracy: 0.8963 - val_loss: 0.7883 - val_accuracy: 0.8117\n",
      "Epoch 4368/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6861 - accuracy: 0.8935 - val_loss: 0.8174 - val_accuracy: 0.8217\n",
      "Epoch 4369/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6777 - accuracy: 0.8972 - val_loss: 0.7732 - val_accuracy: 0.8283\n",
      "Epoch 4370/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6680 - accuracy: 0.8957 - val_loss: 0.8006 - val_accuracy: 0.8083\n",
      "Epoch 4371/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6608 - accuracy: 0.8977 - val_loss: 0.7741 - val_accuracy: 0.8133\n",
      "Epoch 4372/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6537 - accuracy: 0.8928 - val_loss: 0.7751 - val_accuracy: 0.8233\n",
      "Epoch 4373/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6391 - accuracy: 0.9007 - val_loss: 0.7751 - val_accuracy: 0.8133\n",
      "Epoch 4374/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6238 - accuracy: 0.9058 - val_loss: 0.7835 - val_accuracy: 0.8300\n",
      "Epoch 4375/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6550 - accuracy: 0.9040 - val_loss: 0.7935 - val_accuracy: 0.8000\n",
      "Epoch 4376/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6743 - accuracy: 0.8982 - val_loss: 0.7856 - val_accuracy: 0.8300\n",
      "Epoch 4377/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6586 - accuracy: 0.9000 - val_loss: 0.7711 - val_accuracy: 0.8233\n",
      "Epoch 4378/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6465 - accuracy: 0.9008 - val_loss: 0.7773 - val_accuracy: 0.8217\n",
      "Epoch 4379/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6640 - accuracy: 0.9012 - val_loss: 0.8292 - val_accuracy: 0.8200\n",
      "Epoch 4380/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6606 - accuracy: 0.9003 - val_loss: 0.8081 - val_accuracy: 0.8150\n",
      "Epoch 4381/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6683 - accuracy: 0.8975 - val_loss: 0.8082 - val_accuracy: 0.8067\n",
      "Epoch 4382/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6851 - accuracy: 0.8987 - val_loss: 0.7859 - val_accuracy: 0.8000\n",
      "Epoch 4383/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6700 - accuracy: 0.8930 - val_loss: 0.8564 - val_accuracy: 0.7900\n",
      "Epoch 4384/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6522 - accuracy: 0.9002 - val_loss: 0.8226 - val_accuracy: 0.8283\n",
      "Epoch 4385/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6507 - accuracy: 0.8977 - val_loss: 0.7767 - val_accuracy: 0.8133\n",
      "Epoch 4386/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7027 - accuracy: 0.8872 - val_loss: 0.8040 - val_accuracy: 0.8050\n",
      "Epoch 4387/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6435 - accuracy: 0.8972 - val_loss: 0.7616 - val_accuracy: 0.8233\n",
      "Epoch 4388/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6704 - accuracy: 0.8992 - val_loss: 0.7754 - val_accuracy: 0.8117\n",
      "Epoch 4389/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6653 - accuracy: 0.8957 - val_loss: 0.8024 - val_accuracy: 0.8100\n",
      "Epoch 4390/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6881 - accuracy: 0.9015 - val_loss: 0.8210 - val_accuracy: 0.8117\n",
      "Epoch 4391/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6627 - accuracy: 0.9000 - val_loss: 0.8008 - val_accuracy: 0.8183\n",
      "Epoch 4392/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6695 - accuracy: 0.8935 - val_loss: 0.8172 - val_accuracy: 0.8317\n",
      "Epoch 4393/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6428 - accuracy: 0.9013 - val_loss: 0.8095 - val_accuracy: 0.8200\n",
      "Epoch 4394/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6440 - accuracy: 0.8975 - val_loss: 0.7897 - val_accuracy: 0.8217\n",
      "Epoch 4395/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6822 - accuracy: 0.8935 - val_loss: 0.8018 - val_accuracy: 0.8317\n",
      "Epoch 4396/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6545 - accuracy: 0.8967 - val_loss: 0.7590 - val_accuracy: 0.8383\n",
      "Epoch 4397/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6418 - accuracy: 0.9020 - val_loss: 0.7914 - val_accuracy: 0.8200\n",
      "Epoch 4398/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6785 - accuracy: 0.8975 - val_loss: 0.7949 - val_accuracy: 0.8283\n",
      "Epoch 4399/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6645 - accuracy: 0.8935 - val_loss: 0.7858 - val_accuracy: 0.8350\n",
      "Epoch 4400/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6479 - accuracy: 0.8997 - val_loss: 0.7950 - val_accuracy: 0.8333\n",
      "Epoch 4401/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6691 - accuracy: 0.8960 - val_loss: 0.7688 - val_accuracy: 0.8300\n",
      "Epoch 4402/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6568 - accuracy: 0.9018 - val_loss: 0.7727 - val_accuracy: 0.8150\n",
      "Epoch 4403/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6551 - accuracy: 0.8977 - val_loss: 0.7869 - val_accuracy: 0.8267\n",
      "Epoch 4404/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6636 - accuracy: 0.9018 - val_loss: 0.7480 - val_accuracy: 0.8233\n",
      "Epoch 4405/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6800 - accuracy: 0.8997 - val_loss: 0.7280 - val_accuracy: 0.8383\n",
      "Epoch 4406/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6596 - accuracy: 0.8962 - val_loss: 0.7510 - val_accuracy: 0.8183\n",
      "Epoch 4407/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6565 - accuracy: 0.8982 - val_loss: 0.7739 - val_accuracy: 0.8283\n",
      "Epoch 4408/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6573 - accuracy: 0.8943 - val_loss: 0.7895 - val_accuracy: 0.8167\n",
      "Epoch 4409/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6540 - accuracy: 0.8972 - val_loss: 0.7902 - val_accuracy: 0.8183\n",
      "Epoch 4410/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6610 - accuracy: 0.9040 - val_loss: 0.7570 - val_accuracy: 0.8233\n",
      "Epoch 4411/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6661 - accuracy: 0.8973 - val_loss: 0.8003 - val_accuracy: 0.8067\n",
      "Epoch 4412/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6658 - accuracy: 0.8977 - val_loss: 0.8293 - val_accuracy: 0.8033\n",
      "Epoch 4413/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6889 - accuracy: 0.8992 - val_loss: 0.7919 - val_accuracy: 0.8083\n",
      "Epoch 4414/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6370 - accuracy: 0.8993 - val_loss: 0.7716 - val_accuracy: 0.8133\n",
      "Epoch 4415/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6638 - accuracy: 0.8957 - val_loss: 0.7242 - val_accuracy: 0.8200\n",
      "Epoch 4416/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6633 - accuracy: 0.8948 - val_loss: 0.7602 - val_accuracy: 0.8133\n",
      "Epoch 4417/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6590 - accuracy: 0.9005 - val_loss: 0.7425 - val_accuracy: 0.8050\n",
      "Epoch 4418/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6688 - accuracy: 0.8970 - val_loss: 0.7176 - val_accuracy: 0.8300\n",
      "Epoch 4419/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6789 - accuracy: 0.8990 - val_loss: 0.7634 - val_accuracy: 0.8150\n",
      "Epoch 4420/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6569 - accuracy: 0.9013 - val_loss: 0.7403 - val_accuracy: 0.8267\n",
      "Epoch 4421/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6566 - accuracy: 0.8990 - val_loss: 0.7609 - val_accuracy: 0.8200\n",
      "Epoch 4422/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6771 - accuracy: 0.8952 - val_loss: 0.7628 - val_accuracy: 0.8217\n",
      "Epoch 4423/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6840 - accuracy: 0.8930 - val_loss: 0.7352 - val_accuracy: 0.8367\n",
      "Epoch 4424/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6691 - accuracy: 0.8995 - val_loss: 0.7428 - val_accuracy: 0.8267\n",
      "Epoch 4425/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6674 - accuracy: 0.8965 - val_loss: 0.7526 - val_accuracy: 0.8167\n",
      "Epoch 4426/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6661 - accuracy: 0.8990 - val_loss: 0.7435 - val_accuracy: 0.8317\n",
      "Epoch 4427/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6664 - accuracy: 0.9010 - val_loss: 0.7514 - val_accuracy: 0.8333\n",
      "Epoch 4428/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6454 - accuracy: 0.9032 - val_loss: 0.8029 - val_accuracy: 0.8333\n",
      "Epoch 4429/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6659 - accuracy: 0.9003 - val_loss: 0.7920 - val_accuracy: 0.8100\n",
      "Epoch 4430/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6697 - accuracy: 0.8983 - val_loss: 0.7931 - val_accuracy: 0.8267\n",
      "Epoch 4431/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6609 - accuracy: 0.9040 - val_loss: 0.7969 - val_accuracy: 0.8283\n",
      "Epoch 4432/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6489 - accuracy: 0.9028 - val_loss: 0.7938 - val_accuracy: 0.8350\n",
      "Epoch 4433/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6572 - accuracy: 0.8993 - val_loss: 0.7970 - val_accuracy: 0.8050\n",
      "Epoch 4434/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6822 - accuracy: 0.8943 - val_loss: 0.8022 - val_accuracy: 0.8217\n",
      "Epoch 4435/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6787 - accuracy: 0.8967 - val_loss: 0.7977 - val_accuracy: 0.8183\n",
      "Epoch 4436/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6671 - accuracy: 0.8985 - val_loss: 0.7949 - val_accuracy: 0.8317\n",
      "Epoch 4437/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6480 - accuracy: 0.8983 - val_loss: 0.7607 - val_accuracy: 0.8233\n",
      "Epoch 4438/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6487 - accuracy: 0.9040 - val_loss: 0.7738 - val_accuracy: 0.8200\n",
      "Epoch 4439/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6404 - accuracy: 0.9025 - val_loss: 0.7427 - val_accuracy: 0.8333\n",
      "Epoch 4440/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6592 - accuracy: 0.8943 - val_loss: 0.7844 - val_accuracy: 0.8017\n",
      "Epoch 4441/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6467 - accuracy: 0.8962 - val_loss: 0.7996 - val_accuracy: 0.7933\n",
      "Epoch 4442/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6736 - accuracy: 0.8940 - val_loss: 0.7659 - val_accuracy: 0.8267\n",
      "Epoch 4443/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6584 - accuracy: 0.8993 - val_loss: 0.7693 - val_accuracy: 0.8233\n",
      "Epoch 4444/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.8925 - val_loss: 0.7898 - val_accuracy: 0.8267\n",
      "Epoch 4445/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6812 - accuracy: 0.8982 - val_loss: 0.7849 - val_accuracy: 0.8317\n",
      "Epoch 4446/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6889 - accuracy: 0.8920 - val_loss: 0.7784 - val_accuracy: 0.8300\n",
      "Epoch 4447/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6630 - accuracy: 0.9065 - val_loss: 0.7614 - val_accuracy: 0.8283\n",
      "Epoch 4448/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6701 - accuracy: 0.8952 - val_loss: 0.7919 - val_accuracy: 0.8183\n",
      "Epoch 4449/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6810 - accuracy: 0.8972 - val_loss: 0.7809 - val_accuracy: 0.8300\n",
      "Epoch 4450/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6278 - accuracy: 0.9055 - val_loss: 0.7608 - val_accuracy: 0.8317\n",
      "Epoch 4451/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6735 - accuracy: 0.8993 - val_loss: 0.8401 - val_accuracy: 0.8150\n",
      "Epoch 4452/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6803 - accuracy: 0.9015 - val_loss: 0.7949 - val_accuracy: 0.8317\n",
      "Epoch 4453/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6448 - accuracy: 0.9048 - val_loss: 0.8091 - val_accuracy: 0.8317\n",
      "Epoch 4454/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6718 - accuracy: 0.9005 - val_loss: 0.8006 - val_accuracy: 0.8217\n",
      "Epoch 4455/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6565 - accuracy: 0.9022 - val_loss: 0.7885 - val_accuracy: 0.8233\n",
      "Epoch 4456/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6764 - accuracy: 0.8938 - val_loss: 0.7948 - val_accuracy: 0.8250\n",
      "Epoch 4457/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6546 - accuracy: 0.9020 - val_loss: 0.8198 - val_accuracy: 0.8150\n",
      "Epoch 4458/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6750 - accuracy: 0.8967 - val_loss: 0.7973 - val_accuracy: 0.8217\n",
      "Epoch 4459/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6639 - accuracy: 0.8980 - val_loss: 0.7849 - val_accuracy: 0.8150\n",
      "Epoch 4460/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6546 - accuracy: 0.9038 - val_loss: 0.8553 - val_accuracy: 0.8233\n",
      "Epoch 4461/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6334 - accuracy: 0.9053 - val_loss: 0.8048 - val_accuracy: 0.8283\n",
      "Epoch 4462/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6531 - accuracy: 0.9007 - val_loss: 0.8156 - val_accuracy: 0.8283\n",
      "Epoch 4463/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6717 - accuracy: 0.8972 - val_loss: 0.7775 - val_accuracy: 0.8267\n",
      "Epoch 4464/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6757 - accuracy: 0.9028 - val_loss: 0.8048 - val_accuracy: 0.8300\n",
      "Epoch 4465/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7065 - accuracy: 0.8922 - val_loss: 0.8140 - val_accuracy: 0.8350\n",
      "Epoch 4466/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6671 - accuracy: 0.9008 - val_loss: 0.8058 - val_accuracy: 0.8300\n",
      "Epoch 4467/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6608 - accuracy: 0.8973 - val_loss: 0.8314 - val_accuracy: 0.8450\n",
      "Epoch 4468/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6644 - accuracy: 0.9018 - val_loss: 0.7807 - val_accuracy: 0.8300\n",
      "Epoch 4469/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6644 - accuracy: 0.9037 - val_loss: 0.8100 - val_accuracy: 0.8217\n",
      "Epoch 4470/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6691 - accuracy: 0.9030 - val_loss: 0.8264 - val_accuracy: 0.8150\n",
      "Epoch 4471/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6956 - accuracy: 0.8923 - val_loss: 0.8281 - val_accuracy: 0.8250\n",
      "Epoch 4472/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6925 - accuracy: 0.9018 - val_loss: 0.7731 - val_accuracy: 0.8433\n",
      "Epoch 4473/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6757 - accuracy: 0.8997 - val_loss: 0.8082 - val_accuracy: 0.8300\n",
      "Epoch 4474/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6828 - accuracy: 0.8982 - val_loss: 0.7925 - val_accuracy: 0.8283\n",
      "Epoch 4475/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.8990 - val_loss: 0.8378 - val_accuracy: 0.8150\n",
      "Epoch 4476/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6570 - accuracy: 0.9013 - val_loss: 0.8010 - val_accuracy: 0.8300\n",
      "Epoch 4477/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6650 - accuracy: 0.8973 - val_loss: 0.8033 - val_accuracy: 0.8433\n",
      "Epoch 4478/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.9047 - val_loss: 0.8104 - val_accuracy: 0.8317\n",
      "Epoch 4479/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6401 - accuracy: 0.9033 - val_loss: 0.8018 - val_accuracy: 0.8200\n",
      "Epoch 4480/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6560 - accuracy: 0.9062 - val_loss: 0.7957 - val_accuracy: 0.8267\n",
      "Epoch 4481/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6853 - accuracy: 0.8953 - val_loss: 0.8544 - val_accuracy: 0.8233\n",
      "Epoch 4482/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6525 - accuracy: 0.9018 - val_loss: 0.8064 - val_accuracy: 0.8117\n",
      "Epoch 4483/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6415 - accuracy: 0.9033 - val_loss: 0.7792 - val_accuracy: 0.8200\n",
      "Epoch 4484/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6595 - accuracy: 0.9005 - val_loss: 0.7775 - val_accuracy: 0.8200\n",
      "Epoch 4485/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6508 - accuracy: 0.9020 - val_loss: 0.8043 - val_accuracy: 0.8117\n",
      "Epoch 4486/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6747 - accuracy: 0.8995 - val_loss: 0.8092 - val_accuracy: 0.8217\n",
      "Epoch 4487/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6519 - accuracy: 0.9007 - val_loss: 0.7892 - val_accuracy: 0.8117\n",
      "Epoch 4488/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6790 - accuracy: 0.8980 - val_loss: 0.7874 - val_accuracy: 0.8233\n",
      "Epoch 4489/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6664 - accuracy: 0.8998 - val_loss: 0.7937 - val_accuracy: 0.8133\n",
      "Epoch 4490/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6625 - accuracy: 0.9080 - val_loss: 0.8210 - val_accuracy: 0.8067\n",
      "Epoch 4491/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6801 - accuracy: 0.8968 - val_loss: 0.8119 - val_accuracy: 0.8283\n",
      "Epoch 4492/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6636 - accuracy: 0.9020 - val_loss: 0.7979 - val_accuracy: 0.8300\n",
      "Epoch 4493/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6739 - accuracy: 0.9002 - val_loss: 0.7861 - val_accuracy: 0.8300\n",
      "Epoch 4494/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6780 - accuracy: 0.9010 - val_loss: 0.8450 - val_accuracy: 0.8200\n",
      "Epoch 4495/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6827 - accuracy: 0.8918 - val_loss: 0.7974 - val_accuracy: 0.8267\n",
      "Epoch 4496/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6548 - accuracy: 0.9050 - val_loss: 0.8071 - val_accuracy: 0.8233\n",
      "Epoch 4497/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6791 - accuracy: 0.9005 - val_loss: 0.8036 - val_accuracy: 0.8250\n",
      "Epoch 4498/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6760 - accuracy: 0.8985 - val_loss: 0.7835 - val_accuracy: 0.8317\n",
      "Epoch 4499/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6596 - accuracy: 0.8982 - val_loss: 0.7855 - val_accuracy: 0.8467\n",
      "Epoch 4500/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6595 - accuracy: 0.9062 - val_loss: 0.7997 - val_accuracy: 0.8117\n",
      "Epoch 4501/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6709 - accuracy: 0.9032 - val_loss: 0.8098 - val_accuracy: 0.8183\n",
      "Epoch 4502/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6555 - accuracy: 0.8997 - val_loss: 0.8078 - val_accuracy: 0.8317\n",
      "Epoch 4503/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6726 - accuracy: 0.9037 - val_loss: 0.8491 - val_accuracy: 0.8133\n",
      "Epoch 4504/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6536 - accuracy: 0.9055 - val_loss: 0.8428 - val_accuracy: 0.8183\n",
      "Epoch 4505/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6497 - accuracy: 0.9060 - val_loss: 0.8408 - val_accuracy: 0.8283\n",
      "Epoch 4506/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6907 - accuracy: 0.8933 - val_loss: 0.8750 - val_accuracy: 0.8117\n",
      "Epoch 4507/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6648 - accuracy: 0.8982 - val_loss: 0.8164 - val_accuracy: 0.8233\n",
      "Epoch 4508/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6404 - accuracy: 0.9075 - val_loss: 0.8329 - val_accuracy: 0.8250\n",
      "Epoch 4509/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6649 - accuracy: 0.9012 - val_loss: 0.7862 - val_accuracy: 0.8517\n",
      "Epoch 4510/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6607 - accuracy: 0.9005 - val_loss: 0.7958 - val_accuracy: 0.8217\n",
      "Epoch 4511/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6805 - accuracy: 0.8978 - val_loss: 0.8020 - val_accuracy: 0.8333\n",
      "Epoch 4512/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6821 - accuracy: 0.9005 - val_loss: 0.8060 - val_accuracy: 0.8250\n",
      "Epoch 4513/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6700 - accuracy: 0.8937 - val_loss: 0.8075 - val_accuracy: 0.8167\n",
      "Epoch 4514/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6448 - accuracy: 0.9095 - val_loss: 0.7961 - val_accuracy: 0.8233\n",
      "Epoch 4515/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6672 - accuracy: 0.8983 - val_loss: 0.8085 - val_accuracy: 0.8050\n",
      "Epoch 4516/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6498 - accuracy: 0.9045 - val_loss: 0.7766 - val_accuracy: 0.8217\n",
      "Epoch 4517/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6522 - accuracy: 0.9030 - val_loss: 0.7572 - val_accuracy: 0.8267\n",
      "Epoch 4518/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6553 - accuracy: 0.9017 - val_loss: 0.7942 - val_accuracy: 0.8233\n",
      "Epoch 4519/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6740 - accuracy: 0.9010 - val_loss: 0.7734 - val_accuracy: 0.8417\n",
      "Epoch 4520/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6489 - accuracy: 0.9028 - val_loss: 0.7944 - val_accuracy: 0.8183\n",
      "Epoch 4521/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6461 - accuracy: 0.9070 - val_loss: 0.7864 - val_accuracy: 0.8283\n",
      "Epoch 4522/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6788 - accuracy: 0.9020 - val_loss: 0.7595 - val_accuracy: 0.8250\n",
      "Epoch 4523/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6659 - accuracy: 0.8982 - val_loss: 0.7848 - val_accuracy: 0.8150\n",
      "Epoch 4524/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6792 - accuracy: 0.8947 - val_loss: 0.7858 - val_accuracy: 0.8400\n",
      "Epoch 4525/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6715 - accuracy: 0.9030 - val_loss: 0.7745 - val_accuracy: 0.8300\n",
      "Epoch 4526/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6739 - accuracy: 0.9033 - val_loss: 0.7810 - val_accuracy: 0.8217\n",
      "Epoch 4527/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6504 - accuracy: 0.9043 - val_loss: 0.7607 - val_accuracy: 0.8283\n",
      "Epoch 4528/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6687 - accuracy: 0.9008 - val_loss: 0.7888 - val_accuracy: 0.8233\n",
      "Epoch 4529/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6816 - accuracy: 0.9002 - val_loss: 0.7993 - val_accuracy: 0.8100\n",
      "Epoch 4530/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6757 - accuracy: 0.8978 - val_loss: 0.8112 - val_accuracy: 0.8117\n",
      "Epoch 4531/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6621 - accuracy: 0.9112 - val_loss: 0.7820 - val_accuracy: 0.8317\n",
      "Epoch 4532/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6376 - accuracy: 0.9072 - val_loss: 0.7965 - val_accuracy: 0.8183\n",
      "Epoch 4533/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6750 - accuracy: 0.9005 - val_loss: 0.7686 - val_accuracy: 0.8317\n",
      "Epoch 4534/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6531 - accuracy: 0.9057 - val_loss: 0.7733 - val_accuracy: 0.8250\n",
      "Epoch 4535/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6648 - accuracy: 0.8997 - val_loss: 0.7705 - val_accuracy: 0.8283\n",
      "Epoch 4536/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6599 - accuracy: 0.9058 - val_loss: 0.7372 - val_accuracy: 0.8367\n",
      "Epoch 4537/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6494 - accuracy: 0.9042 - val_loss: 0.7921 - val_accuracy: 0.8200\n",
      "Epoch 4538/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6870 - accuracy: 0.9000 - val_loss: 0.7976 - val_accuracy: 0.8200\n",
      "Epoch 4539/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6351 - accuracy: 0.9052 - val_loss: 0.7575 - val_accuracy: 0.8317\n",
      "Epoch 4540/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6723 - accuracy: 0.9003 - val_loss: 0.7982 - val_accuracy: 0.8233\n",
      "Epoch 4541/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6687 - accuracy: 0.8988 - val_loss: 0.7569 - val_accuracy: 0.8350\n",
      "Epoch 4542/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6684 - accuracy: 0.9018 - val_loss: 0.7615 - val_accuracy: 0.8317\n",
      "Epoch 4543/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6622 - accuracy: 0.9030 - val_loss: 0.8068 - val_accuracy: 0.8167\n",
      "Epoch 4544/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6442 - accuracy: 0.9067 - val_loss: 0.8189 - val_accuracy: 0.8250\n",
      "Epoch 4545/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6332 - accuracy: 0.9135 - val_loss: 0.7800 - val_accuracy: 0.8233\n",
      "Epoch 4546/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6532 - accuracy: 0.9043 - val_loss: 0.8196 - val_accuracy: 0.8250\n",
      "Epoch 4547/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6794 - accuracy: 0.9013 - val_loss: 0.8008 - val_accuracy: 0.8233\n",
      "Epoch 4548/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6651 - accuracy: 0.9053 - val_loss: 0.7710 - val_accuracy: 0.8400\n",
      "Epoch 4549/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6589 - accuracy: 0.9000 - val_loss: 0.7498 - val_accuracy: 0.8317\n",
      "Epoch 4550/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6723 - accuracy: 0.9045 - val_loss: 0.8057 - val_accuracy: 0.8083\n",
      "Epoch 4551/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6827 - accuracy: 0.9015 - val_loss: 0.7768 - val_accuracy: 0.8317\n",
      "Epoch 4552/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7082 - accuracy: 0.8963 - val_loss: 0.8378 - val_accuracy: 0.8050\n",
      "Epoch 4553/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7047 - accuracy: 0.8973 - val_loss: 0.8254 - val_accuracy: 0.8267\n",
      "Epoch 4554/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7103 - accuracy: 0.8963 - val_loss: 0.7973 - val_accuracy: 0.8200\n",
      "Epoch 4555/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6841 - accuracy: 0.9025 - val_loss: 0.7832 - val_accuracy: 0.8133\n",
      "Epoch 4556/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7200 - accuracy: 0.8978 - val_loss: 0.8297 - val_accuracy: 0.7933\n",
      "Epoch 4557/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6691 - accuracy: 0.9027 - val_loss: 0.8031 - val_accuracy: 0.8017\n",
      "Epoch 4558/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6702 - accuracy: 0.9022 - val_loss: 0.7488 - val_accuracy: 0.8300\n",
      "Epoch 4559/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7008 - accuracy: 0.8918 - val_loss: 0.8235 - val_accuracy: 0.8467\n",
      "Epoch 4560/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6715 - accuracy: 0.9028 - val_loss: 0.7885 - val_accuracy: 0.8367\n",
      "Epoch 4561/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6797 - accuracy: 0.8955 - val_loss: 0.8420 - val_accuracy: 0.8183\n",
      "Epoch 4562/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6822 - accuracy: 0.9025 - val_loss: 0.8211 - val_accuracy: 0.8183\n",
      "Epoch 4563/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6679 - accuracy: 0.8995 - val_loss: 0.8065 - val_accuracy: 0.8300\n",
      "Epoch 4564/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6680 - accuracy: 0.9023 - val_loss: 0.7832 - val_accuracy: 0.8417\n",
      "Epoch 4565/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6804 - accuracy: 0.8985 - val_loss: 0.8636 - val_accuracy: 0.8050\n",
      "Epoch 4566/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6669 - accuracy: 0.8973 - val_loss: 0.8184 - val_accuracy: 0.8067\n",
      "Epoch 4567/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6311 - accuracy: 0.9065 - val_loss: 0.7990 - val_accuracy: 0.8450\n",
      "Epoch 4568/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6446 - accuracy: 0.9060 - val_loss: 0.7898 - val_accuracy: 0.8483\n",
      "Epoch 4569/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6703 - accuracy: 0.9003 - val_loss: 0.8157 - val_accuracy: 0.8283\n",
      "Epoch 4570/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6615 - accuracy: 0.9007 - val_loss: 0.8222 - val_accuracy: 0.8200\n",
      "Epoch 4571/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6870 - accuracy: 0.8933 - val_loss: 0.8254 - val_accuracy: 0.8217\n",
      "Epoch 4572/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6800 - accuracy: 0.9023 - val_loss: 0.7756 - val_accuracy: 0.8283\n",
      "Epoch 4573/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6537 - accuracy: 0.9033 - val_loss: 0.7718 - val_accuracy: 0.8400\n",
      "Epoch 4574/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6532 - accuracy: 0.9050 - val_loss: 0.7959 - val_accuracy: 0.8333\n",
      "Epoch 4575/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6688 - accuracy: 0.9035 - val_loss: 0.7427 - val_accuracy: 0.8517\n",
      "Epoch 4576/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6491 - accuracy: 0.9060 - val_loss: 0.7821 - val_accuracy: 0.8200\n",
      "Epoch 4577/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6543 - accuracy: 0.9087 - val_loss: 0.7805 - val_accuracy: 0.8217\n",
      "Epoch 4578/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6663 - accuracy: 0.9032 - val_loss: 0.7891 - val_accuracy: 0.8300\n",
      "Epoch 4579/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6664 - accuracy: 0.8977 - val_loss: 0.8003 - val_accuracy: 0.8383\n",
      "Epoch 4580/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6585 - accuracy: 0.9055 - val_loss: 0.7929 - val_accuracy: 0.8200\n",
      "Epoch 4581/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6728 - accuracy: 0.9057 - val_loss: 0.8077 - val_accuracy: 0.8267\n",
      "Epoch 4582/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6762 - accuracy: 0.9023 - val_loss: 0.7944 - val_accuracy: 0.8267\n",
      "Epoch 4583/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6459 - accuracy: 0.9040 - val_loss: 0.8082 - val_accuracy: 0.8200\n",
      "Epoch 4584/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6496 - accuracy: 0.9043 - val_loss: 0.8182 - val_accuracy: 0.8067\n",
      "Epoch 4585/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6972 - accuracy: 0.9003 - val_loss: 0.8109 - val_accuracy: 0.8183\n",
      "Epoch 4586/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6773 - accuracy: 0.9022 - val_loss: 0.8164 - val_accuracy: 0.8150\n",
      "Epoch 4587/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6954 - accuracy: 0.9022 - val_loss: 0.8405 - val_accuracy: 0.7983\n",
      "Epoch 4588/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6666 - accuracy: 0.9077 - val_loss: 0.8134 - val_accuracy: 0.8083\n",
      "Epoch 4589/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6587 - accuracy: 0.9062 - val_loss: 0.8172 - val_accuracy: 0.8217\n",
      "Epoch 4590/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6609 - accuracy: 0.9082 - val_loss: 0.8201 - val_accuracy: 0.8300\n",
      "Epoch 4591/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6475 - accuracy: 0.9037 - val_loss: 0.8244 - val_accuracy: 0.8350\n",
      "Epoch 4592/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6573 - accuracy: 0.9048 - val_loss: 0.8094 - val_accuracy: 0.8233\n",
      "Epoch 4593/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6599 - accuracy: 0.9035 - val_loss: 0.8627 - val_accuracy: 0.8183\n",
      "Epoch 4594/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6794 - accuracy: 0.8978 - val_loss: 0.8430 - val_accuracy: 0.8250\n",
      "Epoch 4595/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6846 - accuracy: 0.8970 - val_loss: 0.7871 - val_accuracy: 0.8417\n",
      "Epoch 4596/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7074 - accuracy: 0.8958 - val_loss: 0.8290 - val_accuracy: 0.8333\n",
      "Epoch 4597/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6973 - accuracy: 0.8947 - val_loss: 0.8339 - val_accuracy: 0.8183\n",
      "Epoch 4598/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6568 - accuracy: 0.9028 - val_loss: 0.8252 - val_accuracy: 0.8083\n",
      "Epoch 4599/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6498 - accuracy: 0.9045 - val_loss: 0.7900 - val_accuracy: 0.8317\n",
      "Epoch 4600/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6487 - accuracy: 0.9027 - val_loss: 0.8428 - val_accuracy: 0.8233\n",
      "Epoch 4601/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6428 - accuracy: 0.9072 - val_loss: 0.7938 - val_accuracy: 0.8250\n",
      "Epoch 4602/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6393 - accuracy: 0.9093 - val_loss: 0.8123 - val_accuracy: 0.8350\n",
      "Epoch 4603/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6490 - accuracy: 0.9042 - val_loss: 0.8243 - val_accuracy: 0.8300\n",
      "Epoch 4604/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6480 - accuracy: 0.9050 - val_loss: 0.7753 - val_accuracy: 0.8250\n",
      "Epoch 4605/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6492 - accuracy: 0.9022 - val_loss: 0.8133 - val_accuracy: 0.8133\n",
      "Epoch 4606/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6826 - accuracy: 0.8935 - val_loss: 0.8155 - val_accuracy: 0.8317\n",
      "Epoch 4607/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6641 - accuracy: 0.8995 - val_loss: 0.7670 - val_accuracy: 0.8367\n",
      "Epoch 4608/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6456 - accuracy: 0.9125 - val_loss: 0.7548 - val_accuracy: 0.8383\n",
      "Epoch 4609/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6700 - accuracy: 0.9013 - val_loss: 0.7993 - val_accuracy: 0.8300\n",
      "Epoch 4610/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6807 - accuracy: 0.8980 - val_loss: 0.8101 - val_accuracy: 0.8350\n",
      "Epoch 4611/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6859 - accuracy: 0.9020 - val_loss: 0.8339 - val_accuracy: 0.8133\n",
      "Epoch 4612/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6486 - accuracy: 0.9047 - val_loss: 0.8222 - val_accuracy: 0.8183\n",
      "Epoch 4613/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6707 - accuracy: 0.9043 - val_loss: 0.8102 - val_accuracy: 0.8417\n",
      "Epoch 4614/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6882 - accuracy: 0.8985 - val_loss: 0.8280 - val_accuracy: 0.8133\n",
      "Epoch 4615/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6812 - accuracy: 0.9015 - val_loss: 0.8010 - val_accuracy: 0.8200\n",
      "Epoch 4616/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6557 - accuracy: 0.9023 - val_loss: 0.7844 - val_accuracy: 0.8333\n",
      "Epoch 4617/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6520 - accuracy: 0.9037 - val_loss: 0.8181 - val_accuracy: 0.8017\n",
      "Epoch 4618/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6518 - accuracy: 0.9002 - val_loss: 0.8241 - val_accuracy: 0.8233\n",
      "Epoch 4619/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6895 - accuracy: 0.8995 - val_loss: 0.8062 - val_accuracy: 0.8467\n",
      "Epoch 4620/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6534 - accuracy: 0.9073 - val_loss: 0.8007 - val_accuracy: 0.8350\n",
      "Epoch 4621/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6808 - accuracy: 0.9010 - val_loss: 0.8298 - val_accuracy: 0.8050\n",
      "Epoch 4622/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6618 - accuracy: 0.9017 - val_loss: 0.8095 - val_accuracy: 0.8317\n",
      "Epoch 4623/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6826 - accuracy: 0.8960 - val_loss: 0.7856 - val_accuracy: 0.8217\n",
      "Epoch 4624/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6940 - accuracy: 0.9003 - val_loss: 0.8159 - val_accuracy: 0.8167\n",
      "Epoch 4625/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7028 - accuracy: 0.8978 - val_loss: 0.8066 - val_accuracy: 0.8317\n",
      "Epoch 4626/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6729 - accuracy: 0.9003 - val_loss: 0.8006 - val_accuracy: 0.8150\n",
      "Epoch 4627/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6626 - accuracy: 0.9060 - val_loss: 0.8189 - val_accuracy: 0.8133\n",
      "Epoch 4628/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6794 - accuracy: 0.8972 - val_loss: 0.8058 - val_accuracy: 0.8350\n",
      "Epoch 4629/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6480 - accuracy: 0.9030 - val_loss: 0.7903 - val_accuracy: 0.8167\n",
      "Epoch 4630/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6892 - accuracy: 0.9015 - val_loss: 0.7760 - val_accuracy: 0.8350\n",
      "Epoch 4631/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6861 - accuracy: 0.8930 - val_loss: 0.7979 - val_accuracy: 0.8033\n",
      "Epoch 4632/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.8997 - val_loss: 0.7841 - val_accuracy: 0.8400\n",
      "Epoch 4633/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6612 - accuracy: 0.9055 - val_loss: 0.8147 - val_accuracy: 0.8200\n",
      "Epoch 4634/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6577 - accuracy: 0.9065 - val_loss: 0.7919 - val_accuracy: 0.8367\n",
      "Epoch 4635/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6705 - accuracy: 0.9082 - val_loss: 0.8139 - val_accuracy: 0.8050\n",
      "Epoch 4636/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.9040 - val_loss: 0.8043 - val_accuracy: 0.8200\n",
      "Epoch 4637/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6306 - accuracy: 0.9077 - val_loss: 0.8070 - val_accuracy: 0.8383\n",
      "Epoch 4638/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6659 - accuracy: 0.9048 - val_loss: 0.7978 - val_accuracy: 0.8300\n",
      "Epoch 4639/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7196 - accuracy: 0.9005 - val_loss: 0.8187 - val_accuracy: 0.8233\n",
      "Epoch 4640/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6602 - accuracy: 0.9093 - val_loss: 0.8471 - val_accuracy: 0.8300\n",
      "Epoch 4641/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6562 - accuracy: 0.9048 - val_loss: 0.8069 - val_accuracy: 0.8117\n",
      "Epoch 4642/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6668 - accuracy: 0.9073 - val_loss: 0.8324 - val_accuracy: 0.7983\n",
      "Epoch 4643/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6483 - accuracy: 0.9100 - val_loss: 0.8099 - val_accuracy: 0.8200\n",
      "Epoch 4644/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6788 - accuracy: 0.9075 - val_loss: 0.8251 - val_accuracy: 0.8200\n",
      "Epoch 4645/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6816 - accuracy: 0.8998 - val_loss: 0.7781 - val_accuracy: 0.8333\n",
      "Epoch 4646/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6439 - accuracy: 0.9062 - val_loss: 0.8167 - val_accuracy: 0.8167\n",
      "Epoch 4647/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6595 - accuracy: 0.9045 - val_loss: 0.8108 - val_accuracy: 0.8217\n",
      "Epoch 4648/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6662 - accuracy: 0.9045 - val_loss: 0.7894 - val_accuracy: 0.8367\n",
      "Epoch 4649/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6569 - accuracy: 0.9045 - val_loss: 0.7819 - val_accuracy: 0.8400\n",
      "Epoch 4650/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6510 - accuracy: 0.9023 - val_loss: 0.8131 - val_accuracy: 0.8267\n",
      "Epoch 4651/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6688 - accuracy: 0.8980 - val_loss: 0.7745 - val_accuracy: 0.8350\n",
      "Epoch 4652/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6837 - accuracy: 0.8968 - val_loss: 0.7887 - val_accuracy: 0.8200\n",
      "Epoch 4653/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6657 - accuracy: 0.8967 - val_loss: 0.7867 - val_accuracy: 0.8367\n",
      "Epoch 4654/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6666 - accuracy: 0.9032 - val_loss: 0.7704 - val_accuracy: 0.8300\n",
      "Epoch 4655/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6592 - accuracy: 0.9025 - val_loss: 0.7781 - val_accuracy: 0.8450\n",
      "Epoch 4656/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6761 - accuracy: 0.9045 - val_loss: 0.7864 - val_accuracy: 0.8167\n",
      "Epoch 4657/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6706 - accuracy: 0.9068 - val_loss: 0.7791 - val_accuracy: 0.8317\n",
      "Epoch 4658/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6550 - accuracy: 0.9063 - val_loss: 0.8108 - val_accuracy: 0.8317\n",
      "Epoch 4659/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6563 - accuracy: 0.9055 - val_loss: 0.8200 - val_accuracy: 0.8350\n",
      "Epoch 4660/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6435 - accuracy: 0.9100 - val_loss: 0.8149 - val_accuracy: 0.8350\n",
      "Epoch 4661/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6812 - accuracy: 0.8975 - val_loss: 0.8116 - val_accuracy: 0.8317\n",
      "Epoch 4662/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6546 - accuracy: 0.9045 - val_loss: 0.8512 - val_accuracy: 0.8150\n",
      "Epoch 4663/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6341 - accuracy: 0.9095 - val_loss: 0.8142 - val_accuracy: 0.8283\n",
      "Epoch 4664/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6532 - accuracy: 0.9098 - val_loss: 0.7900 - val_accuracy: 0.8467\n",
      "Epoch 4665/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6766 - accuracy: 0.9018 - val_loss: 0.7831 - val_accuracy: 0.8433\n",
      "Epoch 4666/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6641 - accuracy: 0.9105 - val_loss: 0.8174 - val_accuracy: 0.8117\n",
      "Epoch 4667/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6947 - accuracy: 0.9003 - val_loss: 0.7926 - val_accuracy: 0.8467\n",
      "Epoch 4668/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6887 - accuracy: 0.9037 - val_loss: 0.7854 - val_accuracy: 0.8250\n",
      "Epoch 4669/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6892 - accuracy: 0.9048 - val_loss: 0.8395 - val_accuracy: 0.8283\n",
      "Epoch 4670/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7007 - accuracy: 0.9008 - val_loss: 0.8284 - val_accuracy: 0.8267\n",
      "Epoch 4671/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6882 - accuracy: 0.9050 - val_loss: 0.7875 - val_accuracy: 0.8267\n",
      "Epoch 4672/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6612 - accuracy: 0.8992 - val_loss: 0.8040 - val_accuracy: 0.8350\n",
      "Epoch 4673/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6647 - accuracy: 0.9045 - val_loss: 0.8003 - val_accuracy: 0.8383\n",
      "Epoch 4674/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6811 - accuracy: 0.8985 - val_loss: 0.7952 - val_accuracy: 0.8283\n",
      "Epoch 4675/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6789 - accuracy: 0.9045 - val_loss: 0.7778 - val_accuracy: 0.8133\n",
      "Epoch 4676/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6532 - accuracy: 0.9033 - val_loss: 0.7719 - val_accuracy: 0.8150\n",
      "Epoch 4677/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6886 - accuracy: 0.8970 - val_loss: 0.8101 - val_accuracy: 0.8017\n",
      "Epoch 4678/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6755 - accuracy: 0.9035 - val_loss: 0.8092 - val_accuracy: 0.8250\n",
      "Epoch 4679/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6621 - accuracy: 0.9075 - val_loss: 0.8176 - val_accuracy: 0.8167\n",
      "Epoch 4680/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6788 - accuracy: 0.8993 - val_loss: 0.8265 - val_accuracy: 0.8150\n",
      "Epoch 4681/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6791 - accuracy: 0.9038 - val_loss: 0.8335 - val_accuracy: 0.8150\n",
      "Epoch 4682/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6643 - accuracy: 0.9053 - val_loss: 0.7879 - val_accuracy: 0.8083\n",
      "Epoch 4683/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6501 - accuracy: 0.9028 - val_loss: 0.7773 - val_accuracy: 0.8050\n",
      "Epoch 4684/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6319 - accuracy: 0.9105 - val_loss: 0.7995 - val_accuracy: 0.8067\n",
      "Epoch 4685/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6770 - accuracy: 0.9028 - val_loss: 0.8483 - val_accuracy: 0.8067\n",
      "Epoch 4686/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6715 - accuracy: 0.8975 - val_loss: 0.8210 - val_accuracy: 0.8133\n",
      "Epoch 4687/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6802 - accuracy: 0.8992 - val_loss: 0.8219 - val_accuracy: 0.8083\n",
      "Epoch 4688/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6753 - accuracy: 0.9020 - val_loss: 0.8278 - val_accuracy: 0.8183\n",
      "Epoch 4689/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6466 - accuracy: 0.9098 - val_loss: 0.8109 - val_accuracy: 0.8183\n",
      "Epoch 4690/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6677 - accuracy: 0.8990 - val_loss: 0.7933 - val_accuracy: 0.8200\n",
      "Epoch 4691/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6650 - accuracy: 0.9042 - val_loss: 0.8211 - val_accuracy: 0.8150\n",
      "Epoch 4692/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6842 - accuracy: 0.8988 - val_loss: 0.8179 - val_accuracy: 0.8233\n",
      "Epoch 4693/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6463 - accuracy: 0.9035 - val_loss: 0.7973 - val_accuracy: 0.8217\n",
      "Epoch 4694/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6661 - accuracy: 0.9022 - val_loss: 0.8054 - val_accuracy: 0.8150\n",
      "Epoch 4695/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6479 - accuracy: 0.9077 - val_loss: 0.8094 - val_accuracy: 0.8233\n",
      "Epoch 4696/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6435 - accuracy: 0.9062 - val_loss: 0.8000 - val_accuracy: 0.8300\n",
      "Epoch 4697/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6546 - accuracy: 0.9030 - val_loss: 0.7897 - val_accuracy: 0.8217\n",
      "Epoch 4698/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6353 - accuracy: 0.9098 - val_loss: 0.7917 - val_accuracy: 0.8033\n",
      "Epoch 4699/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6730 - accuracy: 0.9037 - val_loss: 0.8199 - val_accuracy: 0.8033\n",
      "Epoch 4700/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6793 - accuracy: 0.9002 - val_loss: 0.7959 - val_accuracy: 0.8117\n",
      "Epoch 4701/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6680 - accuracy: 0.9002 - val_loss: 0.7950 - val_accuracy: 0.8267\n",
      "Epoch 4702/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6597 - accuracy: 0.9065 - val_loss: 0.7874 - val_accuracy: 0.8200\n",
      "Epoch 4703/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6819 - accuracy: 0.9022 - val_loss: 0.7926 - val_accuracy: 0.8183\n",
      "Epoch 4704/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6520 - accuracy: 0.9020 - val_loss: 0.7806 - val_accuracy: 0.8267\n",
      "Epoch 4705/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6677 - accuracy: 0.9050 - val_loss: 0.7630 - val_accuracy: 0.8567\n",
      "Epoch 4706/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6666 - accuracy: 0.9013 - val_loss: 0.7808 - val_accuracy: 0.8417\n",
      "Epoch 4707/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6484 - accuracy: 0.9028 - val_loss: 0.8168 - val_accuracy: 0.8200\n",
      "Epoch 4708/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6714 - accuracy: 0.9033 - val_loss: 0.8268 - val_accuracy: 0.8283\n",
      "Epoch 4709/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6440 - accuracy: 0.9100 - val_loss: 0.7970 - val_accuracy: 0.8283\n",
      "Epoch 4710/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6519 - accuracy: 0.9070 - val_loss: 0.7812 - val_accuracy: 0.8267\n",
      "Epoch 4711/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6539 - accuracy: 0.9058 - val_loss: 0.7788 - val_accuracy: 0.8367\n",
      "Epoch 4712/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6531 - accuracy: 0.9085 - val_loss: 0.7457 - val_accuracy: 0.8583\n",
      "Epoch 4713/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6430 - accuracy: 0.9122 - val_loss: 0.7549 - val_accuracy: 0.8383\n",
      "Epoch 4714/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6361 - accuracy: 0.9090 - val_loss: 0.7554 - val_accuracy: 0.8483\n",
      "Epoch 4715/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6616 - accuracy: 0.9058 - val_loss: 0.7761 - val_accuracy: 0.8433\n",
      "Epoch 4716/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6815 - accuracy: 0.9020 - val_loss: 0.7948 - val_accuracy: 0.8333\n",
      "Epoch 4717/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6691 - accuracy: 0.9028 - val_loss: 0.7635 - val_accuracy: 0.8467\n",
      "Epoch 4718/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6664 - accuracy: 0.9057 - val_loss: 0.7541 - val_accuracy: 0.8533\n",
      "Epoch 4719/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6830 - accuracy: 0.9040 - val_loss: 0.7693 - val_accuracy: 0.8483\n",
      "Epoch 4720/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6709 - accuracy: 0.8972 - val_loss: 0.7977 - val_accuracy: 0.8250\n",
      "Epoch 4721/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6744 - accuracy: 0.9012 - val_loss: 0.8036 - val_accuracy: 0.8300\n",
      "Epoch 4722/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6718 - accuracy: 0.9045 - val_loss: 0.8048 - val_accuracy: 0.8383\n",
      "Epoch 4723/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6662 - accuracy: 0.9027 - val_loss: 0.7923 - val_accuracy: 0.8300\n",
      "Epoch 4724/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6440 - accuracy: 0.9048 - val_loss: 0.7956 - val_accuracy: 0.8267\n",
      "Epoch 4725/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6617 - accuracy: 0.9032 - val_loss: 0.8101 - val_accuracy: 0.8183\n",
      "Epoch 4726/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.9045 - val_loss: 0.7760 - val_accuracy: 0.8467\n",
      "Epoch 4727/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6511 - accuracy: 0.9038 - val_loss: 0.7637 - val_accuracy: 0.8550\n",
      "Epoch 4728/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6566 - accuracy: 0.9052 - val_loss: 0.7647 - val_accuracy: 0.8300\n",
      "Epoch 4729/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6735 - accuracy: 0.8955 - val_loss: 0.7776 - val_accuracy: 0.8433\n",
      "Epoch 4730/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6676 - accuracy: 0.9025 - val_loss: 0.7976 - val_accuracy: 0.8283\n",
      "Epoch 4731/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6711 - accuracy: 0.9073 - val_loss: 0.7681 - val_accuracy: 0.8450\n",
      "Epoch 4732/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6840 - accuracy: 0.9050 - val_loss: 0.7812 - val_accuracy: 0.8450\n",
      "Epoch 4733/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6595 - accuracy: 0.9060 - val_loss: 0.8177 - val_accuracy: 0.8233\n",
      "Epoch 4734/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6642 - accuracy: 0.9033 - val_loss: 0.8395 - val_accuracy: 0.8100\n",
      "Epoch 4735/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6422 - accuracy: 0.9102 - val_loss: 0.8522 - val_accuracy: 0.8117\n",
      "Epoch 4736/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6227 - accuracy: 0.9123 - val_loss: 0.8208 - val_accuracy: 0.8250\n",
      "Epoch 4737/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6404 - accuracy: 0.9087 - val_loss: 0.8010 - val_accuracy: 0.8317\n",
      "Epoch 4738/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6673 - accuracy: 0.9090 - val_loss: 0.8199 - val_accuracy: 0.8417\n",
      "Epoch 4739/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6867 - accuracy: 0.8987 - val_loss: 0.7950 - val_accuracy: 0.8467\n",
      "Epoch 4740/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6771 - accuracy: 0.9043 - val_loss: 0.8527 - val_accuracy: 0.8300\n",
      "Epoch 4741/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6573 - accuracy: 0.9013 - val_loss: 0.8262 - val_accuracy: 0.8400\n",
      "Epoch 4742/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6672 - accuracy: 0.9053 - val_loss: 0.8104 - val_accuracy: 0.8383\n",
      "Epoch 4743/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.9045 - val_loss: 0.7909 - val_accuracy: 0.8450\n",
      "Epoch 4744/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6803 - accuracy: 0.8957 - val_loss: 0.8455 - val_accuracy: 0.8483\n",
      "Epoch 4745/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7151 - accuracy: 0.8993 - val_loss: 0.8644 - val_accuracy: 0.8217\n",
      "Epoch 4746/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6672 - accuracy: 0.9057 - val_loss: 0.8734 - val_accuracy: 0.8233\n",
      "Epoch 4747/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.9048 - val_loss: 0.8019 - val_accuracy: 0.8367\n",
      "Epoch 4748/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6728 - accuracy: 0.9058 - val_loss: 0.8137 - val_accuracy: 0.8317\n",
      "Epoch 4749/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6493 - accuracy: 0.9030 - val_loss: 0.8142 - val_accuracy: 0.8333\n",
      "Epoch 4750/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6849 - accuracy: 0.9032 - val_loss: 0.8230 - val_accuracy: 0.8233\n",
      "Epoch 4751/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6849 - accuracy: 0.9017 - val_loss: 0.8759 - val_accuracy: 0.8133\n",
      "Epoch 4752/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6610 - accuracy: 0.9065 - val_loss: 0.8596 - val_accuracy: 0.8250\n",
      "Epoch 4753/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6560 - accuracy: 0.9105 - val_loss: 0.8652 - val_accuracy: 0.8167\n",
      "Epoch 4754/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6781 - accuracy: 0.9012 - val_loss: 0.7892 - val_accuracy: 0.8433\n",
      "Epoch 4755/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.9015 - val_loss: 0.8431 - val_accuracy: 0.8300\n",
      "Epoch 4756/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6740 - accuracy: 0.9045 - val_loss: 0.8478 - val_accuracy: 0.8283\n",
      "Epoch 4757/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6518 - accuracy: 0.9062 - val_loss: 0.8180 - val_accuracy: 0.8400\n",
      "Epoch 4758/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6371 - accuracy: 0.9122 - val_loss: 0.7891 - val_accuracy: 0.8517\n",
      "Epoch 4759/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6480 - accuracy: 0.9090 - val_loss: 0.7574 - val_accuracy: 0.8350\n",
      "Epoch 4760/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6570 - accuracy: 0.8977 - val_loss: 0.7858 - val_accuracy: 0.8383\n",
      "Epoch 4761/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6938 - accuracy: 0.8997 - val_loss: 0.8144 - val_accuracy: 0.8467\n",
      "Epoch 4762/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6536 - accuracy: 0.9017 - val_loss: 0.8135 - val_accuracy: 0.8383\n",
      "Epoch 4763/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6700 - accuracy: 0.9062 - val_loss: 0.7871 - val_accuracy: 0.8533\n",
      "Epoch 4764/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6743 - accuracy: 0.9048 - val_loss: 0.7820 - val_accuracy: 0.8433\n",
      "Epoch 4765/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6732 - accuracy: 0.9012 - val_loss: 0.7826 - val_accuracy: 0.8350\n",
      "Epoch 4766/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6505 - accuracy: 0.9093 - val_loss: 0.8224 - val_accuracy: 0.8267\n",
      "Epoch 4767/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6692 - accuracy: 0.9000 - val_loss: 0.8106 - val_accuracy: 0.8333\n",
      "Epoch 4768/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6578 - accuracy: 0.9080 - val_loss: 0.8119 - val_accuracy: 0.8300\n",
      "Epoch 4769/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6515 - accuracy: 0.9067 - val_loss: 0.8486 - val_accuracy: 0.8083\n",
      "Epoch 4770/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6668 - accuracy: 0.9003 - val_loss: 0.8522 - val_accuracy: 0.8083\n",
      "Epoch 4771/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6830 - accuracy: 0.9057 - val_loss: 0.9040 - val_accuracy: 0.8150\n",
      "Epoch 4772/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6892 - accuracy: 0.8973 - val_loss: 0.8652 - val_accuracy: 0.8217\n",
      "Epoch 4773/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6749 - accuracy: 0.9037 - val_loss: 0.8640 - val_accuracy: 0.8117\n",
      "Epoch 4774/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6687 - accuracy: 0.9113 - val_loss: 0.8486 - val_accuracy: 0.8300\n",
      "Epoch 4775/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6694 - accuracy: 0.9065 - val_loss: 0.8459 - val_accuracy: 0.8067\n",
      "Epoch 4776/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6530 - accuracy: 0.9013 - val_loss: 0.8134 - val_accuracy: 0.8250\n",
      "Epoch 4777/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6738 - accuracy: 0.9008 - val_loss: 0.8460 - val_accuracy: 0.8083\n",
      "Epoch 4778/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6710 - accuracy: 0.9028 - val_loss: 0.7999 - val_accuracy: 0.8217\n",
      "Epoch 4779/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6616 - accuracy: 0.9033 - val_loss: 0.7851 - val_accuracy: 0.8450\n",
      "Epoch 4780/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6521 - accuracy: 0.9075 - val_loss: 0.8240 - val_accuracy: 0.8133\n",
      "Epoch 4781/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6953 - accuracy: 0.9035 - val_loss: 0.8052 - val_accuracy: 0.8183\n",
      "Epoch 4782/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6734 - accuracy: 0.9032 - val_loss: 0.8423 - val_accuracy: 0.7983\n",
      "Epoch 4783/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6785 - accuracy: 0.8960 - val_loss: 0.8091 - val_accuracy: 0.8100\n",
      "Epoch 4784/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.8978 - val_loss: 0.8037 - val_accuracy: 0.8183\n",
      "Epoch 4785/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6461 - accuracy: 0.9045 - val_loss: 0.8463 - val_accuracy: 0.8033\n",
      "Epoch 4786/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6674 - accuracy: 0.9052 - val_loss: 0.8176 - val_accuracy: 0.8150\n",
      "Epoch 4787/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6622 - accuracy: 0.9057 - val_loss: 0.8444 - val_accuracy: 0.8033\n",
      "Epoch 4788/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6673 - accuracy: 0.9063 - val_loss: 0.8325 - val_accuracy: 0.8167\n",
      "Epoch 4789/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6818 - accuracy: 0.9035 - val_loss: 0.8333 - val_accuracy: 0.8050\n",
      "Epoch 4790/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6557 - accuracy: 0.9075 - val_loss: 0.8163 - val_accuracy: 0.8317\n",
      "Epoch 4791/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6397 - accuracy: 0.9127 - val_loss: 0.8209 - val_accuracy: 0.8350\n",
      "Epoch 4792/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.9065 - val_loss: 0.8608 - val_accuracy: 0.8217\n",
      "Epoch 4793/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6774 - accuracy: 0.9027 - val_loss: 0.8049 - val_accuracy: 0.8350\n",
      "Epoch 4794/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6605 - accuracy: 0.9043 - val_loss: 0.8620 - val_accuracy: 0.8233\n",
      "Epoch 4795/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6671 - accuracy: 0.9078 - val_loss: 0.8483 - val_accuracy: 0.8083\n",
      "Epoch 4796/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6551 - accuracy: 0.9042 - val_loss: 0.8363 - val_accuracy: 0.8200\n",
      "Epoch 4797/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6723 - accuracy: 0.9068 - val_loss: 0.8173 - val_accuracy: 0.8233\n",
      "Epoch 4798/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6820 - accuracy: 0.9010 - val_loss: 0.8041 - val_accuracy: 0.8383\n",
      "Epoch 4799/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6732 - accuracy: 0.9033 - val_loss: 0.8225 - val_accuracy: 0.8317\n",
      "Epoch 4800/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6545 - accuracy: 0.9033 - val_loss: 0.8416 - val_accuracy: 0.8267\n",
      "Epoch 4801/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6711 - accuracy: 0.9057 - val_loss: 0.8155 - val_accuracy: 0.8317\n",
      "Epoch 4802/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6691 - accuracy: 0.9095 - val_loss: 0.8348 - val_accuracy: 0.8350\n",
      "Epoch 4803/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6499 - accuracy: 0.9093 - val_loss: 0.8247 - val_accuracy: 0.8233\n",
      "Epoch 4804/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6549 - accuracy: 0.9057 - val_loss: 0.7971 - val_accuracy: 0.8233\n",
      "Epoch 4805/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6686 - accuracy: 0.9058 - val_loss: 0.7997 - val_accuracy: 0.8367\n",
      "Epoch 4806/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6560 - accuracy: 0.9118 - val_loss: 0.7814 - val_accuracy: 0.8350\n",
      "Epoch 4807/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6247 - accuracy: 0.9092 - val_loss: 0.8033 - val_accuracy: 0.8283\n",
      "Epoch 4808/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6265 - accuracy: 0.9127 - val_loss: 0.7430 - val_accuracy: 0.8500\n",
      "Epoch 4809/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6529 - accuracy: 0.9052 - val_loss: 0.8490 - val_accuracy: 0.8250\n",
      "Epoch 4810/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6365 - accuracy: 0.9043 - val_loss: 0.7899 - val_accuracy: 0.8400\n",
      "Epoch 4811/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6482 - accuracy: 0.9045 - val_loss: 0.8082 - val_accuracy: 0.8217\n",
      "Epoch 4812/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6628 - accuracy: 0.9067 - val_loss: 0.7961 - val_accuracy: 0.8200\n",
      "Epoch 4813/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6388 - accuracy: 0.9117 - val_loss: 0.8269 - val_accuracy: 0.8233\n",
      "Epoch 4814/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6418 - accuracy: 0.9083 - val_loss: 0.8250 - val_accuracy: 0.8150\n",
      "Epoch 4815/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6365 - accuracy: 0.9042 - val_loss: 0.8077 - val_accuracy: 0.8183\n",
      "Epoch 4816/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6244 - accuracy: 0.9108 - val_loss: 0.8099 - val_accuracy: 0.8150\n",
      "Epoch 4817/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6289 - accuracy: 0.9103 - val_loss: 0.8250 - val_accuracy: 0.8267\n",
      "Epoch 4818/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6810 - accuracy: 0.9063 - val_loss: 0.7716 - val_accuracy: 0.8217\n",
      "Epoch 4819/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6612 - accuracy: 0.9010 - val_loss: 0.7604 - val_accuracy: 0.8417\n",
      "Epoch 4820/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6711 - accuracy: 0.9003 - val_loss: 0.8247 - val_accuracy: 0.8233\n",
      "Epoch 4821/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6807 - accuracy: 0.9018 - val_loss: 0.7928 - val_accuracy: 0.8300\n",
      "Epoch 4822/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6362 - accuracy: 0.9072 - val_loss: 0.8285 - val_accuracy: 0.8300\n",
      "Epoch 4823/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6741 - accuracy: 0.9027 - val_loss: 0.8048 - val_accuracy: 0.8367\n",
      "Epoch 4824/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6414 - accuracy: 0.9112 - val_loss: 0.8452 - val_accuracy: 0.8183\n",
      "Epoch 4825/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6541 - accuracy: 0.9080 - val_loss: 0.8055 - val_accuracy: 0.8467\n",
      "Epoch 4826/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6685 - accuracy: 0.9083 - val_loss: 0.8376 - val_accuracy: 0.8083\n",
      "Epoch 4827/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6780 - accuracy: 0.9033 - val_loss: 0.8354 - val_accuracy: 0.8167\n",
      "Epoch 4828/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6547 - accuracy: 0.9063 - val_loss: 0.8196 - val_accuracy: 0.8233\n",
      "Epoch 4829/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.9010 - val_loss: 0.8467 - val_accuracy: 0.8300\n",
      "Epoch 4830/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6793 - accuracy: 0.9045 - val_loss: 0.7899 - val_accuracy: 0.8333\n",
      "Epoch 4831/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6995 - accuracy: 0.9018 - val_loss: 0.8160 - val_accuracy: 0.8517\n",
      "Epoch 4832/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6431 - accuracy: 0.9147 - val_loss: 0.7962 - val_accuracy: 0.8450\n",
      "Epoch 4833/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6483 - accuracy: 0.9098 - val_loss: 0.8175 - val_accuracy: 0.8083\n",
      "Epoch 4834/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6509 - accuracy: 0.9062 - val_loss: 0.7973 - val_accuracy: 0.8317\n",
      "Epoch 4835/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6605 - accuracy: 0.9103 - val_loss: 0.7981 - val_accuracy: 0.8283\n",
      "Epoch 4836/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6334 - accuracy: 0.9055 - val_loss: 0.7659 - val_accuracy: 0.8450\n",
      "Epoch 4837/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6560 - accuracy: 0.9010 - val_loss: 0.8020 - val_accuracy: 0.8267\n",
      "Epoch 4838/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6786 - accuracy: 0.9067 - val_loss: 0.7563 - val_accuracy: 0.8333\n",
      "Epoch 4839/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6661 - accuracy: 0.9022 - val_loss: 0.7789 - val_accuracy: 0.8250\n",
      "Epoch 4840/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6471 - accuracy: 0.9032 - val_loss: 0.7553 - val_accuracy: 0.8367\n",
      "Epoch 4841/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6452 - accuracy: 0.9038 - val_loss: 0.7795 - val_accuracy: 0.8317\n",
      "Epoch 4842/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6580 - accuracy: 0.9085 - val_loss: 0.7874 - val_accuracy: 0.8250\n",
      "Epoch 4843/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6687 - accuracy: 0.9023 - val_loss: 0.7958 - val_accuracy: 0.8283\n",
      "Epoch 4844/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6600 - accuracy: 0.9042 - val_loss: 0.8211 - val_accuracy: 0.8317\n",
      "Epoch 4845/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6809 - accuracy: 0.9040 - val_loss: 0.8166 - val_accuracy: 0.8217\n",
      "Epoch 4846/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6587 - accuracy: 0.9058 - val_loss: 0.7946 - val_accuracy: 0.8283\n",
      "Epoch 4847/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6571 - accuracy: 0.9062 - val_loss: 0.8010 - val_accuracy: 0.8317\n",
      "Epoch 4848/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6885 - accuracy: 0.9060 - val_loss: 0.8462 - val_accuracy: 0.8200\n",
      "Epoch 4849/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6531 - accuracy: 0.9068 - val_loss: 0.7677 - val_accuracy: 0.8517\n",
      "Epoch 4850/5000\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6428 - accuracy: 0.9048 - val_loss: 0.7303 - val_accuracy: 0.8617\n",
      "Epoch 4851/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6472 - accuracy: 0.9078 - val_loss: 0.7918 - val_accuracy: 0.8350\n",
      "Epoch 4852/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6438 - accuracy: 0.9110 - val_loss: 0.7515 - val_accuracy: 0.8517\n",
      "Epoch 4853/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.9005 - val_loss: 0.8077 - val_accuracy: 0.8483\n",
      "Epoch 4854/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6646 - accuracy: 0.9060 - val_loss: 0.8474 - val_accuracy: 0.8100\n",
      "Epoch 4855/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6730 - accuracy: 0.9038 - val_loss: 0.8434 - val_accuracy: 0.8250\n",
      "Epoch 4856/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6665 - accuracy: 0.9032 - val_loss: 0.7995 - val_accuracy: 0.8317\n",
      "Epoch 4857/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6495 - accuracy: 0.9098 - val_loss: 0.7793 - val_accuracy: 0.8317\n",
      "Epoch 4858/5000\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.6667 - accuracy: 0.9042 - val_loss: 0.7279 - val_accuracy: 0.8583\n",
      "Epoch 4859/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6480 - accuracy: 0.9105 - val_loss: 0.7879 - val_accuracy: 0.8483\n",
      "Epoch 4860/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6792 - accuracy: 0.9045 - val_loss: 0.7779 - val_accuracy: 0.8450\n",
      "Epoch 4861/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6695 - accuracy: 0.9048 - val_loss: 0.7875 - val_accuracy: 0.8383\n",
      "Epoch 4862/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6544 - accuracy: 0.9103 - val_loss: 0.7782 - val_accuracy: 0.8467\n",
      "Epoch 4863/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6651 - accuracy: 0.9013 - val_loss: 0.8284 - val_accuracy: 0.8300\n",
      "Epoch 4864/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6587 - accuracy: 0.9137 - val_loss: 0.8500 - val_accuracy: 0.8350\n",
      "Epoch 4865/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6602 - accuracy: 0.9043 - val_loss: 0.7923 - val_accuracy: 0.8350\n",
      "Epoch 4866/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6434 - accuracy: 0.9117 - val_loss: 0.8131 - val_accuracy: 0.8383\n",
      "Epoch 4867/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6695 - accuracy: 0.9048 - val_loss: 0.8111 - val_accuracy: 0.8400\n",
      "Epoch 4868/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6589 - accuracy: 0.9112 - val_loss: 0.8300 - val_accuracy: 0.8300\n",
      "Epoch 4869/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6747 - accuracy: 0.9025 - val_loss: 0.8191 - val_accuracy: 0.8233\n",
      "Epoch 4870/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6716 - accuracy: 0.9038 - val_loss: 0.7851 - val_accuracy: 0.8433\n",
      "Epoch 4871/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6618 - accuracy: 0.9135 - val_loss: 0.8007 - val_accuracy: 0.8417\n",
      "Epoch 4872/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6473 - accuracy: 0.9135 - val_loss: 0.7949 - val_accuracy: 0.8283\n",
      "Epoch 4873/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6643 - accuracy: 0.9053 - val_loss: 0.7993 - val_accuracy: 0.8200\n",
      "Epoch 4874/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7033 - accuracy: 0.9058 - val_loss: 0.7939 - val_accuracy: 0.8333\n",
      "Epoch 4875/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7072 - accuracy: 0.8967 - val_loss: 0.7945 - val_accuracy: 0.8317\n",
      "Epoch 4876/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.7082 - accuracy: 0.9002 - val_loss: 0.8415 - val_accuracy: 0.8133\n",
      "Epoch 4877/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6883 - accuracy: 0.9023 - val_loss: 0.7857 - val_accuracy: 0.8433\n",
      "Epoch 4878/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6796 - accuracy: 0.9022 - val_loss: 0.7775 - val_accuracy: 0.8317\n",
      "Epoch 4879/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6638 - accuracy: 0.9047 - val_loss: 0.8314 - val_accuracy: 0.8183\n",
      "Epoch 4880/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6653 - accuracy: 0.9022 - val_loss: 0.7973 - val_accuracy: 0.8150\n",
      "Epoch 4881/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6581 - accuracy: 0.9068 - val_loss: 0.8044 - val_accuracy: 0.8183\n",
      "Epoch 4882/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6578 - accuracy: 0.9052 - val_loss: 0.7864 - val_accuracy: 0.8300\n",
      "Epoch 4883/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6545 - accuracy: 0.9070 - val_loss: 0.8134 - val_accuracy: 0.8333\n",
      "Epoch 4884/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6999 - accuracy: 0.8993 - val_loss: 0.8169 - val_accuracy: 0.8417\n",
      "Epoch 4885/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6650 - accuracy: 0.9085 - val_loss: 0.8618 - val_accuracy: 0.8067\n",
      "Epoch 4886/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6825 - accuracy: 0.9003 - val_loss: 0.8485 - val_accuracy: 0.8300\n",
      "Epoch 4887/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6645 - accuracy: 0.9093 - val_loss: 0.8370 - val_accuracy: 0.8300\n",
      "Epoch 4888/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6598 - accuracy: 0.9080 - val_loss: 0.8106 - val_accuracy: 0.8400\n",
      "Epoch 4889/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6626 - accuracy: 0.9028 - val_loss: 0.8205 - val_accuracy: 0.8233\n",
      "Epoch 4890/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6684 - accuracy: 0.9048 - val_loss: 0.8293 - val_accuracy: 0.8300\n",
      "Epoch 4891/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6451 - accuracy: 0.9095 - val_loss: 0.8254 - val_accuracy: 0.8350\n",
      "Epoch 4892/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6335 - accuracy: 0.9137 - val_loss: 0.8719 - val_accuracy: 0.8200\n",
      "Epoch 4893/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6718 - accuracy: 0.9027 - val_loss: 0.8248 - val_accuracy: 0.8200\n",
      "Epoch 4894/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6620 - accuracy: 0.9045 - val_loss: 0.8608 - val_accuracy: 0.8150\n",
      "Epoch 4895/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6708 - accuracy: 0.9070 - val_loss: 0.8441 - val_accuracy: 0.8283\n",
      "Epoch 4896/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6958 - accuracy: 0.9028 - val_loss: 0.8173 - val_accuracy: 0.8250\n",
      "Epoch 4897/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6618 - accuracy: 0.9080 - val_loss: 0.8082 - val_accuracy: 0.8200\n",
      "Epoch 4898/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6678 - accuracy: 0.9070 - val_loss: 0.7826 - val_accuracy: 0.8333\n",
      "Epoch 4899/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6749 - accuracy: 0.9045 - val_loss: 0.8320 - val_accuracy: 0.8217\n",
      "Epoch 4900/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6601 - accuracy: 0.9062 - val_loss: 0.8270 - val_accuracy: 0.8250\n",
      "Epoch 4901/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6607 - accuracy: 0.9112 - val_loss: 0.8043 - val_accuracy: 0.8417\n",
      "Epoch 4902/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6804 - accuracy: 0.9077 - val_loss: 0.8101 - val_accuracy: 0.8350\n",
      "Epoch 4903/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6474 - accuracy: 0.9113 - val_loss: 0.8402 - val_accuracy: 0.8250\n",
      "Epoch 4904/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6502 - accuracy: 0.9128 - val_loss: 0.8442 - val_accuracy: 0.8367\n",
      "Epoch 4905/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6573 - accuracy: 0.9093 - val_loss: 0.8335 - val_accuracy: 0.8367\n",
      "Epoch 4906/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6556 - accuracy: 0.9068 - val_loss: 0.8344 - val_accuracy: 0.8150\n",
      "Epoch 4907/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6586 - accuracy: 0.9033 - val_loss: 0.8197 - val_accuracy: 0.8433\n",
      "Epoch 4908/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6485 - accuracy: 0.9115 - val_loss: 0.8454 - val_accuracy: 0.8417\n",
      "Epoch 4909/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6581 - accuracy: 0.9095 - val_loss: 0.8641 - val_accuracy: 0.8200\n",
      "Epoch 4910/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6769 - accuracy: 0.9085 - val_loss: 0.8709 - val_accuracy: 0.8400\n",
      "Epoch 4911/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6717 - accuracy: 0.9022 - val_loss: 0.8665 - val_accuracy: 0.8317\n",
      "Epoch 4912/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6808 - accuracy: 0.8995 - val_loss: 0.8721 - val_accuracy: 0.8417\n",
      "Epoch 4913/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6719 - accuracy: 0.9118 - val_loss: 0.8881 - val_accuracy: 0.8250\n",
      "Epoch 4914/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6612 - accuracy: 0.9048 - val_loss: 0.8576 - val_accuracy: 0.8250\n",
      "Epoch 4915/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6514 - accuracy: 0.9078 - val_loss: 0.8159 - val_accuracy: 0.8300\n",
      "Epoch 4916/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6553 - accuracy: 0.9052 - val_loss: 0.8450 - val_accuracy: 0.8117\n",
      "Epoch 4917/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6527 - accuracy: 0.9033 - val_loss: 0.8173 - val_accuracy: 0.8233\n",
      "Epoch 4918/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6567 - accuracy: 0.9047 - val_loss: 0.7851 - val_accuracy: 0.8383\n",
      "Epoch 4919/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6558 - accuracy: 0.9080 - val_loss: 0.7968 - val_accuracy: 0.8417\n",
      "Epoch 4920/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6583 - accuracy: 0.9053 - val_loss: 0.7997 - val_accuracy: 0.8367\n",
      "Epoch 4921/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6318 - accuracy: 0.9090 - val_loss: 0.8147 - val_accuracy: 0.8333\n",
      "Epoch 4922/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6540 - accuracy: 0.9072 - val_loss: 0.8279 - val_accuracy: 0.8217\n",
      "Epoch 4923/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6587 - accuracy: 0.9028 - val_loss: 0.8371 - val_accuracy: 0.8333\n",
      "Epoch 4924/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6598 - accuracy: 0.9097 - val_loss: 0.7914 - val_accuracy: 0.8233\n",
      "Epoch 4925/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6476 - accuracy: 0.9043 - val_loss: 0.7877 - val_accuracy: 0.8383\n",
      "Epoch 4926/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6631 - accuracy: 0.9073 - val_loss: 0.8324 - val_accuracy: 0.8167\n",
      "Epoch 4927/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6673 - accuracy: 0.9030 - val_loss: 0.7849 - val_accuracy: 0.8367\n",
      "Epoch 4928/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6466 - accuracy: 0.9043 - val_loss: 0.8188 - val_accuracy: 0.8167\n",
      "Epoch 4929/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6420 - accuracy: 0.9060 - val_loss: 0.7983 - val_accuracy: 0.8317\n",
      "Epoch 4930/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6469 - accuracy: 0.9088 - val_loss: 0.8090 - val_accuracy: 0.8267\n",
      "Epoch 4931/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6472 - accuracy: 0.9060 - val_loss: 0.8665 - val_accuracy: 0.8300\n",
      "Epoch 4932/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6760 - accuracy: 0.9035 - val_loss: 0.8158 - val_accuracy: 0.8300\n",
      "Epoch 4933/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7057 - accuracy: 0.8998 - val_loss: 0.8333 - val_accuracy: 0.8250\n",
      "Epoch 4934/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6619 - accuracy: 0.9093 - val_loss: 0.8429 - val_accuracy: 0.8233\n",
      "Epoch 4935/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6762 - accuracy: 0.9055 - val_loss: 0.9174 - val_accuracy: 0.8167\n",
      "Epoch 4936/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6581 - accuracy: 0.9070 - val_loss: 0.8743 - val_accuracy: 0.8050\n",
      "Epoch 4937/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6485 - accuracy: 0.9105 - val_loss: 0.8506 - val_accuracy: 0.8217\n",
      "Epoch 4938/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6575 - accuracy: 0.9080 - val_loss: 0.8146 - val_accuracy: 0.8217\n",
      "Epoch 4939/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6507 - accuracy: 0.9078 - val_loss: 0.8535 - val_accuracy: 0.8233\n",
      "Epoch 4940/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6733 - accuracy: 0.9098 - val_loss: 0.8222 - val_accuracy: 0.8250\n",
      "Epoch 4941/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6707 - accuracy: 0.9105 - val_loss: 0.8745 - val_accuracy: 0.8117\n",
      "Epoch 4942/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6540 - accuracy: 0.9095 - val_loss: 0.8415 - val_accuracy: 0.8517\n",
      "Epoch 4943/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6903 - accuracy: 0.9035 - val_loss: 0.8468 - val_accuracy: 0.8383\n",
      "Epoch 4944/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6432 - accuracy: 0.9118 - val_loss: 0.8707 - val_accuracy: 0.8433\n",
      "Epoch 4945/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6604 - accuracy: 0.9130 - val_loss: 0.9025 - val_accuracy: 0.8317\n",
      "Epoch 4946/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6868 - accuracy: 0.9113 - val_loss: 0.9064 - val_accuracy: 0.8333\n",
      "Epoch 4947/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6848 - accuracy: 0.9035 - val_loss: 0.8614 - val_accuracy: 0.8217\n",
      "Epoch 4948/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6677 - accuracy: 0.9035 - val_loss: 0.8348 - val_accuracy: 0.8217\n",
      "Epoch 4949/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6839 - accuracy: 0.9022 - val_loss: 0.8684 - val_accuracy: 0.8350\n",
      "Epoch 4950/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6828 - accuracy: 0.9078 - val_loss: 0.8509 - val_accuracy: 0.8233\n",
      "Epoch 4951/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6615 - accuracy: 0.9085 - val_loss: 0.8647 - val_accuracy: 0.8200\n",
      "Epoch 4952/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6740 - accuracy: 0.9093 - val_loss: 0.8646 - val_accuracy: 0.8267\n",
      "Epoch 4953/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6822 - accuracy: 0.9087 - val_loss: 0.8337 - val_accuracy: 0.8300\n",
      "Epoch 4954/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6621 - accuracy: 0.9093 - val_loss: 0.8353 - val_accuracy: 0.8267\n",
      "Epoch 4955/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6597 - accuracy: 0.9047 - val_loss: 0.8362 - val_accuracy: 0.8250\n",
      "Epoch 4956/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6358 - accuracy: 0.9130 - val_loss: 0.8445 - val_accuracy: 0.8400\n",
      "Epoch 4957/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6334 - accuracy: 0.9112 - val_loss: 0.8164 - val_accuracy: 0.8350\n",
      "Epoch 4958/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6540 - accuracy: 0.9073 - val_loss: 0.8567 - val_accuracy: 0.8100\n",
      "Epoch 4959/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6625 - accuracy: 0.9100 - val_loss: 0.8123 - val_accuracy: 0.8250\n",
      "Epoch 4960/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6644 - accuracy: 0.9053 - val_loss: 0.8249 - val_accuracy: 0.8233\n",
      "Epoch 4961/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6430 - accuracy: 0.9078 - val_loss: 0.8011 - val_accuracy: 0.8450\n",
      "Epoch 4962/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6497 - accuracy: 0.9040 - val_loss: 0.8465 - val_accuracy: 0.8167\n",
      "Epoch 4963/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.7051 - accuracy: 0.9020 - val_loss: 0.8297 - val_accuracy: 0.8317\n",
      "Epoch 4964/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6544 - accuracy: 0.9042 - val_loss: 0.8199 - val_accuracy: 0.8367\n",
      "Epoch 4965/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6506 - accuracy: 0.9068 - val_loss: 0.8402 - val_accuracy: 0.8250\n",
      "Epoch 4966/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6557 - accuracy: 0.9085 - val_loss: 0.8121 - val_accuracy: 0.8317\n",
      "Epoch 4967/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6689 - accuracy: 0.9078 - val_loss: 0.8085 - val_accuracy: 0.8450\n",
      "Epoch 4968/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6574 - accuracy: 0.9058 - val_loss: 0.8460 - val_accuracy: 0.8367\n",
      "Epoch 4969/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6664 - accuracy: 0.9043 - val_loss: 0.8305 - val_accuracy: 0.8300\n",
      "Epoch 4970/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6610 - accuracy: 0.9037 - val_loss: 0.8381 - val_accuracy: 0.8317\n",
      "Epoch 4971/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6661 - accuracy: 0.9093 - val_loss: 0.8302 - val_accuracy: 0.8317\n",
      "Epoch 4972/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6508 - accuracy: 0.9093 - val_loss: 0.8391 - val_accuracy: 0.8317\n",
      "Epoch 4973/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6849 - accuracy: 0.9018 - val_loss: 0.8451 - val_accuracy: 0.8150\n",
      "Epoch 4974/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6528 - accuracy: 0.9078 - val_loss: 0.8473 - val_accuracy: 0.8167\n",
      "Epoch 4975/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6509 - accuracy: 0.9085 - val_loss: 0.8576 - val_accuracy: 0.7983\n",
      "Epoch 4976/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6560 - accuracy: 0.9048 - val_loss: 0.8679 - val_accuracy: 0.8133\n",
      "Epoch 4977/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6457 - accuracy: 0.9152 - val_loss: 0.8182 - val_accuracy: 0.8433\n",
      "Epoch 4978/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6666 - accuracy: 0.9112 - val_loss: 0.8176 - val_accuracy: 0.8367\n",
      "Epoch 4979/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6504 - accuracy: 0.9122 - val_loss: 0.8149 - val_accuracy: 0.8350\n",
      "Epoch 4980/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6475 - accuracy: 0.9092 - val_loss: 0.8234 - val_accuracy: 0.8167\n",
      "Epoch 4981/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6581 - accuracy: 0.9058 - val_loss: 0.8502 - val_accuracy: 0.8267\n",
      "Epoch 4982/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6694 - accuracy: 0.9052 - val_loss: 0.8242 - val_accuracy: 0.8150\n",
      "Epoch 4983/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6616 - accuracy: 0.9047 - val_loss: 0.8251 - val_accuracy: 0.8467\n",
      "Epoch 4984/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6444 - accuracy: 0.9090 - val_loss: 0.8719 - val_accuracy: 0.8117\n",
      "Epoch 4985/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6448 - accuracy: 0.9117 - val_loss: 0.8709 - val_accuracy: 0.8400\n",
      "Epoch 4986/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6494 - accuracy: 0.9042 - val_loss: 0.8229 - val_accuracy: 0.8400\n",
      "Epoch 4987/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6509 - accuracy: 0.9053 - val_loss: 0.8215 - val_accuracy: 0.8283\n",
      "Epoch 4988/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6337 - accuracy: 0.9102 - val_loss: 0.7841 - val_accuracy: 0.8333\n",
      "Epoch 4989/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6779 - accuracy: 0.9042 - val_loss: 0.8001 - val_accuracy: 0.8333\n",
      "Epoch 4990/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6491 - accuracy: 0.9067 - val_loss: 0.8103 - val_accuracy: 0.8417\n",
      "Epoch 4991/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6445 - accuracy: 0.9085 - val_loss: 0.8217 - val_accuracy: 0.8333\n",
      "Epoch 4992/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6676 - accuracy: 0.9077 - val_loss: 0.8552 - val_accuracy: 0.8183\n",
      "Epoch 4993/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6528 - accuracy: 0.9097 - val_loss: 0.8211 - val_accuracy: 0.8283\n",
      "Epoch 4994/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6321 - accuracy: 0.9130 - val_loss: 0.8904 - val_accuracy: 0.8183\n",
      "Epoch 4995/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6481 - accuracy: 0.9100 - val_loss: 0.8305 - val_accuracy: 0.8350\n",
      "Epoch 4996/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6584 - accuracy: 0.9052 - val_loss: 0.8082 - val_accuracy: 0.8417\n",
      "Epoch 4997/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6376 - accuracy: 0.9058 - val_loss: 0.7818 - val_accuracy: 0.8400\n",
      "Epoch 4998/5000\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6341 - accuracy: 0.9097 - val_loss: 0.7936 - val_accuracy: 0.8133\n",
      "Epoch 4999/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6442 - accuracy: 0.9082 - val_loss: 0.7751 - val_accuracy: 0.8450\n",
      "Epoch 5000/5000\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.6523 - accuracy: 0.9078 - val_loss: 0.8088 - val_accuracy: 0.8267\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 291, 128)          1408      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 282, 128)          163968    \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 273, 128)          163968    \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 264, 64)           81984     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 255, 64)           41024     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 246, 64)           41024     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 15744)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15744)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              16122880  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 17,316,195\n",
      "Trainable params: 17,316,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test Accuracy for learning rate 0.0045 CV index 0 is : 0.862\n"
     ]
    }
   ],
   "source": [
    "#Warning: Running this code again will overwrite previously trained models.\n",
    "\n",
    "tmp = list(range(0,4800,400))\n",
    "X_Hold_out = [] #Holdout = testing | Max\n",
    "X_CV=[]\n",
    "Y_Hold_out = []\n",
    "Y_CV=[]\n",
    "for i in range(len(tmp)-1):\n",
    "    X_Hold_out+=[X[tmp[i]:tmp[i+1]]]\n",
    "    Y_Hold_out+=[Y[tmp[i]:tmp[i+1]]]\n",
    "    X_CV += [np.concatenate((X[0:tmp[i]],X[tmp[i+1]:]))]\n",
    "    Y_CV += [np.concatenate((Y[0:tmp[i]],Y[tmp[i+1]:]))]\n",
    "N_Leave_One_Subject = len(tmp)-1\n",
    "\n",
    "\n",
    "for learn_rate in [0.0045]:\n",
    "    for leave_one_idx in range(N_Leave_One_Subject): \n",
    "        print(leave_one_idx)\n",
    "        X_train = X_CV[leave_one_idx] # 300 refers to N_features\n",
    "        Y_train = Y_CV[leave_one_idx].reshape(-1,1)\n",
    "        X_test = X_Hold_out[leave_one_idx]\n",
    "        Y_test = Y_Hold_out[leave_one_idx]\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train).reshape(-1,300,1)\n",
    "        X_test = scaler.transform(X_test).reshape(-1,300,1)\n",
    "\n",
    "#Y_..._onehot contains one hot encoded Y_... i.e, if Y[i] = 0, Y_onehot[i] = [1,0,0] \n",
    "\n",
    "        X_train, Y_train = RandomOverSampler(random_state=0).fit_resample(X_train.reshape(-1,300),Y_train.flatten())\n",
    "        X_train = X_train.reshape(-1,300,1)\n",
    "        X_test, Y_test = RandomOverSampler(random_state=0).fit_resample(X_test.reshape(-1,300),Y_test.flatten())\n",
    "        X_test = X_test.reshape(-1,300,1)\n",
    "\n",
    "        Y_train_onehot = np.eye(3)[Y_train.astype(int)].reshape(-1,3)\n",
    "        Y_test_onehot = np.eye(3)[Y_test.astype(int)].reshape(-1,3)\n",
    "\n",
    "\n",
    "        print(\"to create\")\n",
    "        model = create_model()\n",
    "\n",
    "        savedpath = './plateau'\n",
    "        print(\"created\")\n",
    "        \n",
    "        #If the model weights have not yet been computed (i.e model did not exist), create weights file, otherwise, load the weights. Files are located in the plateau folder\n",
    "        best_model_path=os.path.join(savedpath,f\"weights_holdout_regularized_{leave_one_idx}_{learn_rate}.best.hdf5\")\n",
    "        print(best_model_path)\n",
    "        if len(glob.glob(os.path.join(savedpath, f\"weights_holdout_regularized_{leave_one_idx}_{learn_rate}.best.hdf5\")))==0:\n",
    "            print(\"created a new model\")   \n",
    "        else:\n",
    "            print(\"loaded weights from file\")\n",
    "            model.load_weights(os.path.join(savedpath,f'weights_holdout_regularized_{leave_one_idx}_{learn_rate}.best.hdf5'))\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adam(lr=learn_rate),\n",
    "                      metrics=['accuracy'])\n",
    "        batch_size = 64\n",
    "        epochs = 5000\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=50, min_lr=0.00001) #Reduce learning rate when a metric has stopped improving.\n",
    "        checkpoint = ModelCheckpoint(best_model_path, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "        csv_logger = keras.callbacks.CSVLogger(os.path.join(savedpath, f'training_holdout_regularized_{leave_one_idx}_{learn_rate}.log'))\n",
    "        print(\"Before Fit\")\n",
    "        model.fit(X_train, Y_train_onehot,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_test, Y_test_onehot),\n",
    "                  callbacks=[csv_logger,checkpoint,reduce_lr])\n",
    "        print(model.summary())\n",
    "        model.load_weights(os.path.join(savedpath,f'weights_holdout_regularized_{leave_one_idx}_{learn_rate}.best.hdf5'))\n",
    "        score, acc = model.evaluate(X_test, Y_test_onehot, batch_size=batch_size,verbose=0)\n",
    "        with open(os.path.join(savedpath,f\"test_holdout_regularized_{leave_one_idx}_{learn_rate}.log\"), 'a') as f:\n",
    "            print(\"...Test size:\" + \"{:.3f}\".format(X_test.shape[0]), file=f)\n",
    "            print(\"...Test score:\"+\"{:.3f}\".format(score),file=f)\n",
    "            print(\"...Testing accuracy:\" + \"{:.3f}\".format(acc), file=f)\n",
    "        print(f'Test Accuracy for learning rate {learn_rate} CV index {leave_one_idx} is :', \"{:.3f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1621906815949,
     "user": {
      "displayName": "Maxime Tchibozo",
      "photoUrl": "",
      "userId": "01215953581360341724"
     },
     "user_tz": 240
    },
    "id": "_1n4jCTuywLq",
    "outputId": "205b0052-4e8e-42ed-abed-a1d37cc23e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Number  7 :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmp = list(range(0,4800,400))\n",
    "N_Leave_One_Subject = len(tmp)-1\n",
    "\n",
    "for learn_rate in [0.0045]:\n",
    "    for leave_one_idx in [7]:\n",
    "        model_num = leave_one_idx\n",
    "        print('Cross-Validation Number ',leave_one_idx,':')\n",
    "        train_result = pd.read_csv(os.path.join('./plateau',f'training_holdout_regularized_{model_num}_{learn_rate}.log'))\n",
    "        train_result = train_result[train_result.epoch < 5001][train_result.epoch > 1].iloc[::10]\n",
    "\n",
    "        ax = figure(0).gca()\n",
    "        ax.plot('epoch','val_accuracy',data=train_result,color='crimson')\n",
    "        ax.plot('epoch','accuracy',data=train_result,color='navy')\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.legend(bbox_to_anchor=(0.8, 0.09), loc='upper left', borderaxespad=0.)\n",
    "        plt.title('Cross-Validation Accuracy - Subject: '+str(leave_one_idx))\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('accuracy')\n",
    "        ax.set_yticks(np.arange(0.5,1,0.1))\n",
    "        fig = ax.get_figure()\n",
    "        fig.set_figheight(9)\n",
    "        fig.set_figwidth(9) \n",
    "        plt.grid()\n",
    "        #fig.savefig(\"fixed-acc_cv\"+str(leave_one_idx)+\"_lr_\"+str(learn_rate)+\".png\")\n",
    "\n",
    "        train_result = train_result[train_result.epoch > 300]\n",
    "\n",
    "        ax2 = figure(1).gca()\n",
    "        ax2.plot('epoch','val_loss',data=train_result,color='crimson')\n",
    "        ax2.plot('epoch','loss',data=train_result,color='navy')\n",
    "        ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax2.legend(bbox_to_anchor=(0.8, 0.95), loc='upper left', borderaxespad=0.)\n",
    "        ax2.set_xlabel('epoch')\n",
    "        ax2.set_ylabel('loss')\n",
    "        plt.title('Cross-Validation Loss - Subject: '+str(leave_one_idx))\n",
    "\n",
    "        fig2 = ax2.get_figure()\n",
    "        fig2.set_figheight(9)\n",
    "        fig2.set_figwidth(9)  \n",
    "        plt.grid()    \n",
    "        fig2.savefig(\"fixed-loss_cv\"+str(leave_one_idx)+\"_lr_\"+str(learn_rate)+\"_zoom.png\")\n",
    "\n",
    "        show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRjw1LcyJ7-J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xN9SWc83v5hV",
    "x65v8vdKG7xg"
   ],
   "name": "Hyper_test_updated_regularised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
